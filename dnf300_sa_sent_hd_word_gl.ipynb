{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import spacy\n",
    "from keras.utils import to_categorical\n",
    "from spacy.lang.en import English\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.layers import BatchNormalization, Lambda, Concatenate, Dropout, Conv1D, MaxPooling1D, Input, TimeDistributed, Dense, LSTM, RepeatVector, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from AttentionModules import SelfAttention, CrossAttention\n",
    "import sys,os\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['authors', 'claim_ids', 'evidence', 'headline', 'id', 'reason',\n",
       "        'claims', 'type', 'urls'],\n",
       "       dtype='object'),\n",
       " Index(['authors', 'evidence', 'headline', 'id', 'reason', 'type', 'urls'], dtype='object'),\n",
       " 300,\n",
       " 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf300 = pd.read_json('evaluation_set/deepnofakes/dnf_300/combined_300.json').T\n",
    "dnf_eval = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "# display(dnf_eval.head(2))\n",
    "dnf_eval.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls'] \n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_array_id.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "dnf_eval.keys(), dnf300.keys(), len(articles.keys()), len(article_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "train_batchsize = 32\n",
    "val_batchsize = 32\n",
    "test_batchsize = 50\n",
    "train_steps_per_epoch = 4\n",
    "val_steps_per_epoch = 1\n",
    "epochs = 2000\n",
    "max_sentences = 500\n",
    "# for idx in articles.keys():\n",
    "#     num = len(articles[idx])\n",
    "#     if num>=max_sentences:\n",
    "#         max_sentences = num\n",
    "        \n",
    "max_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = sorted(dnf_eval.headline.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "non_test_titles = np.array(list(set(titles)-set(test_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, val_index in kf.split(non_test_titles):\n",
    "    indices.append([train_index,val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202] [203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220\n",
      " 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238\n",
      " 239 240 241 242 243 244 245 246 247 248 249 250 251 252]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(203, 50, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_index, val_index = indices[np.random.randint(0,num_splits)]\n",
    "print(train_index,val_index)\n",
    "val_titles = non_test_titles[val_index]\n",
    "train_titles = non_test_titles[train_index]\n",
    "len(train_titles),len(val_titles),len(test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy():\n",
    "    sentencizer = English()\n",
    "    sentencizer.add_pipe(sentencizer.create_pipe('sentencizer'))\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    return sentencizer, nlp\n",
    "sentencizer, nlp = load_spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf(batchsize,dataframe,mode):\n",
    "    counter=0\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            idx=np.random.choice(train_titles)\n",
    "        elif mode=='val':\n",
    "            idx=np.random.choice(val_titles)\n",
    "        elif mode=='test':\n",
    "            idx=np.random.choice(test_titles)\n",
    "        idx = idx.strip()\n",
    "        \n",
    "            \n",
    "#         cl = dataframe[dataframe.Article==idx]['Claim'].values\n",
    "#         sentences=articles[ar_id]\n",
    "#         print(len(sentences))\n",
    "        if mode=='test':\n",
    "            hd = dnf_eval[dnf_eval.headline==idx]['headline'].values[0].lower()\n",
    "            ar_id = dnf_eval[dnf_eval.headline==idx]['id'].values[0]\n",
    "            cl = dnf_eval[dnf_eval.headline==idx]['claim_ids'].values[0]\n",
    "            ar_claims.append(cl)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                hd = dataframe[dataframe.headline==idx]['headline'].values[0].lower()\n",
    "                ar_id = dataframe[dataframe.headline==idx]['id'].values[0]\n",
    "                ar_claims.append('None')\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(idx)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "#         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "        \n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "        counter+=1\n",
    "        if counter==batchsize:\n",
    "            inputs = {\n",
    "                'article_id': np.array(ar_ids)\n",
    "                ,'headline': np.array(hds)\n",
    "                ,'sentence_vectors' : np.array(ar_sents)\n",
    "                ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "                ,'claims':np.array(ar_claims)\n",
    "                ,'sentences':np.array(ar_sentences)\n",
    "            }\n",
    "            outputs = {\n",
    "                'headline_token_classes': np.array(ar_head_classes)\n",
    "                ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "            }\n",
    "            yield inputs,outputs\n",
    "            ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "            counter=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = datagen_dnf(train_batchsize,dnf300,mode='train')\n",
    "vdg = datagen_dnf(val_batchsize,dnf300,mode='val')\n",
    "test_dg = datagen_dnf(test_batchsize,dnf300,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(test_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['sentence_vectors'].shape, x['headline_vector'].shape, y['headline_token_classes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 500, 1024)    0           ca1[0][0]                        \n",
      "                                                                 ca2[0][0]                        \n",
      "                                                                 ca3[0][0]                        \n",
      "                                                                 ca4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 1024)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 500, 1024)    4096        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 250, 256)     786688      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 125, 256)     196864      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 63, 256)      196864      conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 32, 256)      196864      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 256)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 256)      1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 50, 256)      0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50, 256)      525312      repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 50, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 50, 256)      1024        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "headline_token_classes (TimeDis (None, 50, 20000)    5140000     batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 7,844,152\n",
      "Trainable params: 7,839,992\n",
      "Non-trainable params: 4,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"2213pt\" viewBox=\"0.00 0.00 1810.50 2213.00\" width=\"1811pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 2209)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-2209 1806.5,-2209 1806.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140267327383312 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140267327383312</title>\n",
       "<polygon fill=\"none\" points=\"857,-2158.5 857,-2204.5 1198,-2204.5 1198,-2158.5 857,-2158.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2177.8\">sentence_vectors: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2158.5 1033,-2204.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2189.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2181.5 1088,-2181.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2166.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2158.5 1088,-2204.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2189.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2181.5 1198,-2181.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2166.3\">(None, 500, 300)</text>\n",
       "</g>\n",
       "<!-- 140267327383704 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140267327383704</title>\n",
       "<polygon fill=\"none\" points=\"883.5,-2075.5 883.5,-2121.5 1171.5,-2121.5 1171.5,-2075.5 883.5,-2075.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2094.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2075.5 1006.5,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2098.5 1061.5,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2075.5 1061.5,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2106.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2098.5 1171.5,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2083.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 140267327383312&#45;&gt;140267327383704 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140267327383312-&gt;140267327383704</title>\n",
       "<path d=\"M1027.5,-2158.3799C1027.5,-2150.1745 1027.5,-2140.7679 1027.5,-2131.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2131.784 1027.5,-2121.784 1024.0001,-2131.784 1031.0001,-2131.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140267327383816 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140267327383816</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1992.5 885.5,-2038.5 1169.5,-2038.5 1169.5,-1992.5 885.5,-1992.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-2011.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1992.5 1010.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-2015.5 1065.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1992.5 1065.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-2023.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-2015.5 1169.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-2000.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 140267327383704&#45;&gt;140267327383816 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140267327383704-&gt;140267327383816</title>\n",
       "<path d=\"M1027.5,-2075.3799C1027.5,-2067.1745 1027.5,-2057.7679 1027.5,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2048.784 1027.5,-2038.784 1024.0001,-2048.784 1031.0001,-2048.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140267327384544 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140267327384544</title>\n",
       "<polygon fill=\"none\" points=\"886.5,-1909.5 886.5,-1955.5 1168.5,-1955.5 1168.5,-1909.5 886.5,-1909.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1928.8\">conv1d_2: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1909.5 1009.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1932.5 1064.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1909.5 1064.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1940.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1932.5 1168.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1917.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140267327383816&#45;&gt;140267327384544 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140267327383816-&gt;140267327384544</title>\n",
       "<path d=\"M1027.5,-1992.3799C1027.5,-1984.1745 1027.5,-1974.7679 1027.5,-1965.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1965.784 1027.5,-1955.784 1024.0001,-1965.784 1031.0001,-1965.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140267367359152 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140267367359152</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1826.5 885.5,-1872.5 1169.5,-1872.5 1169.5,-1826.5 885.5,-1826.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1845.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1826.5 1010.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1849.5 1065.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1826.5 1065.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1857.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1849.5 1169.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1834.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140267327384544&#45;&gt;140267367359152 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140267327384544-&gt;140267367359152</title>\n",
       "<path d=\"M1027.5,-1909.3799C1027.5,-1901.1745 1027.5,-1891.7679 1027.5,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1882.784 1027.5,-1872.784 1024.0001,-1882.784 1031.0001,-1882.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266633986288 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140266633986288</title>\n",
       "<polygon fill=\"none\" points=\"818,-1743.5 818,-1789.5 1237,-1789.5 1237,-1743.5 818,-1743.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1762.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1743.5 1078,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1766.5 1133,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1743.5 1133,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1774.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1766.5 1237,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1751.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140267367359152&#45;&gt;140266633986288 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140267367359152-&gt;140266633986288</title>\n",
       "<path d=\"M1027.5,-1826.3799C1027.5,-1818.1745 1027.5,-1808.7679 1027.5,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1799.784 1027.5,-1789.784 1024.0001,-1799.784 1031.0001,-1799.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266633872664 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140266633872664</title>\n",
       "<polygon fill=\"none\" points=\"252.5,-1660.5 252.5,-1706.5 626.5,-1706.5 626.5,-1660.5 252.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-1679.8\">sa1: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1660.5 367.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1683.5 422.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1660.5 422.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1683.5 626.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266633986288&#45;&gt;140266633872664 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140266633986288-&gt;140266633872664</title>\n",
       "<path d=\"M864.4901,-1743.4901C786.1844,-1732.4367 692.2952,-1719.1837 612.7036,-1707.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"612.9631,-1704.4508 602.572,-1706.5187 611.9847,-1711.3821 612.9631,-1704.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266633309880 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140266633309880</title>\n",
       "<polygon fill=\"none\" points=\"644.5,-1660.5 644.5,-1706.5 1018.5,-1706.5 1018.5,-1660.5 644.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"702\" y=\"-1679.8\">sa2: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1660.5 759.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1683.5 814.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1660.5 814.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1683.5 1018.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266633986288&#45;&gt;140266633309880 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140266633986288-&gt;140266633309880</title>\n",
       "<path d=\"M973.1634,-1743.4901C949.0535,-1733.2803 920.5118,-1721.1938 895.3877,-1710.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"896.5156,-1707.2313 885.9423,-1706.5547 893.7859,-1713.6771 896.5156,-1707.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266632012464 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140266632012464</title>\n",
       "<polygon fill=\"none\" points=\"1036.5,-1660.5 1036.5,-1706.5 1410.5,-1706.5 1410.5,-1660.5 1036.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094\" y=\"-1679.8\">sa3: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1660.5 1151.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1683.5 1206.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1660.5 1206.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1683.5 1410.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266633986288&#45;&gt;140266632012464 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140266633986288-&gt;140266632012464</title>\n",
       "<path d=\"M1081.8366,-1743.4901C1105.9465,-1733.2803 1134.4882,-1721.1938 1159.6123,-1710.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1161.2141,-1713.6771 1169.0577,-1706.5547 1158.4844,-1707.2313 1161.2141,-1713.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266631307840 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140266631307840</title>\n",
       "<polygon fill=\"none\" points=\"1428.5,-1660.5 1428.5,-1706.5 1802.5,-1706.5 1802.5,-1660.5 1428.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1486\" y=\"-1679.8\">sa4: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1660.5 1543.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1683.5 1598.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1660.5 1598.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1683.5 1802.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266633986288&#45;&gt;140266631307840 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140266633986288-&gt;140266631307840</title>\n",
       "<path d=\"M1190.5099,-1743.4901C1268.8156,-1732.4367 1362.7048,-1719.1837 1442.2964,-1707.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1443.0153,-1711.3821 1452.428,-1706.5187 1442.0369,-1704.4508 1443.0153,-1711.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266630465688 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140266630465688</title>\n",
       "<polygon fill=\"none\" points=\"718,-1577.5 718,-1623.5 1337,-1623.5 1337,-1577.5 718,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-1596.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"886,-1577.5 886,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"886,-1600.5 941,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"941,-1577.5 941,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1608.3\">[(None, 500, 32), (None, 500, 32), (None, 500, 32), (None, 500, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"941,-1600.5 1337,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1585.3\">(None, 500, 128)</text>\n",
       "</g>\n",
       "<!-- 140266633872664&#45;&gt;140266630465688 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140266633872664-&gt;140266630465688</title>\n",
       "<path d=\"M602.5099,-1660.4901C680.8156,-1649.4367 774.7048,-1636.1837 854.2964,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"855.0153,-1628.3821 864.428,-1623.5187 854.0369,-1621.4508 855.0153,-1628.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266633309880&#45;&gt;140266630465688 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140266633309880-&gt;140266630465688</title>\n",
       "<path d=\"M885.8366,-1660.4901C909.9465,-1650.2803 938.4882,-1638.1938 963.6123,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"965.2141,-1630.6771 973.0577,-1623.5547 962.4844,-1624.2313 965.2141,-1630.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266632012464&#45;&gt;140266630465688 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140266632012464-&gt;140266630465688</title>\n",
       "<path d=\"M1169.1634,-1660.4901C1145.0535,-1650.2803 1116.5118,-1638.1938 1091.3877,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1092.5156,-1624.2313 1081.9423,-1623.5547 1089.7859,-1630.6771 1092.5156,-1624.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266631307840&#45;&gt;140266630465688 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140266631307840-&gt;140266630465688</title>\n",
       "<path d=\"M1452.4901,-1660.4901C1374.1844,-1649.4367 1280.2952,-1636.1837 1200.7036,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1200.9631,-1621.4508 1190.572,-1623.5187 1199.9847,-1628.3821 1200.9631,-1621.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140267327384152 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140267327384152</title>\n",
       "<polygon fill=\"none\" points=\"357,-1577.5 357,-1623.5 700,-1623.5 700,-1577.5 357,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-1596.8\">input_headline_vector: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"562,-1577.5 562,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"562,-1600.5 617,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"617,-1577.5 617,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1608.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"617,-1600.5 700,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1585.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140266629313536 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140266629313536</title>\n",
       "<polygon fill=\"none\" points=\"439.5,-1494.5 439.5,-1540.5 679.5,-1540.5 679.5,-1494.5 439.5,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-1513.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1494.5 541.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1517.5 596.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1494.5 596.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1525.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1517.5 679.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1502.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140267327384152&#45;&gt;140266629313536 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>140267327384152-&gt;140266629313536</title>\n",
       "<path d=\"M537.1352,-1577.3799C540.2665,-1568.9962 543.8662,-1559.3584 547.2495,-1550.2996\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"550.5834,-1551.3766 550.8036,-1540.784 544.0259,-1548.9273 550.5834,-1551.3766\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266633574944 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140266633574944</title>\n",
       "<polygon fill=\"none\" points=\"881.5,-1494.5 881.5,-1540.5 1169.5,-1540.5 1169.5,-1494.5 881.5,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"943\" y=\"-1513.8\">conv1d_3: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1494.5 1004.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1517.5 1059.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1494.5 1059.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1525.3\">(None, 500, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1517.5 1169.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1502.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140266630465688&#45;&gt;140266633574944 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>140266630465688-&gt;140266633574944</title>\n",
       "<path d=\"M1026.9429,-1577.3799C1026.7452,-1569.1745 1026.5185,-1559.7679 1026.3043,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1029.801,-1550.6968 1026.0611,-1540.784 1022.8031,-1550.8655 1029.801,-1550.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629163216 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>140266629163216</title>\n",
       "<polygon fill=\"none\" points=\"437,-1411.5 437,-1457.5 712,-1457.5 712,-1411.5 437,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-1430.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"560,-1411.5 560,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"560,-1434.5 615,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"615,-1411.5 615,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1442.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"615,-1434.5 712,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1419.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140266629313536&#45;&gt;140266629163216 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>140266629313536-&gt;140266629163216</title>\n",
       "<path d=\"M563.6783,-1494.3799C565.1612,-1486.1745 566.8612,-1476.7679 568.4677,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"571.9578,-1468.2471 570.292,-1457.784 565.0693,-1467.0021 571.9578,-1468.2471\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629720776 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>140266629720776</title>\n",
       "<polygon fill=\"none\" points=\"876.5,-1411.5 876.5,-1457.5 1166.5,-1457.5 1166.5,-1411.5 876.5,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"939\" y=\"-1430.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1411.5 1001.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1434.5 1056.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1411.5 1056.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1442.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1434.5 1166.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1419.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140266633574944&#45;&gt;140266629720776 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>140266633574944-&gt;140266629720776</title>\n",
       "<path d=\"M1024.3858,-1494.3799C1023.9903,-1486.1745 1023.537,-1476.7679 1023.1086,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1026.5995,-1467.6039 1022.6221,-1457.784 1019.6076,-1467.9409 1026.5995,-1467.6039\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266628496856 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>140266628496856</title>\n",
       "<polygon fill=\"none\" points=\"376.5,-1328.5 376.5,-1374.5 788.5,-1374.5 788.5,-1328.5 376.5,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-1347.8\">batch_normalization_3: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1328.5 636.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1351.5 691.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1328.5 691.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1359.3\">(None, 1, 256)</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1351.5 788.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1336.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140266629163216&#45;&gt;140266628496856 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>140266629163216-&gt;140266628496856</title>\n",
       "<path d=\"M576.7284,-1411.3799C577.5193,-1403.1745 578.426,-1393.7679 579.2828,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"582.7801,-1385.0737 580.2558,-1374.784 575.8124,-1384.4021 582.7801,-1385.0737\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629720160 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>140266629720160</title>\n",
       "<polygon fill=\"none\" points=\"807,-1328.5 807,-1374.5 1232,-1374.5 1232,-1328.5 807,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"937\" y=\"-1347.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1328.5 1067,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1351.5 1122,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1328.5 1122,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1359.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1351.5 1232,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1336.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140266629720776&#45;&gt;140266629720160 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>140266629720776-&gt;140266629720160</title>\n",
       "<path d=\"M1020.9429,-1411.3799C1020.7452,-1403.1745 1020.5185,-1393.7679 1020.3043,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1023.801,-1384.6968 1020.0611,-1374.784 1016.8031,-1384.8655 1023.801,-1384.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266628425488 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>140266628425488</title>\n",
       "<polygon fill=\"none\" points=\"810,-1245.5 810,-1291.5 1197,-1291.5 1197,-1245.5 810,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872.5\" y=\"-1264.8\">ca1: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"935,-1245.5 935,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"935,-1268.5 990,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"990,-1245.5 990,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"990,-1268.5 1197,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266628496856&#45;&gt;140266628425488 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>140266628496856-&gt;140266628425488</title>\n",
       "<path d=\"M699.2129,-1328.4901C754.3078,-1317.6282 820.1773,-1304.642 876.519,-1293.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"877.4259,-1296.9229 886.5601,-1291.5547 876.0719,-1290.0551 877.4259,-1296.9229\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266627502152 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>140266627502152</title>\n",
       "<polygon fill=\"none\" points=\"1215,-1245.5 1215,-1291.5 1602,-1291.5 1602,-1245.5 1215,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277.5\" y=\"-1264.8\">ca2: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1245.5 1340,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1268.5 1395,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1245.5 1395,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1268.5 1602,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266628496856&#45;&gt;140266627502152 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>140266628496856-&gt;140266627502152</title>\n",
       "<path d=\"M788.5682,-1328.986C791.9028,-1328.6525 795.2153,-1328.3236 798.5,-1328 976.3881,-1310.477 1023.7095,-1310.5124 1204.8542,-1292.1557\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1205.3964,-1295.6187 1214.9903,-1291.1236 1204.6872,-1288.6547 1205.3964,-1295.6187\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266626491000 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>140266626491000</title>\n",
       "<polygon fill=\"none\" points=\"0,-1245.5 0,-1291.5 387,-1291.5 387,-1245.5 0,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-1264.8\">ca3: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"125,-1245.5 125,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-1268.5 180,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-1245.5 180,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"180,-1268.5 387,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266628496856&#45;&gt;140266626491000 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>140266628496856-&gt;140266626491000</title>\n",
       "<path d=\"M474.6584,-1328.4901C423.962,-1317.6731 363.3923,-1304.7495 311.4764,-1293.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"312.0616,-1290.2185 301.5514,-1291.5547 310.6009,-1297.0644 312.0616,-1290.2185\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266625640544 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>140266625640544</title>\n",
       "<polygon fill=\"none\" points=\"405,-1245.5 405,-1291.5 792,-1291.5 792,-1245.5 405,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467.5\" y=\"-1264.8\">ca4: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"530,-1245.5 530,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"530,-1268.5 585,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"585,-1245.5 585,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"585,-1268.5 792,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140266628496856&#45;&gt;140266625640544 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>140266628496856-&gt;140266625640544</title>\n",
       "<path d=\"M586.9569,-1328.3799C588.5386,-1320.1745 590.352,-1310.7679 592.0656,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"595.5553,-1302.2658 594.0115,-1291.784 588.6818,-1300.9407 595.5553,-1302.2658\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629720160&#45;&gt;140266628425488 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>140266629720160-&gt;140266628425488</title>\n",
       "<path d=\"M1015.0431,-1328.3799C1013.4614,-1320.1745 1011.648,-1310.7679 1009.9344,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1013.3182,-1300.9407 1007.9885,-1291.784 1006.4447,-1302.2658 1013.3182,-1300.9407\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629720160&#45;&gt;140266627502152 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>140266629720160-&gt;140266627502152</title>\n",
       "<path d=\"M1127.3416,-1328.4901C1178.038,-1317.6731 1238.6077,-1304.7495 1290.5236,-1293.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1291.3991,-1297.0644 1300.4486,-1291.5547 1289.9384,-1290.2185 1291.3991,-1297.0644\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629720160&#45;&gt;140266626491000 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>140266629720160-&gt;140266626491000</title>\n",
       "<path d=\"M806.8249,-1328.9162C803.6957,-1328.6071 800.5859,-1328.3015 797.5,-1328 622.1938,-1310.873 575.6096,-1310.3786 397.0043,-1292.1432\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"397.3151,-1288.6568 387.0102,-1291.1184 396.601,-1295.6203 397.3151,-1288.6568\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266629720160&#45;&gt;140266625640544 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>140266629720160-&gt;140266625640544</title>\n",
       "<path d=\"M902.7871,-1328.4901C847.6922,-1317.6282 781.8227,-1304.642 725.481,-1293.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"725.9281,-1290.0551 715.4399,-1291.5547 724.5741,-1296.9229 725.9281,-1290.0551\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266624906016 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>140266624906016</title>\n",
       "<polygon fill=\"none\" points=\"477.5,-1162.5 477.5,-1208.5 1123.5,-1208.5 1123.5,-1162.5 477.5,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-1181.8\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1162.5 645.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1185.5 700.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1162.5 700.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1193.3\">[(None, 500, 256), (None, 500, 256), (None, 500, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1185.5 1123.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1170.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140266628425488&#45;&gt;140266624906016 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>140266628425488-&gt;140266624906016</title>\n",
       "<path d=\"M947.2228,-1245.4901C922.1419,-1235.2353 892.4302,-1223.0872 866.3257,-1212.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"867.4675,-1209.0996 856.8867,-1208.5547 864.8183,-1215.579 867.4675,-1209.0996\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266627502152&#45;&gt;140266624906016 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>140266627502152-&gt;140266624906016</title>\n",
       "<path d=\"M1239.9455,-1245.4901C1158.8115,-1234.4142 1061.4981,-1221.1297 979.0922,-1209.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"979.5002,-1206.4035 969.1187,-1208.5187 978.5534,-1213.3392 979.5002,-1206.4035\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266626491000&#45;&gt;140266624906016 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>140266626491000-&gt;140266624906016</title>\n",
       "<path d=\"M361.7773,-1245.4901C442.7778,-1234.4142 539.9312,-1221.1297 622.2015,-1209.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"622.725,-1213.3413 632.1586,-1208.5187 621.7766,-1206.4058 622.725,-1213.3413\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266625640544&#45;&gt;140266624906016 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>140266625640544-&gt;140266624906016</title>\n",
       "<path d=\"M654.5,-1245.4901C679.4573,-1235.2353 709.0226,-1223.0872 734.9986,-1212.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"736.4717,-1215.5927 744.3911,-1208.5547 733.8112,-1209.1179 736.4717,-1215.5927\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266624081592 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>140266624081592</title>\n",
       "<polygon fill=\"none\" points=\"652,-1079.5 652,-1125.5 949,-1125.5 949,-1079.5 652,-1079.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1098.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"777,-1079.5 777,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"777,-1102.5 832,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-1079.5 832,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1110.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"832,-1102.5 949,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1087.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140266624906016&#45;&gt;140266624081592 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>140266624906016-&gt;140266624081592</title>\n",
       "<path d=\"M800.5,-1162.3799C800.5,-1154.1745 800.5,-1144.7679 800.5,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1135.784 800.5,-1125.784 797.0001,-1135.784 804.0001,-1135.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266628053032 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>140266628053032</title>\n",
       "<polygon fill=\"none\" points=\"584.5,-996.5 584.5,-1042.5 1016.5,-1042.5 1016.5,-996.5 584.5,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1015.8\">batch_normalization_4: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-996.5 844.5,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-1019.5 899.5,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-996.5 899.5,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-1027.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-1019.5 1016.5,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-1004.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140266624081592&#45;&gt;140266628053032 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>140266624081592-&gt;140266628053032</title>\n",
       "<path d=\"M800.5,-1079.3799C800.5,-1071.1745 800.5,-1061.7679 800.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1052.784 800.5,-1042.784 797.0001,-1052.784 804.0001,-1052.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266628052192 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>140266628052192</title>\n",
       "<polygon fill=\"none\" points=\"653,-913.5 653,-959.5 948,-959.5 948,-913.5 653,-913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-932.8\">conv1d_4: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-913.5 776,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-936.5 831,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"831,-913.5 831,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-944.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"831,-936.5 948,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-921.3\">(None, 250, 256)</text>\n",
       "</g>\n",
       "<!-- 140266628053032&#45;&gt;140266628052192 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>140266628053032-&gt;140266628052192</title>\n",
       "<path d=\"M800.5,-996.3799C800.5,-988.1745 800.5,-978.7679 800.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-969.784 800.5,-959.784 797.0001,-969.784 804.0001,-969.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266623899856 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>140266623899856</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-830.5 656.5,-876.5 944.5,-876.5 944.5,-830.5 656.5,-830.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-849.8\">conv1d_5: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-830.5 779.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-853.5 834.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-830.5 834.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-861.3\">(None, 250, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-853.5 944.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-838.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 140266628052192&#45;&gt;140266623899856 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>140266628052192-&gt;140266623899856</title>\n",
       "<path d=\"M800.5,-913.3799C800.5,-905.1745 800.5,-895.7679 800.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-886.784 800.5,-876.784 797.0001,-886.784 804.0001,-886.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266623054120 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>140266623054120</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-747.5 656.5,-793.5 944.5,-793.5 944.5,-747.5 656.5,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-766.8\">conv1d_6: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-747.5 779.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-770.5 834.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-747.5 834.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-778.3\">(None, 125, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-770.5 944.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-755.3\">(None, 63, 256)</text>\n",
       "</g>\n",
       "<!-- 140266623899856&#45;&gt;140266623054120 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>140266623899856-&gt;140266623054120</title>\n",
       "<path d=\"M800.5,-830.3799C800.5,-822.1745 800.5,-812.7679 800.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-803.784 800.5,-793.784 797.0001,-803.784 804.0001,-803.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266622231272 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>140266622231272</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-664.5 659.5,-710.5 941.5,-710.5 941.5,-664.5 659.5,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-683.8\">conv1d_7: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-664.5 782.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-687.5 837.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-664.5 837.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-695.3\">(None, 63, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-687.5 941.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-672.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140266623054120&#45;&gt;140266622231272 -->\n",
       "<g class=\"edge\" id=\"edge37\">\n",
       "<title>140266623054120-&gt;140266622231272</title>\n",
       "<path d=\"M800.5,-747.3799C800.5,-739.1745 800.5,-729.7679 800.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-720.784 800.5,-710.784 797.0001,-720.784 804.0001,-720.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266622333840 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>140266622333840</title>\n",
       "<polygon fill=\"none\" points=\"658.5,-581.5 658.5,-627.5 942.5,-627.5 942.5,-581.5 658.5,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-600.8\">dropout_5: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-581.5 783.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-604.5 838.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-581.5 838.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-612.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-604.5 942.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-589.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140266622231272&#45;&gt;140266622333840 -->\n",
       "<g class=\"edge\" id=\"edge38\">\n",
       "<title>140266622231272-&gt;140266622333840</title>\n",
       "<path d=\"M800.5,-664.3799C800.5,-656.1745 800.5,-646.7679 800.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-637.784 800.5,-627.784 797.0001,-637.784 804.0001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266622336024 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>140266622336024</title>\n",
       "<polygon fill=\"none\" points=\"591,-498.5 591,-544.5 1010,-544.5 1010,-498.5 591,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-517.8\">batch_normalization_5: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"851,-498.5 851,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"851,-521.5 906,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"906,-498.5 906,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-529.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"906,-521.5 1010,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-506.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140266622333840&#45;&gt;140266622336024 -->\n",
       "<g class=\"edge\" id=\"edge39\">\n",
       "<title>140266622333840-&gt;140266622336024</title>\n",
       "<path d=\"M800.5,-581.3799C800.5,-573.1745 800.5,-563.7679 800.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-554.784 800.5,-544.784 797.0001,-554.784 804.0001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266621916104 -->\n",
       "<g class=\"node\" id=\"node32\">\n",
       "<title>140266621916104</title>\n",
       "<polygon fill=\"none\" points=\"559.5,-415.5 559.5,-461.5 1041.5,-461.5 1041.5,-415.5 559.5,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-434.8\">global_average_pooling1d_1: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-415.5 882.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-438.5 937.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-415.5 937.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-446.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-438.5 1041.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-423.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140266622336024&#45;&gt;140266621916104 -->\n",
       "<g class=\"edge\" id=\"edge40\">\n",
       "<title>140266622336024-&gt;140266621916104</title>\n",
       "<path d=\"M800.5,-498.3799C800.5,-490.1745 800.5,-480.7679 800.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-471.784 800.5,-461.784 797.0001,-471.784 804.0001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266622047736 -->\n",
       "<g class=\"node\" id=\"node33\">\n",
       "<title>140266622047736</title>\n",
       "<polygon fill=\"none\" points=\"628.5,-332.5 628.5,-378.5 972.5,-378.5 972.5,-332.5 628.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-351.8\">repeat_vector_1: RepeatVector</text>\n",
       "<polyline fill=\"none\" points=\"813.5,-332.5 813.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"841\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"813.5,-355.5 868.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"841\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"868.5,-332.5 868.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"920.5\" y=\"-363.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"868.5,-355.5 972.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"920.5\" y=\"-340.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140266621916104&#45;&gt;140266622047736 -->\n",
       "<g class=\"edge\" id=\"edge41\">\n",
       "<title>140266621916104-&gt;140266622047736</title>\n",
       "<path d=\"M800.5,-415.3799C800.5,-407.1745 800.5,-397.7679 800.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-388.784 800.5,-378.784 797.0001,-388.784 804.0001,-388.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266622049584 -->\n",
       "<g class=\"node\" id=\"node34\">\n",
       "<title>140266622049584</title>\n",
       "<polygon fill=\"none\" points=\"672,-249.5 672,-295.5 929,-295.5 929,-249.5 672,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-268.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"770,-249.5 770,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"797.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"770,-272.5 825,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"797.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"825,-249.5 825,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"877\" y=\"-280.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"825,-272.5 929,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"877\" y=\"-257.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140266622047736&#45;&gt;140266622049584 -->\n",
       "<g class=\"edge\" id=\"edge42\">\n",
       "<title>140266622047736-&gt;140266622049584</title>\n",
       "<path d=\"M800.5,-332.3799C800.5,-324.1745 800.5,-314.7679 800.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-305.784 800.5,-295.784 797.0001,-305.784 804.0001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266621007520 -->\n",
       "<g class=\"node\" id=\"node35\">\n",
       "<title>140266621007520</title>\n",
       "<polygon fill=\"none\" points=\"658.5,-166.5 658.5,-212.5 942.5,-212.5 942.5,-166.5 658.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-185.8\">dropout_6: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-166.5 783.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-189.5 838.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-166.5 838.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-197.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-189.5 942.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-174.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140266622049584&#45;&gt;140266621007520 -->\n",
       "<g class=\"edge\" id=\"edge43\">\n",
       "<title>140266622049584-&gt;140266621007520</title>\n",
       "<path d=\"M800.5,-249.3799C800.5,-241.1745 800.5,-231.7679 800.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-222.784 800.5,-212.784 797.0001,-222.784 804.0001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266619996984 -->\n",
       "<g class=\"node\" id=\"node36\">\n",
       "<title>140266619996984</title>\n",
       "<polygon fill=\"none\" points=\"591,-83.5 591,-129.5 1010,-129.5 1010,-83.5 591,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-102.8\">batch_normalization_6: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"851,-83.5 851,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"851,-106.5 906,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"906,-83.5 906,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-114.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"906,-106.5 1010,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-91.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140266621007520&#45;&gt;140266619996984 -->\n",
       "<g class=\"edge\" id=\"edge44\">\n",
       "<title>140266621007520-&gt;140266619996984</title>\n",
       "<path d=\"M800.5,-166.3799C800.5,-158.1745 800.5,-148.7679 800.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-139.784 800.5,-129.784 797.0001,-139.784 804.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140266618595648 -->\n",
       "<g class=\"node\" id=\"node37\">\n",
       "<title>140266618595648</title>\n",
       "<polygon fill=\"none\" points=\"546,-.5 546,-46.5 1055,-46.5 1055,-.5 546,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-19.8\">headline_token_classes(dense_2): TimeDistributed(Dense)</text>\n",
       "<polyline fill=\"none\" points=\"883,-.5 883,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"883,-23.5 938,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"938,-.5 938,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"996.5\" y=\"-31.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"938,-23.5 1055,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"996.5\" y=\"-8.3\">(None, 50, 20000)</text>\n",
       "</g>\n",
       "<!-- 140266619996984&#45;&gt;140266618595648 -->\n",
       "<g class=\"edge\" id=\"edge45\">\n",
       "<title>140266619996984-&gt;140266618595648</title>\n",
       "<path d=\"M800.5,-83.3799C800.5,-75.1745 800.5,-65.7679 800.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-56.784 800.5,-46.784 797.0001,-56.784 804.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    inp_sentence_vectors = Input(shape=(max_sentences, 300), name='sentence_vectors')\n",
    "    inp_headline_vector = Input(shape=(300,), name='input_headline_vector')\n",
    "    conv1 = Conv1D(filters=16,kernel_size=3,strides=1,activation='relu', padding='same')(inp_sentence_vectors)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv2 = Conv1D(filters=32,kernel_size=3,strides=1,activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    sent_sa_feat_1, sent_beta_1, sent_gamma_1 = SelfAttention(int(conv2.shape[-1]), name = 'sa1')(conv2)\n",
    "    sent_sa_feat_2, sent_beta_2, sent_gamma_2 = SelfAttention(int(conv2.shape[-1]), name = 'sa2')(conv2)\n",
    "    sent_sa_feat_3, sent_beta_3, sent_gamma_3 = SelfAttention(int(conv2.shape[-1]), name = 'sa3')(conv2)\n",
    "    sent_sa_feat_4, sent_beta_4, sent_gamma_4 = SelfAttention(int(conv2.shape[-1]), name = 'sa4')(conv2)\n",
    "    concat1 = Concatenate()([sent_sa_feat_1,sent_sa_feat_2,sent_sa_feat_3,sent_sa_feat_4])\n",
    "    conv3 = Conv1D(filters=256,kernel_size=3, strides=1, activation='relu', padding='same')(concat1)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    headline = Dense(256, activation='relu')(inp_headline_vector)\n",
    "    headline = Lambda(lambda x:K.expand_dims(x, axis=1))(headline)\n",
    "    headline = BatchNormalization()(headline)\n",
    "    sent_hd_sa_feat_1, sent_hd_beta_1, sent_hd_gamma_1 = CrossAttention(int(conv3.shape[-1]), name = 'ca1')([headline,conv3])\n",
    "    sent_hd_sa_feat_2, sent_hd_beta_2, sent_hd_gamma_2 = CrossAttention(int(conv3.shape[-1]), name = 'ca2')([headline,conv3])\n",
    "    sent_hd_sa_feat_3, sent_hd_beta_3, sent_hd_gamma_3 = CrossAttention(int(conv3.shape[-1]), name = 'ca3')([headline,conv3])\n",
    "    sent_hd_sa_feat_4, sent_hd_beta_4, sent_hd_gamma_4 = CrossAttention(int(conv3.shape[-1]), name = 'ca4')([headline,conv3])  \n",
    "    concat3 = Concatenate()([sent_hd_sa_feat_1,sent_hd_sa_feat_2,sent_hd_sa_feat_3,sent_hd_sa_feat_4])\n",
    "    concat3 = Dropout(0.5)(concat3)\n",
    "    concat3 = BatchNormalization()(concat3)\n",
    "    conv5 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(concat3)\n",
    "    conv6 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv5)\n",
    "    conv7 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv6)\n",
    "    conv8 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv7)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    gap = GlobalAveragePooling1D()(conv8)\n",
    "    repeat = RepeatVector(50)(gap)\n",
    "    lstm1 = LSTM(256,return_sequences=True, activation='relu')(repeat)\n",
    "    lstm1 = Dropout(0.5)(lstm1)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    gen_hd_vector = TimeDistributed(Dense(20000,activation='softmax'), name='headline_token_classes')(lstm1)\n",
    "    model = Model([inp_sentence_vectors,inp_headline_vector],gen_hd_vector)\n",
    "    return model\n",
    "model = build_model()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001,beta_1=0.0,beta_2=0.99),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "# print('model params:',model.count_params())\n",
    "SVG(model_to_dot(model,show_layer_names=True,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now()\n",
    "mc = ModelCheckpoint('weights/dnf300_sa_sent_hd_word_gl.hdf5',save_best_only=True,save_weights_only=True)\n",
    "tb = TensorBoard(batch_size=32,log_dir='logs/dnf300_sa_sent_hd_word_gl/{0}'.format(dt.timestamp()),write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 9.9080 - acc: 0.0000e+00 - val_loss: 9.9093 - val_acc: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 9.9060 - acc: 0.0000e+00 - val_loss: 9.8768 - val_acc: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 9.8983 - acc: 0.0000e+00 - val_loss: 9.8522 - val_acc: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 2s 393ms/step - loss: 9.8903 - acc: 0.0000e+00 - val_loss: 9.8183 - val_acc: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 9.8832 - acc: 0.0011 - val_loss: 9.7706 - val_acc: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.8756 - acc: 0.0028 - val_loss: 9.6923 - val_acc: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.8611 - acc: 0.0037 - val_loss: 9.5561 - val_acc: 0.7350\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 9.8430 - acc: 0.0106 - val_loss: 9.3150 - val_acc: 0.7613\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.8018 - acc: 0.0609 - val_loss: 8.3826 - val_acc: 0.7588\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.8544 - acc: 0.0216 - val_loss: 9.5909 - val_acc: 0.6394\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.8145 - acc: 0.0786 - val_loss: 9.5421 - val_acc: 0.6369\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.7921 - acc: 0.1180 - val_loss: 9.6408 - val_acc: 0.5350\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 9.7781 - acc: 0.1716 - val_loss: 9.3265 - val_acc: 0.6875\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.7482 - acc: 0.2042 - val_loss: 11.4155 - val_acc: 0.2425\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.7319 - acc: 0.2492 - val_loss: 9.3576 - val_acc: 0.6869\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.7120 - acc: 0.2822 - val_loss: 8.5456 - val_acc: 0.6744\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.6845 - acc: 0.3008 - val_loss: 8.7800 - val_acc: 0.7063\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.6545 - acc: 0.3091 - val_loss: 8.6804 - val_acc: 0.6881\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.6505 - acc: 0.3589 - val_loss: 8.7129 - val_acc: 0.6875\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.6263 - acc: 0.3791 - val_loss: 8.5049 - val_acc: 0.6862\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.6139 - acc: 0.4189 - val_loss: 8.5420 - val_acc: 0.6706\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.6065 - acc: 0.4497 - val_loss: 8.5363 - val_acc: 0.6925\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.5900 - acc: 0.4547 - val_loss: 8.5226 - val_acc: 0.7013\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.5663 - acc: 0.4908 - val_loss: 8.5464 - val_acc: 0.6913\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.5485 - acc: 0.4955 - val_loss: 8.5051 - val_acc: 0.6894\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.5504 - acc: 0.5231 - val_loss: 8.5019 - val_acc: 0.7006\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.5165 - acc: 0.5217 - val_loss: 8.4933 - val_acc: 0.7000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.5022 - acc: 0.5295 - val_loss: 8.4823 - val_acc: 0.6844\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.4848 - acc: 0.5539 - val_loss: 8.4565 - val_acc: 0.6844\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.4740 - acc: 0.5541 - val_loss: 8.4272 - val_acc: 0.6913\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.4586 - acc: 0.5575 - val_loss: 8.3934 - val_acc: 0.7006\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.4299 - acc: 0.5545 - val_loss: 8.3803 - val_acc: 0.6963\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.3914 - acc: 0.5753 - val_loss: 8.3889 - val_acc: 0.6944\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.4046 - acc: 0.5856 - val_loss: 8.3724 - val_acc: 0.6900\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.3750 - acc: 0.5938 - val_loss: 8.2821 - val_acc: 0.7144\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.3384 - acc: 0.5903 - val_loss: 8.2760 - val_acc: 0.7025\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.3351 - acc: 0.5984 - val_loss: 8.2328 - val_acc: 0.7206\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.3025 - acc: 0.6042 - val_loss: 8.2564 - val_acc: 0.7150\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 9.2990 - acc: 0.6106 - val_loss: 8.2128 - val_acc: 0.6969\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.2377 - acc: 0.6186 - val_loss: 8.0821 - val_acc: 0.7188\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.2344 - acc: 0.6230 - val_loss: 8.1221 - val_acc: 0.7244\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.2004 - acc: 0.6230 - val_loss: 10.7205 - val_acc: 0.4381\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.1661 - acc: 0.6380 - val_loss: 8.0788 - val_acc: 0.7269\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.1462 - acc: 0.6394 - val_loss: 8.1315 - val_acc: 0.7031\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.1217 - acc: 0.6439 - val_loss: 8.0133 - val_acc: 0.6919\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.0738 - acc: 0.6448 - val_loss: 7.9890 - val_acc: 0.7169\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.0521 - acc: 0.6555 - val_loss: 7.9866 - val_acc: 0.7287\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 9.0215 - acc: 0.6659 - val_loss: 7.9231 - val_acc: 0.7456\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.0211 - acc: 0.6531 - val_loss: 4.6814 - val_acc: 0.7419\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 9.1129 - acc: 0.6603 - val_loss: 8.0842 - val_acc: 0.7200\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 8.9573 - acc: 0.6722 - val_loss: 8.2038 - val_acc: 0.7287\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 8.9892 - acc: 0.6784 - val_loss: 8.2164 - val_acc: 0.7356\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 8.9046 - acc: 0.6802 - val_loss: 8.2784 - val_acc: 0.7206\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 8.8930 - acc: 0.6858 - val_loss: 8.2360 - val_acc: 0.7400\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 8.8666 - acc: 0.6833 - val_loss: 8.2642 - val_acc: 0.7406\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.8308 - acc: 0.6867 - val_loss: 8.2894 - val_acc: 0.7256\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 8.7884 - acc: 0.6808 - val_loss: 8.2868 - val_acc: 0.7200\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 8.7885 - acc: 0.6895 - val_loss: 5.3340 - val_acc: 0.7275\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.7828 - acc: 0.6877 - val_loss: 8.2407 - val_acc: 0.7569\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.7223 - acc: 0.6909 - val_loss: 8.2519 - val_acc: 0.7344\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 8.6904 - acc: 0.6869 - val_loss: 8.2663 - val_acc: 0.7350\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 8.6776 - acc: 0.6859 - val_loss: 8.2574 - val_acc: 0.7425\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.6404 - acc: 0.6941 - val_loss: 8.1678 - val_acc: 0.7450\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.5943 - acc: 0.7009 - val_loss: 8.1834 - val_acc: 0.7469\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.5355 - acc: 0.7012 - val_loss: 8.1595 - val_acc: 0.7269\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.5302 - acc: 0.6931 - val_loss: 8.1391 - val_acc: 0.7412\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.5013 - acc: 0.6934 - val_loss: 8.1138 - val_acc: 0.7306\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.4652 - acc: 0.6927 - val_loss: 8.1014 - val_acc: 0.7456\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.4780 - acc: 0.6969 - val_loss: 8.0714 - val_acc: 0.7500\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.4173 - acc: 0.6988 - val_loss: 8.1007 - val_acc: 0.7300\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.3673 - acc: 0.7045 - val_loss: 8.0601 - val_acc: 0.7550\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.3668 - acc: 0.6998 - val_loss: 8.0674 - val_acc: 0.7344\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.3194 - acc: 0.7017 - val_loss: 8.0829 - val_acc: 0.7312\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 8.2953 - acc: 0.6953 - val_loss: 7.9925 - val_acc: 0.7362\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.2510 - acc: 0.6948 - val_loss: 7.9472 - val_acc: 0.7519\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.2355 - acc: 0.6898 - val_loss: 8.1209 - val_acc: 0.7481\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.2005 - acc: 0.6980 - val_loss: 7.8951 - val_acc: 0.7344\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.1730 - acc: 0.6897 - val_loss: 7.8065 - val_acc: 0.7437\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.1168 - acc: 0.7059 - val_loss: 7.8401 - val_acc: 0.7350\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.1250 - acc: 0.6881 - val_loss: 7.7501 - val_acc: 0.7256\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.0398 - acc: 0.6959 - val_loss: 7.7096 - val_acc: 0.7337\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.0610 - acc: 0.6928 - val_loss: 7.7012 - val_acc: 0.7469\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 8.0055 - acc: 0.6903 - val_loss: 7.6555 - val_acc: 0.7469\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 8.0143 - acc: 0.6872 - val_loss: 7.6131 - val_acc: 0.7381\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 7.9494 - acc: 0.6867 - val_loss: 7.7636 - val_acc: 0.7294\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 7.9081 - acc: 0.6884 - val_loss: 7.7092 - val_acc: 0.7381\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 7.8873 - acc: 0.6897 - val_loss: 7.7132 - val_acc: 0.7513\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 7.8186 - acc: 0.6831 - val_loss: 7.5610 - val_acc: 0.7306\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 7.8212 - acc: 0.6884 - val_loss: 7.5855 - val_acc: 0.7300\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.7756 - acc: 0.6858 - val_loss: 7.5674 - val_acc: 0.7262\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.7463 - acc: 0.6841 - val_loss: 7.4522 - val_acc: 0.7156\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 7.7308 - acc: 0.6875 - val_loss: 7.4561 - val_acc: 0.7188\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 7.6998 - acc: 0.6850 - val_loss: 7.5543 - val_acc: 0.7281\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 7.6450 - acc: 0.6933 - val_loss: 7.6030 - val_acc: 0.7412\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.6425 - acc: 0.6819 - val_loss: 7.6894 - val_acc: 0.7231\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.5982 - acc: 0.6928 - val_loss: 7.5001 - val_acc: 0.7375\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.5626 - acc: 0.6833 - val_loss: 5.4395 - val_acc: 0.7400\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.5484 - acc: 0.6852 - val_loss: 7.5050 - val_acc: 0.7256\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.4964 - acc: 0.6845 - val_loss: 7.6024 - val_acc: 0.7300\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.5065 - acc: 0.6784 - val_loss: 7.4908 - val_acc: 0.7556\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.4704 - acc: 0.6833 - val_loss: 7.4921 - val_acc: 0.7456\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.4033 - acc: 0.6841 - val_loss: 7.4622 - val_acc: 0.7356\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 7.3852 - acc: 0.6881 - val_loss: 7.5380 - val_acc: 0.7244\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.3517 - acc: 0.6752 - val_loss: 7.5388 - val_acc: 0.7094\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 7.3268 - acc: 0.6803 - val_loss: 7.4125 - val_acc: 0.7244\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.3071 - acc: 0.6852 - val_loss: 7.5186 - val_acc: 0.7181\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.2295 - acc: 0.6758 - val_loss: 7.5149 - val_acc: 0.7275\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 7.2224 - acc: 0.6866 - val_loss: 7.4870 - val_acc: 0.7200\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 7.1597 - acc: 0.6803 - val_loss: 7.4637 - val_acc: 0.7163\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 7.1894 - acc: 0.6719 - val_loss: 4.1505 - val_acc: 0.7225\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.1478 - acc: 0.6747 - val_loss: 7.2297 - val_acc: 0.7250\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 7.1060 - acc: 0.6752 - val_loss: 7.2884 - val_acc: 0.7312\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.1163 - acc: 0.6673 - val_loss: 7.2697 - val_acc: 0.7412\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.1109 - acc: 0.6767 - val_loss: 7.2138 - val_acc: 0.7319\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.9976 - acc: 0.6758 - val_loss: 7.1579 - val_acc: 0.7444\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.9496 - acc: 0.6744 - val_loss: 7.1850 - val_acc: 0.7256\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.9574 - acc: 0.6733 - val_loss: 7.2216 - val_acc: 0.7038\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.8981 - acc: 0.6755 - val_loss: 7.1851 - val_acc: 0.7237\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 6.8192 - acc: 0.6747 - val_loss: 7.2144 - val_acc: 0.7300\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.8158 - acc: 0.6642 - val_loss: 7.2143 - val_acc: 0.7169\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.8141 - acc: 0.6677 - val_loss: 7.2640 - val_acc: 0.7200\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.7765 - acc: 0.6633 - val_loss: 7.2910 - val_acc: 0.7181\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.7348 - acc: 0.6741 - val_loss: 7.2593 - val_acc: 0.6913\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.7090 - acc: 0.6609 - val_loss: 7.2294 - val_acc: 0.7212\n",
      "Epoch 125/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 3s/step - loss: 6.6490 - acc: 0.6734 - val_loss: 7.1490 - val_acc: 0.7156\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.6339 - acc: 0.6781 - val_loss: 7.1092 - val_acc: 0.7150\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.6175 - acc: 0.6686 - val_loss: 7.1191 - val_acc: 0.7138\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.5493 - acc: 0.6705 - val_loss: 7.1076 - val_acc: 0.7113\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.5358 - acc: 0.6600 - val_loss: 6.9412 - val_acc: 0.7144\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 6.5145 - acc: 0.6683 - val_loss: 6.9676 - val_acc: 0.7188\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.4790 - acc: 0.6713 - val_loss: 7.0416 - val_acc: 0.7244\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.4291 - acc: 0.6733 - val_loss: 7.0295 - val_acc: 0.7237\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.4295 - acc: 0.6647 - val_loss: 6.8892 - val_acc: 0.7138\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 6.3628 - acc: 0.6737 - val_loss: 6.9554 - val_acc: 0.7244\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.3166 - acc: 0.6741 - val_loss: 6.9286 - val_acc: 0.7156\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.3164 - acc: 0.6705 - val_loss: 6.8075 - val_acc: 0.7262\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 6.2536 - acc: 0.6695 - val_loss: 6.8016 - val_acc: 0.6931\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 6.2121 - acc: 0.6794 - val_loss: 6.9022 - val_acc: 0.7275\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 6.1645 - acc: 0.6698 - val_loss: 6.8510 - val_acc: 0.7094\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 6.0724 - acc: 0.6766 - val_loss: 6.9952 - val_acc: 0.7038\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 6.0762 - acc: 0.6637 - val_loss: 6.9432 - val_acc: 0.7212\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 6.0200 - acc: 0.6772 - val_loss: 6.8235 - val_acc: 0.7056\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5.9773 - acc: 0.6772 - val_loss: 6.7801 - val_acc: 0.7262\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 5.9265 - acc: 0.6744 - val_loss: 6.8611 - val_acc: 0.7125\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 5.8879 - acc: 0.6709 - val_loss: 6.8192 - val_acc: 0.7200\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 5.8475 - acc: 0.6758 - val_loss: 6.6384 - val_acc: 0.7275\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 5.8493 - acc: 0.6733 - val_loss: 6.6100 - val_acc: 0.7188\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 5.8133 - acc: 0.6767 - val_loss: 6.4982 - val_acc: 0.7025\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 5.7812 - acc: 0.6791 - val_loss: 6.4328 - val_acc: 0.7094\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 5.7629 - acc: 0.6700 - val_loss: 6.5131 - val_acc: 0.7144\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5.7166 - acc: 0.6758 - val_loss: 6.3389 - val_acc: 0.7156\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6244 - acc: 0.6791 - val_loss: 6.5208 - val_acc: 0.7119\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 5.6309 - acc: 0.6681 - val_loss: 6.4274 - val_acc: 0.7094\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 5.6484 - acc: 0.6659 - val_loss: 6.2291 - val_acc: 0.7212\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5744 - acc: 0.6733 - val_loss: 6.3525 - val_acc: 0.7212\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5.5011 - acc: 0.6875 - val_loss: 6.3290 - val_acc: 0.7200\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5.4954 - acc: 0.6916 - val_loss: 6.1844 - val_acc: 0.7119\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5.4802 - acc: 0.6778 - val_loss: 5.8972 - val_acc: 0.7281\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5663 - acc: 0.6872 - val_loss: 4.2537 - val_acc: 0.6731\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.9088 - acc: 0.6828 - val_loss: 5.2968 - val_acc: 0.7144\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.7745 - acc: 0.6816 - val_loss: 6.0495 - val_acc: 0.7131\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.7080 - acc: 0.6866 - val_loss: 6.1341 - val_acc: 0.7125\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6805 - acc: 0.6906 - val_loss: 6.0486 - val_acc: 0.7256\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6191 - acc: 0.6998 - val_loss: 6.0096 - val_acc: 0.7119\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6149 - acc: 0.6784 - val_loss: 6.1623 - val_acc: 0.7069\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5.5585 - acc: 0.6914 - val_loss: 5.8784 - val_acc: 0.7225\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5288 - acc: 0.6919 - val_loss: 5.9242 - val_acc: 0.7262\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.4873 - acc: 0.6886 - val_loss: 5.9363 - val_acc: 0.7156\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 5.4467 - acc: 0.6867 - val_loss: 5.9520 - val_acc: 0.7125\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3801 - acc: 0.6994 - val_loss: 5.9431 - val_acc: 0.7038\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3774 - acc: 0.6900 - val_loss: 5.8464 - val_acc: 0.7206\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3368 - acc: 0.6889 - val_loss: 5.5958 - val_acc: 0.7419\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.2629 - acc: 0.6989 - val_loss: 5.7352 - val_acc: 0.7231\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.2703 - acc: 0.6848 - val_loss: 5.7239 - val_acc: 0.7300\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.2801 - acc: 0.6842 - val_loss: 5.7631 - val_acc: 0.7163\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5.1979 - acc: 0.6881 - val_loss: 5.6889 - val_acc: 0.7237\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.2036 - acc: 0.6864 - val_loss: 5.7123 - val_acc: 0.7131\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1628 - acc: 0.6898 - val_loss: 5.6506 - val_acc: 0.7188\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9919 - acc: 0.6931 - val_loss: 5.6707 - val_acc: 0.7081\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0256 - acc: 0.6845 - val_loss: 5.5655 - val_acc: 0.7300\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9247 - acc: 0.6945 - val_loss: 5.5429 - val_acc: 0.7294\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.9792 - acc: 0.6763 - val_loss: 5.5372 - val_acc: 0.7262\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8879 - acc: 0.6938 - val_loss: 5.5659 - val_acc: 0.7019\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.9168 - acc: 0.6819 - val_loss: 5.4590 - val_acc: 0.7106\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.8147 - acc: 0.6997 - val_loss: 5.4742 - val_acc: 0.7144\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.7954 - acc: 0.6934 - val_loss: 5.4266 - val_acc: 0.7356\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8023 - acc: 0.6866 - val_loss: 5.3640 - val_acc: 0.7244\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7434 - acc: 0.6917 - val_loss: 5.3825 - val_acc: 0.7075\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7684 - acc: 0.6856 - val_loss: 5.2639 - val_acc: 0.7281\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7634 - acc: 0.6828 - val_loss: 5.2633 - val_acc: 0.7237\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6965 - acc: 0.6911 - val_loss: 5.2008 - val_acc: 0.7256\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.6384 - acc: 0.6981 - val_loss: 5.3187 - val_acc: 0.7125\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6440 - acc: 0.6892 - val_loss: 5.4469 - val_acc: 0.6919\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5797 - acc: 0.6973 - val_loss: 5.1761 - val_acc: 0.7200\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5463 - acc: 0.7017 - val_loss: 5.1487 - val_acc: 0.7206\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5342 - acc: 0.6927 - val_loss: 5.0622 - val_acc: 0.7119\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.5293 - acc: 0.7075 - val_loss: 4.9820 - val_acc: 0.7188\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.4795 - acc: 0.7077 - val_loss: 4.9745 - val_acc: 0.7394\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5823 - acc: 0.6909 - val_loss: 5.0566 - val_acc: 0.7256\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4585 - acc: 0.6967 - val_loss: 5.0222 - val_acc: 0.7250\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4527 - acc: 0.6989 - val_loss: 4.8182 - val_acc: 0.7425\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3392 - acc: 0.7056 - val_loss: 4.9766 - val_acc: 0.7331\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.4171 - acc: 0.7077 - val_loss: 4.9968 - val_acc: 0.7256\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.4200 - acc: 0.6941 - val_loss: 4.9765 - val_acc: 0.7362\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2784 - acc: 0.7078 - val_loss: 4.9154 - val_acc: 0.7381\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3051 - acc: 0.7003 - val_loss: 4.9807 - val_acc: 0.7194\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 4.2752 - acc: 0.7111 - val_loss: 4.9636 - val_acc: 0.7256\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2496 - acc: 0.7034 - val_loss: 4.8578 - val_acc: 0.7306\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.2103 - acc: 0.7141 - val_loss: 4.8986 - val_acc: 0.7375\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2359 - acc: 0.7070 - val_loss: 4.7972 - val_acc: 0.7269\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.3287 - acc: 0.7056 - val_loss: 4.6720 - val_acc: 0.7425\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3101 - acc: 0.7092 - val_loss: 3.4065 - val_acc: 0.7262\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.8925 - acc: 0.7045 - val_loss: 4.5999 - val_acc: 0.7244\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8492 - acc: 0.7184 - val_loss: 4.6741 - val_acc: 0.7394\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8748 - acc: 0.7034 - val_loss: 4.6356 - val_acc: 0.7356\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.7041 - acc: 0.7100 - val_loss: 4.7089 - val_acc: 0.7306\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.6559 - acc: 0.7095 - val_loss: 4.7298 - val_acc: 0.7306\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5835 - acc: 0.7159 - val_loss: 4.8025 - val_acc: 0.7387\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5971 - acc: 0.7088 - val_loss: 4.7316 - val_acc: 0.7400\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4839 - acc: 0.7170 - val_loss: 4.6641 - val_acc: 0.7356\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.4287 - acc: 0.7148 - val_loss: 4.6631 - val_acc: 0.7231\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5275 - acc: 0.6966 - val_loss: 4.5435 - val_acc: 0.7444\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4565 - acc: 0.7053 - val_loss: 4.6492 - val_acc: 0.7394\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4132 - acc: 0.7094 - val_loss: 4.6849 - val_acc: 0.7369\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3511 - acc: 0.7095 - val_loss: 4.7311 - val_acc: 0.7044\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4624 - acc: 0.7002 - val_loss: 4.7013 - val_acc: 0.7287\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.1853 - acc: 0.7067 - val_loss: 4.6829 - val_acc: 0.7325\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2840 - acc: 0.6977 - val_loss: 4.5697 - val_acc: 0.7306\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.1517 - acc: 0.7102 - val_loss: 4.6157 - val_acc: 0.7325\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2107 - acc: 0.7117 - val_loss: 4.5983 - val_acc: 0.7131\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.1634 - acc: 0.7158 - val_loss: 4.6185 - val_acc: 0.7381\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2206 - acc: 0.6981 - val_loss: 4.6361 - val_acc: 0.7156\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.0740 - acc: 0.7192 - val_loss: 4.3787 - val_acc: 0.7487\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.1096 - acc: 0.7114 - val_loss: 4.4995 - val_acc: 0.7156\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.0409 - acc: 0.7041 - val_loss: 4.4092 - val_acc: 0.7406\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0257 - acc: 0.7062 - val_loss: 4.4688 - val_acc: 0.7419\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9791 - acc: 0.7120 - val_loss: 4.4442 - val_acc: 0.7325\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9051 - acc: 0.7014 - val_loss: 4.4033 - val_acc: 0.7462\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.8881 - acc: 0.7145 - val_loss: 4.4147 - val_acc: 0.7294\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8647 - acc: 0.7184 - val_loss: 4.4328 - val_acc: 0.7219\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8401 - acc: 0.7136 - val_loss: 4.2840 - val_acc: 0.7281\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8698 - acc: 0.7116 - val_loss: 4.1894 - val_acc: 0.7462\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8048 - acc: 0.7116 - val_loss: 4.3225 - val_acc: 0.7306\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7361 - acc: 0.7191 - val_loss: 4.2957 - val_acc: 0.7387\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7412 - acc: 0.7163 - val_loss: 4.3368 - val_acc: 0.7138\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7939 - acc: 0.7053 - val_loss: 4.2544 - val_acc: 0.7331\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7319 - acc: 0.7073 - val_loss: 4.2284 - val_acc: 0.7262\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.6457 - acc: 0.7156 - val_loss: 4.1241 - val_acc: 0.7419\n",
      "Epoch 249/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 3.6325 - acc: 0.7156 - val_loss: 4.1483 - val_acc: 0.7119\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6408 - acc: 0.7141 - val_loss: 4.1943 - val_acc: 0.7156\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7221 - acc: 0.6962 - val_loss: 4.1652 - val_acc: 0.7244\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6085 - acc: 0.7073 - val_loss: 4.2263 - val_acc: 0.7150\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5299 - acc: 0.7153 - val_loss: 4.0279 - val_acc: 0.7406\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5157 - acc: 0.7158 - val_loss: 3.9443 - val_acc: 0.7444\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5167 - acc: 0.7086 - val_loss: 4.1098 - val_acc: 0.7381\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4688 - acc: 0.7191 - val_loss: 4.0528 - val_acc: 0.7144\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5118 - acc: 0.7108 - val_loss: 3.9577 - val_acc: 0.7325\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5085 - acc: 0.7136 - val_loss: 4.0843 - val_acc: 0.7206\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4298 - acc: 0.7041 - val_loss: 3.9225 - val_acc: 0.7312\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4202 - acc: 0.7173 - val_loss: 3.9363 - val_acc: 0.7456\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5035 - acc: 0.7203 - val_loss: 3.9102 - val_acc: 0.7300\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.4050 - acc: 0.7217 - val_loss: 3.8718 - val_acc: 0.7444\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.3272 - acc: 0.7194 - val_loss: 3.8125 - val_acc: 0.7450\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3895 - acc: 0.7112 - val_loss: 3.7974 - val_acc: 0.7369\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.3616 - acc: 0.7139 - val_loss: 3.8552 - val_acc: 0.7131\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.3898 - acc: 0.7100 - val_loss: 3.8461 - val_acc: 0.7231\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3219 - acc: 0.7108 - val_loss: 3.8167 - val_acc: 0.7138\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3100 - acc: 0.7166 - val_loss: 3.6745 - val_acc: 0.7400\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2584 - acc: 0.7161 - val_loss: 3.6711 - val_acc: 0.7244\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2382 - acc: 0.7222 - val_loss: 3.5885 - val_acc: 0.7444\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2943 - acc: 0.7162 - val_loss: 3.4974 - val_acc: 0.7469\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2043 - acc: 0.7203 - val_loss: 3.6850 - val_acc: 0.7319\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1765 - acc: 0.7244 - val_loss: 3.4399 - val_acc: 0.7625\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2745 - acc: 0.7077 - val_loss: 3.5442 - val_acc: 0.7394\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.2043 - acc: 0.7117 - val_loss: 3.5909 - val_acc: 0.7369\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.1583 - acc: 0.7205 - val_loss: 3.4356 - val_acc: 0.7400\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1359 - acc: 0.7153 - val_loss: 3.6363 - val_acc: 0.7206\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.1075 - acc: 0.7183 - val_loss: 3.4605 - val_acc: 0.7462\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2024 - acc: 0.7069 - val_loss: 3.5479 - val_acc: 0.7437\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1568 - acc: 0.7066 - val_loss: 3.6212 - val_acc: 0.7200\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.0372 - acc: 0.7288 - val_loss: 3.4601 - val_acc: 0.7281\n",
      "Epoch 282/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1091 - acc: 0.7163 - val_loss: 3.4263 - val_acc: 0.7312\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.0823 - acc: 0.7209 - val_loss: 3.4693 - val_acc: 0.7375\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 3.0441 - acc: 0.7252 - val_loss: 2.8836 - val_acc: 0.7475\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2000 - acc: 0.7239 - val_loss: 3.3878 - val_acc: 0.7244\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1229 - acc: 0.7252 - val_loss: 3.4174 - val_acc: 0.7244\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.1667 - acc: 0.7112 - val_loss: 3.3261 - val_acc: 0.7431\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.0833 - acc: 0.7198 - val_loss: 3.4308 - val_acc: 0.7231\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 3.0014 - acc: 0.7256 - val_loss: 3.3177 - val_acc: 0.7337\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.9800 - acc: 0.7238 - val_loss: 3.2833 - val_acc: 0.7362\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.0504 - acc: 0.7155 - val_loss: 3.3340 - val_acc: 0.7425\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.0202 - acc: 0.7141 - val_loss: 3.1849 - val_acc: 0.7625\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.9979 - acc: 0.7177 - val_loss: 3.4041 - val_acc: 0.7138\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.9697 - acc: 0.7172 - val_loss: 3.2714 - val_acc: 0.7231\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.9199 - acc: 0.7227 - val_loss: 3.3557 - val_acc: 0.7369\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.8506 - acc: 0.7317 - val_loss: 3.1868 - val_acc: 0.7437\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8438 - acc: 0.7278 - val_loss: 3.2879 - val_acc: 0.7412\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.8303 - acc: 0.7320 - val_loss: 3.2819 - val_acc: 0.7169\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.8414 - acc: 0.7220 - val_loss: 3.2376 - val_acc: 0.7419\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8161 - acc: 0.7236 - val_loss: 3.2961 - val_acc: 0.7163\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8476 - acc: 0.7239 - val_loss: 3.1238 - val_acc: 0.7431\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8003 - acc: 0.7291 - val_loss: 3.2430 - val_acc: 0.7275\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7306 - acc: 0.7306 - val_loss: 3.1887 - val_acc: 0.7325\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7934 - acc: 0.7208 - val_loss: 3.2241 - val_acc: 0.7437\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.7438 - acc: 0.7309 - val_loss: 3.4046 - val_acc: 0.7163\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.8209 - acc: 0.7216 - val_loss: 3.1195 - val_acc: 0.7588\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7348 - acc: 0.7211 - val_loss: 3.1274 - val_acc: 0.7369\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7290 - acc: 0.7231 - val_loss: 3.1977 - val_acc: 0.7225\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6676 - acc: 0.7289 - val_loss: 3.1179 - val_acc: 0.7462\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7380 - acc: 0.7205 - val_loss: 3.0328 - val_acc: 0.7387\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6598 - acc: 0.7312 - val_loss: 3.0464 - val_acc: 0.7406\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7096 - acc: 0.7269 - val_loss: 3.0297 - val_acc: 0.7356\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8226 - acc: 0.7131 - val_loss: 3.0263 - val_acc: 0.7237\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7243 - acc: 0.7225 - val_loss: 2.9981 - val_acc: 0.7444\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5480 - acc: 0.7359 - val_loss: 2.8108 - val_acc: 0.7563\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6583 - acc: 0.7239 - val_loss: 2.9349 - val_acc: 0.7412\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6156 - acc: 0.7270 - val_loss: 3.0800 - val_acc: 0.7319\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5718 - acc: 0.7339 - val_loss: 3.0004 - val_acc: 0.7294\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6108 - acc: 0.7298 - val_loss: 2.8508 - val_acc: 0.7675\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6176 - acc: 0.7334 - val_loss: 2.8831 - val_acc: 0.7481\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4567 - acc: 0.7380 - val_loss: 2.7877 - val_acc: 0.7581\n",
      "Epoch 322/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6591 - acc: 0.7305 - val_loss: 2.8282 - val_acc: 0.7681\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5824 - acc: 0.7263 - val_loss: 2.7945 - val_acc: 0.7525\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5564 - acc: 0.7309 - val_loss: 2.8229 - val_acc: 0.7606\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5915 - acc: 0.7236 - val_loss: 2.8391 - val_acc: 0.7362\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6395 - acc: 0.7241 - val_loss: 2.8802 - val_acc: 0.7344\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6248 - acc: 0.7206 - val_loss: 2.7686 - val_acc: 0.7475\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.6167 - acc: 0.7288 - val_loss: 2.8525 - val_acc: 0.7400\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6110 - acc: 0.7234 - val_loss: 2.9112 - val_acc: 0.7262\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5638 - acc: 0.7269 - val_loss: 2.7574 - val_acc: 0.7500\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5173 - acc: 0.7345 - val_loss: 2.8480 - val_acc: 0.7387\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5719 - acc: 0.7214 - val_loss: 2.7685 - val_acc: 0.7437\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4859 - acc: 0.7344 - val_loss: 2.7557 - val_acc: 0.7475\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4489 - acc: 0.7416 - val_loss: 2.7568 - val_acc: 0.7406\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4024 - acc: 0.7427 - val_loss: 2.5873 - val_acc: 0.7675\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3781 - acc: 0.7450 - val_loss: 2.6442 - val_acc: 0.7506\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4003 - acc: 0.7358 - val_loss: 2.7715 - val_acc: 0.7456\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4748 - acc: 0.7291 - val_loss: 2.6608 - val_acc: 0.7531\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4091 - acc: 0.7342 - val_loss: 2.7150 - val_acc: 0.7456\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3899 - acc: 0.7352 - val_loss: 2.6492 - val_acc: 0.7538\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4006 - acc: 0.7264 - val_loss: 2.6248 - val_acc: 0.7481\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4128 - acc: 0.7267 - val_loss: 2.7375 - val_acc: 0.7219\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3410 - acc: 0.7398 - val_loss: 2.7192 - val_acc: 0.7312\n",
      "Epoch 344/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3113 - acc: 0.7370 - val_loss: 2.5916 - val_acc: 0.7519\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4018 - acc: 0.7288 - val_loss: 2.6699 - val_acc: 0.7544\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3051 - acc: 0.7395 - val_loss: 2.4143 - val_acc: 0.7731\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3105 - acc: 0.7436 - val_loss: 2.7557 - val_acc: 0.7362\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3730 - acc: 0.7369 - val_loss: 2.4517 - val_acc: 0.7575\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3305 - acc: 0.7400 - val_loss: 2.5290 - val_acc: 0.7375\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2689 - acc: 0.7455 - val_loss: 2.5150 - val_acc: 0.7569\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3508 - acc: 0.7381 - val_loss: 2.6265 - val_acc: 0.7600\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3588 - acc: 0.7233 - val_loss: 2.6853 - val_acc: 0.7319\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2920 - acc: 0.7380 - val_loss: 2.5948 - val_acc: 0.7556\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.2092 - acc: 0.7459 - val_loss: 2.5656 - val_acc: 0.7400\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3078 - acc: 0.7339 - val_loss: 2.4239 - val_acc: 0.7481\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3025 - acc: 0.7345 - val_loss: 2.3544 - val_acc: 0.7806\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4104 - acc: 0.7170 - val_loss: 2.4763 - val_acc: 0.7475\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3063 - acc: 0.7347 - val_loss: 2.6656 - val_acc: 0.7550\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2666 - acc: 0.7389 - val_loss: 6.3877 - val_acc: 0.5038\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3758 - acc: 0.7392 - val_loss: 2.7787 - val_acc: 0.7331\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5081 - acc: 0.7231 - val_loss: 2.5583 - val_acc: 0.7575\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2681 - acc: 0.7516 - val_loss: 2.6436 - val_acc: 0.7231\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3702 - acc: 0.7312 - val_loss: 2.6294 - val_acc: 0.7500\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3153 - acc: 0.7430 - val_loss: 2.4695 - val_acc: 0.7544\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4606 - acc: 0.7248 - val_loss: 2.3548 - val_acc: 0.7750\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4367 - acc: 0.7203 - val_loss: 2.5849 - val_acc: 0.7394\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2941 - acc: 0.7362 - val_loss: 2.5043 - val_acc: 0.7506\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3476 - acc: 0.7280 - val_loss: 2.4951 - val_acc: 0.7531\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1518 - acc: 0.7523 - val_loss: 2.3955 - val_acc: 0.7837\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2874 - acc: 0.7333 - val_loss: 2.3621 - val_acc: 0.7669\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2194 - acc: 0.7413 - val_loss: 2.4147 - val_acc: 0.7556\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2483 - acc: 0.7361 - val_loss: 2.5550 - val_acc: 0.7481\n",
      "Epoch 373/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.2230 - acc: 0.7364 - val_loss: 2.4730 - val_acc: 0.7475\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2432 - acc: 0.7377 - val_loss: 2.5765 - val_acc: 0.7387\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2040 - acc: 0.7412 - val_loss: 2.2147 - val_acc: 0.7931\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1811 - acc: 0.7467 - val_loss: 2.4076 - val_acc: 0.7731\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2012 - acc: 0.7378 - val_loss: 2.6059 - val_acc: 0.7437\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2238 - acc: 0.7387 - val_loss: 2.5378 - val_acc: 0.7431\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.1760 - acc: 0.7428 - val_loss: 2.3053 - val_acc: 0.7594\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1411 - acc: 0.7377 - val_loss: 2.3042 - val_acc: 0.7638\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2385 - acc: 0.7347 - val_loss: 2.3807 - val_acc: 0.7669\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1832 - acc: 0.7350 - val_loss: 2.7872 - val_acc: 0.7194\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2586 - acc: 0.7258 - val_loss: 2.4495 - val_acc: 0.7531\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1645 - acc: 0.7405 - val_loss: 2.5489 - val_acc: 0.7525\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1593 - acc: 0.7423 - val_loss: 2.5464 - val_acc: 0.7550\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2416 - acc: 0.7317 - val_loss: 2.6166 - val_acc: 0.7244\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0529 - acc: 0.7569 - val_loss: 2.5289 - val_acc: 0.7431\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0927 - acc: 0.7480 - val_loss: 2.4713 - val_acc: 0.7650\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2040 - acc: 0.7300 - val_loss: 2.4684 - val_acc: 0.7556\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1650 - acc: 0.7402 - val_loss: 2.3919 - val_acc: 0.7594\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1009 - acc: 0.7395 - val_loss: 2.4621 - val_acc: 0.7400\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1079 - acc: 0.7413 - val_loss: 2.3302 - val_acc: 0.7738\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1985 - acc: 0.7295 - val_loss: 2.4071 - val_acc: 0.7550\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1777 - acc: 0.7314 - val_loss: 2.4555 - val_acc: 0.7481\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0319 - acc: 0.7486 - val_loss: 2.2086 - val_acc: 0.7706\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9848 - acc: 0.7531 - val_loss: 2.2402 - val_acc: 0.7600\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1198 - acc: 0.7370 - val_loss: 2.3342 - val_acc: 0.7556\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0517 - acc: 0.7447 - val_loss: 2.2700 - val_acc: 0.7706\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0377 - acc: 0.7517 - val_loss: 2.1575 - val_acc: 0.7862\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1178 - acc: 0.7367 - val_loss: 2.1918 - val_acc: 0.7781\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1472 - acc: 0.7322 - val_loss: 2.3405 - val_acc: 0.7456\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0520 - acc: 0.7425 - val_loss: 2.5296 - val_acc: 0.7237\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9916 - acc: 0.7491 - val_loss: 2.4611 - val_acc: 0.7456\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9765 - acc: 0.7544 - val_loss: 2.2649 - val_acc: 0.7631\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0337 - acc: 0.7441 - val_loss: 2.1369 - val_acc: 0.7756\n",
      "Epoch 406/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.0607 - acc: 0.7403 - val_loss: 2.1641 - val_acc: 0.7694\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0101 - acc: 0.7534 - val_loss: 2.3043 - val_acc: 0.7369\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0163 - acc: 0.7433 - val_loss: 2.4190 - val_acc: 0.7400\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0793 - acc: 0.7328 - val_loss: 2.3177 - val_acc: 0.7544\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0513 - acc: 0.7442 - val_loss: 2.2517 - val_acc: 0.7531\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0811 - acc: 0.7350 - val_loss: 2.1226 - val_acc: 0.7812\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0101 - acc: 0.7391 - val_loss: 2.2234 - val_acc: 0.7638\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1010 - acc: 0.7275 - val_loss: 2.4101 - val_acc: 0.7475\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0416 - acc: 0.7406 - val_loss: 2.4765 - val_acc: 0.7456\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9760 - acc: 0.7431 - val_loss: 2.3939 - val_acc: 0.7356\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0346 - acc: 0.7406 - val_loss: 2.3948 - val_acc: 0.7394\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0913 - acc: 0.7331 - val_loss: 2.3177 - val_acc: 0.7575\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0899 - acc: 0.7384 - val_loss: 2.5871 - val_acc: 0.7200\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0535 - acc: 0.7375 - val_loss: 2.2986 - val_acc: 0.7469\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0579 - acc: 0.7414 - val_loss: 2.4635 - val_acc: 0.7362\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9812 - acc: 0.7444 - val_loss: 2.5243 - val_acc: 0.7244\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0191 - acc: 0.7433 - val_loss: 2.4864 - val_acc: 0.7487\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9736 - acc: 0.7433 - val_loss: 2.3280 - val_acc: 0.7437\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0161 - acc: 0.7378 - val_loss: 2.2167 - val_acc: 0.7669\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0031 - acc: 0.7417 - val_loss: 2.3526 - val_acc: 0.7681\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9810 - acc: 0.7416 - val_loss: 2.2494 - val_acc: 0.7619\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0348 - acc: 0.7380 - val_loss: 2.1651 - val_acc: 0.7688\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9567 - acc: 0.7398 - val_loss: 2.1924 - val_acc: 0.7544\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9783 - acc: 0.7398 - val_loss: 2.3634 - val_acc: 0.7494\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0427 - acc: 0.7338 - val_loss: 1.9599 - val_acc: 0.7975\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9177 - acc: 0.7498 - val_loss: 2.1681 - val_acc: 0.7788\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.0307 - acc: 0.7338 - val_loss: 2.1558 - val_acc: 0.7706\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0400 - acc: 0.7277 - val_loss: 2.2179 - val_acc: 0.7563\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9917 - acc: 0.7403 - val_loss: 2.3887 - val_acc: 0.7394\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9868 - acc: 0.7458 - val_loss: 2.2183 - val_acc: 0.7594\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0660 - acc: 0.7325 - val_loss: 2.2805 - val_acc: 0.7462\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9774 - acc: 0.7388 - val_loss: 2.2557 - val_acc: 0.7688\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9921 - acc: 0.7387 - val_loss: 2.2790 - val_acc: 0.7631\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8989 - acc: 0.7514 - val_loss: 2.1811 - val_acc: 0.7613\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9590 - acc: 0.7430 - val_loss: 2.1041 - val_acc: 0.7619\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9261 - acc: 0.7488 - val_loss: 2.2720 - val_acc: 0.7506\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9787 - acc: 0.7373 - val_loss: 1.9769 - val_acc: 0.7837\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9574 - acc: 0.7358 - val_loss: 2.1821 - val_acc: 0.7581\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9237 - acc: 0.7400 - val_loss: 2.1510 - val_acc: 0.7619\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9485 - acc: 0.7417 - val_loss: 2.1673 - val_acc: 0.7581\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9215 - acc: 0.7453 - val_loss: 2.0546 - val_acc: 0.7725\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8321 - acc: 0.7528 - val_loss: 2.1491 - val_acc: 0.7625\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8923 - acc: 0.7434 - val_loss: 2.1721 - val_acc: 0.7469\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9889 - acc: 0.7327 - val_loss: 2.0793 - val_acc: 0.7669\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9302 - acc: 0.7419 - val_loss: 2.1845 - val_acc: 0.7550\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9307 - acc: 0.7400 - val_loss: 2.1043 - val_acc: 0.7581\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8601 - acc: 0.7492 - val_loss: 2.1577 - val_acc: 0.7644\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8270 - acc: 0.7525 - val_loss: 2.2365 - val_acc: 0.7425\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9020 - acc: 0.7420 - val_loss: 1.9913 - val_acc: 0.7831\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8424 - acc: 0.7550 - val_loss: 2.0802 - val_acc: 0.7688\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8772 - acc: 0.7455 - val_loss: 2.1224 - val_acc: 0.7581\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9364 - acc: 0.7369 - val_loss: 2.2490 - val_acc: 0.7437\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8868 - acc: 0.7411 - val_loss: 2.2205 - val_acc: 0.7481\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8635 - acc: 0.7425 - val_loss: 2.2405 - val_acc: 0.7575\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9916 - acc: 0.7272 - val_loss: 2.2743 - val_acc: 0.7400\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9122 - acc: 0.7384 - val_loss: 2.2895 - val_acc: 0.7456\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8323 - acc: 0.7459 - val_loss: 2.1738 - val_acc: 0.7513\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8483 - acc: 0.7405 - val_loss: 2.1454 - val_acc: 0.7631\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8087 - acc: 0.7481 - val_loss: 1.8144 - val_acc: 0.7887\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9289 - acc: 0.7370 - val_loss: 2.1540 - val_acc: 0.7588\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8051 - acc: 0.7537 - val_loss: 2.1706 - val_acc: 0.7519\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8577 - acc: 0.7470 - val_loss: 2.2216 - val_acc: 0.7513\n",
      "Epoch 468/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8732 - acc: 0.7452 - val_loss: 2.1645 - val_acc: 0.7613\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9369 - acc: 0.7384 - val_loss: 2.1974 - val_acc: 0.7500\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8561 - acc: 0.7514 - val_loss: 1.9511 - val_acc: 0.7969\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9498 - acc: 0.7366 - val_loss: 2.1440 - val_acc: 0.7569\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7850 - acc: 0.7484 - val_loss: 2.0013 - val_acc: 0.7706\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8402 - acc: 0.7505 - val_loss: 2.3173 - val_acc: 0.7431\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8994 - acc: 0.7367 - val_loss: 2.1236 - val_acc: 0.7538\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8801 - acc: 0.7402 - val_loss: 2.1180 - val_acc: 0.7719\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9235 - acc: 0.7339 - val_loss: 2.0370 - val_acc: 0.7675\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8153 - acc: 0.7520 - val_loss: 2.3569 - val_acc: 0.7350\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8506 - acc: 0.7433 - val_loss: 2.2059 - val_acc: 0.7719\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8954 - acc: 0.7414 - val_loss: 2.1098 - val_acc: 0.7781\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9113 - acc: 0.7380 - val_loss: 2.1148 - val_acc: 0.7581\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8750 - acc: 0.7427 - val_loss: 2.0729 - val_acc: 0.7594\n",
      "Epoch 482/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7679 - acc: 0.7534 - val_loss: 2.1461 - val_acc: 0.7569\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8517 - acc: 0.7447 - val_loss: 1.9522 - val_acc: 0.7825\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9135 - acc: 0.7342 - val_loss: 1.9503 - val_acc: 0.7738\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8536 - acc: 0.7430 - val_loss: 2.0895 - val_acc: 0.7713\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8524 - acc: 0.7427 - val_loss: 2.2132 - val_acc: 0.7500\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8802 - acc: 0.7414 - val_loss: 2.2457 - val_acc: 0.7519\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8085 - acc: 0.7505 - val_loss: 2.0596 - val_acc: 0.7594\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8097 - acc: 0.7491 - val_loss: 2.1869 - val_acc: 0.7513\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8741 - acc: 0.7423 - val_loss: 2.0738 - val_acc: 0.7656\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8680 - acc: 0.7428 - val_loss: 2.1415 - val_acc: 0.7713\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9914 - acc: 0.7261 - val_loss: 2.3167 - val_acc: 0.7400\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9540 - acc: 0.7497 - val_loss: 2.4712 - val_acc: 0.7563\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0061 - acc: 0.7419 - val_loss: 2.0912 - val_acc: 0.7594\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9712 - acc: 0.7386 - val_loss: 2.2470 - val_acc: 0.7550\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8739 - acc: 0.7470 - val_loss: 2.0589 - val_acc: 0.7638\n",
      "Epoch 497/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.9690 - acc: 0.7342 - val_loss: 2.3251 - val_acc: 0.7394\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8431 - acc: 0.7495 - val_loss: 2.0081 - val_acc: 0.7594\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8761 - acc: 0.7439 - val_loss: 2.0874 - val_acc: 0.7569\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9073 - acc: 0.7353 - val_loss: 2.0354 - val_acc: 0.7725\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7930 - acc: 0.7562 - val_loss: 1.8128 - val_acc: 0.7881\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9046 - acc: 0.7359 - val_loss: 2.0714 - val_acc: 0.7638\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9631 - acc: 0.7250 - val_loss: 2.0932 - val_acc: 0.7475\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8762 - acc: 0.7378 - val_loss: 1.9358 - val_acc: 0.7744\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8598 - acc: 0.7359 - val_loss: 1.9183 - val_acc: 0.7819\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8555 - acc: 0.7408 - val_loss: 2.1573 - val_acc: 0.7475\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8590 - acc: 0.7397 - val_loss: 2.1223 - val_acc: 0.7556\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9250 - acc: 0.7305 - val_loss: 2.0725 - val_acc: 0.7550\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8297 - acc: 0.7417 - val_loss: 1.9314 - val_acc: 0.7781\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6556 - acc: 0.7648 - val_loss: 2.2529 - val_acc: 0.7475\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8146 - acc: 0.7420 - val_loss: 1.8574 - val_acc: 0.7856\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8118 - acc: 0.7491 - val_loss: 1.9973 - val_acc: 0.7750\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7566 - acc: 0.7492 - val_loss: 2.0006 - val_acc: 0.7663\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9053 - acc: 0.7317 - val_loss: 2.1667 - val_acc: 0.7437\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9026 - acc: 0.7341 - val_loss: 2.1197 - val_acc: 0.7631\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7452 - acc: 0.7575 - val_loss: 2.2556 - val_acc: 0.7519\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7985 - acc: 0.7514 - val_loss: 2.0415 - val_acc: 0.7713\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8558 - acc: 0.7428 - val_loss: 2.1029 - val_acc: 0.7500\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8822 - acc: 0.7358 - val_loss: 1.9925 - val_acc: 0.7631\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7187 - acc: 0.7577 - val_loss: 1.9754 - val_acc: 0.7669\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8484 - acc: 0.7386 - val_loss: 2.1632 - val_acc: 0.7563\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7233 - acc: 0.7533 - val_loss: 2.1740 - val_acc: 0.7475\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7851 - acc: 0.7442 - val_loss: 2.0453 - val_acc: 0.7613\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7236 - acc: 0.7598 - val_loss: 2.0788 - val_acc: 0.7575\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7800 - acc: 0.7441 - val_loss: 2.1721 - val_acc: 0.7569\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8301 - acc: 0.7394 - val_loss: 1.9354 - val_acc: 0.7750\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7258 - acc: 0.7502 - val_loss: 1.9305 - val_acc: 0.7831\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7774 - acc: 0.7453 - val_loss: 2.0605 - val_acc: 0.7706\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7010 - acc: 0.7552 - val_loss: 2.0754 - val_acc: 0.7581\n",
      "Epoch 530/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8833 - acc: 0.7317 - val_loss: 2.0012 - val_acc: 0.7788\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7961 - acc: 0.7475 - val_loss: 2.1047 - val_acc: 0.7656\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8687 - acc: 0.7377 - val_loss: 1.9736 - val_acc: 0.7769\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7204 - acc: 0.7580 - val_loss: 2.3883 - val_acc: 0.7331\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7826 - acc: 0.7453 - val_loss: 2.0295 - val_acc: 0.7656\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7647 - acc: 0.7488 - val_loss: 1.9487 - val_acc: 0.7688\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8181 - acc: 0.7363 - val_loss: 2.1396 - val_acc: 0.7531\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7881 - acc: 0.7450 - val_loss: 2.1523 - val_acc: 0.7556\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7454 - acc: 0.7506 - val_loss: 2.1804 - val_acc: 0.7425\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7346 - acc: 0.7489 - val_loss: 1.8761 - val_acc: 0.7887\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6750 - acc: 0.7583 - val_loss: 1.9606 - val_acc: 0.7719\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7417 - acc: 0.7475 - val_loss: 2.1371 - val_acc: 0.7519\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7135 - acc: 0.7522 - val_loss: 2.2458 - val_acc: 0.7412\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6621 - acc: 0.7614 - val_loss: 2.0476 - val_acc: 0.7625\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9344 - acc: 0.7247 - val_loss: 2.1069 - val_acc: 0.7594\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6654 - acc: 0.7605 - val_loss: 2.0662 - val_acc: 0.7600\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7231 - acc: 0.7523 - val_loss: 2.3594 - val_acc: 0.7300\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7303 - acc: 0.7502 - val_loss: 2.0044 - val_acc: 0.7688\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7907 - acc: 0.7427 - val_loss: 2.0785 - val_acc: 0.7619\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7916 - acc: 0.7378 - val_loss: 1.9902 - val_acc: 0.7725\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6396 - acc: 0.7605 - val_loss: 1.9946 - val_acc: 0.7688\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7499 - acc: 0.7456 - val_loss: 2.0737 - val_acc: 0.7625\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7912 - acc: 0.7402 - val_loss: 1.9854 - val_acc: 0.7700\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9203 - acc: 0.7233 - val_loss: 1.9817 - val_acc: 0.7706\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7555 - acc: 0.7395 - val_loss: 1.9102 - val_acc: 0.7731\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6721 - acc: 0.7573 - val_loss: 2.0322 - val_acc: 0.7669\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6300 - acc: 0.7598 - val_loss: 1.9344 - val_acc: 0.7738\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7902 - acc: 0.7417 - val_loss: 1.9007 - val_acc: 0.7844\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7914 - acc: 0.7389 - val_loss: 2.0102 - val_acc: 0.7731\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8075 - acc: 0.7350 - val_loss: 1.9980 - val_acc: 0.7613\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6789 - acc: 0.7488 - val_loss: 1.8849 - val_acc: 0.7763\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6774 - acc: 0.7555 - val_loss: 1.9627 - val_acc: 0.7656\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8810 - acc: 0.7264 - val_loss: 1.9193 - val_acc: 0.7812\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6969 - acc: 0.7522 - val_loss: 2.2397 - val_acc: 0.7437\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7322 - acc: 0.7470 - val_loss: 2.2017 - val_acc: 0.7531\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6031 - acc: 0.7605 - val_loss: 1.7437 - val_acc: 0.7950\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6920 - acc: 0.7511 - val_loss: 2.1541 - val_acc: 0.7469\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7765 - acc: 0.7448 - val_loss: 1.9127 - val_acc: 0.7812\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8169 - acc: 0.7341 - val_loss: 1.9766 - val_acc: 0.7656\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6769 - acc: 0.7530 - val_loss: 1.9310 - val_acc: 0.7794\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7100 - acc: 0.7470 - val_loss: 1.8450 - val_acc: 0.7869\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7843 - acc: 0.7395 - val_loss: 2.1102 - val_acc: 0.7475\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6323 - acc: 0.7569 - val_loss: 1.9930 - val_acc: 0.7775\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6905 - acc: 0.7484 - val_loss: 2.0154 - val_acc: 0.7694\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5743 - acc: 0.7627 - val_loss: 1.9179 - val_acc: 0.7738\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7802 - acc: 0.7392 - val_loss: 1.9814 - val_acc: 0.7688\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7600 - acc: 0.7441 - val_loss: 2.1621 - val_acc: 0.7569\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7501 - acc: 0.7392 - val_loss: 2.0677 - val_acc: 0.7569\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6120 - acc: 0.7602 - val_loss: 1.9992 - val_acc: 0.7763\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7170 - acc: 0.7462 - val_loss: 2.0737 - val_acc: 0.7588\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6980 - acc: 0.7487 - val_loss: 2.0077 - val_acc: 0.7731\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7589 - acc: 0.7369 - val_loss: 2.2235 - val_acc: 0.7469\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6436 - acc: 0.7553 - val_loss: 1.8398 - val_acc: 0.7887\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7400 - acc: 0.7448 - val_loss: 1.9929 - val_acc: 0.7563\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6254 - acc: 0.7570 - val_loss: 2.0104 - val_acc: 0.7694\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6930 - acc: 0.7522 - val_loss: 2.1873 - val_acc: 0.7538\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7198 - acc: 0.7455 - val_loss: 2.1382 - val_acc: 0.7519\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6305 - acc: 0.7591 - val_loss: 2.0143 - val_acc: 0.7638\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6581 - acc: 0.7559 - val_loss: 2.0252 - val_acc: 0.7719\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6624 - acc: 0.7502 - val_loss: 1.9749 - val_acc: 0.7625\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6577 - acc: 0.7536 - val_loss: 1.9359 - val_acc: 0.7781\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7504 - acc: 0.7387 - val_loss: 2.0679 - val_acc: 0.7675\n",
      "Epoch 592/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8284 - acc: 0.7278 - val_loss: 8.0245 - val_acc: 0.3850\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8235 - acc: 0.7341 - val_loss: 1.9672 - val_acc: 0.7756\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7032 - acc: 0.7456 - val_loss: 2.0085 - val_acc: 0.7738\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7689 - acc: 0.7402 - val_loss: 1.9499 - val_acc: 0.7756\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8188 - acc: 0.7323 - val_loss: 2.0929 - val_acc: 0.7556\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7693 - acc: 0.7452 - val_loss: 1.9563 - val_acc: 0.7719\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7237 - acc: 0.7494 - val_loss: 1.9178 - val_acc: 0.7769\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6672 - acc: 0.7547 - val_loss: 1.8875 - val_acc: 0.7819\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6266 - acc: 0.7606 - val_loss: 1.9455 - val_acc: 0.7744\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6607 - acc: 0.7528 - val_loss: 2.0499 - val_acc: 0.7650\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6686 - acc: 0.7505 - val_loss: 2.0217 - val_acc: 0.7606\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6501 - acc: 0.7514 - val_loss: 1.9259 - val_acc: 0.7700\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6420 - acc: 0.7538 - val_loss: 1.9887 - val_acc: 0.7706\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8153 - acc: 0.7348 - val_loss: 2.1733 - val_acc: 0.7444\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7760 - acc: 0.7356 - val_loss: 1.8366 - val_acc: 0.7769\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7544 - acc: 0.7378 - val_loss: 2.2095 - val_acc: 0.7437\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6396 - acc: 0.7517 - val_loss: 1.8369 - val_acc: 0.7812\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6624 - acc: 0.7455 - val_loss: 2.4050 - val_acc: 0.7350\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7203 - acc: 0.7384 - val_loss: 2.1424 - val_acc: 0.7581\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8587 - acc: 0.7339 - val_loss: 2.0151 - val_acc: 0.7669\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6672 - acc: 0.7533 - val_loss: 2.2153 - val_acc: 0.7569\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7904 - acc: 0.7389 - val_loss: 1.9082 - val_acc: 0.7731\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6705 - acc: 0.7525 - val_loss: 2.2390 - val_acc: 0.7412\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8164 - acc: 0.7333 - val_loss: 1.8784 - val_acc: 0.7856\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7036 - acc: 0.7500 - val_loss: 2.0559 - val_acc: 0.7575\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7192 - acc: 0.7414 - val_loss: 2.2145 - val_acc: 0.7588\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7632 - acc: 0.7387 - val_loss: 1.7823 - val_acc: 0.8000\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8323 - acc: 0.7306 - val_loss: 1.9721 - val_acc: 0.7769\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7828 - acc: 0.7334 - val_loss: 1.9463 - val_acc: 0.7812\n",
      "Epoch 621/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7430 - acc: 0.7419 - val_loss: 2.1729 - val_acc: 0.7544\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6691 - acc: 0.7492 - val_loss: 2.2008 - val_acc: 0.7563\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7887 - acc: 0.7352 - val_loss: 1.9412 - val_acc: 0.7750\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6828 - acc: 0.7473 - val_loss: 1.9444 - val_acc: 0.7738\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6857 - acc: 0.7441 - val_loss: 1.7146 - val_acc: 0.8056\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6652 - acc: 0.7506 - val_loss: 2.0981 - val_acc: 0.7619\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8304 - acc: 0.7289 - val_loss: 1.8022 - val_acc: 0.7956\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6466 - acc: 0.7550 - val_loss: 2.0195 - val_acc: 0.7700\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6714 - acc: 0.7492 - val_loss: 2.1893 - val_acc: 0.7581\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6935 - acc: 0.7478 - val_loss: 2.2599 - val_acc: 0.7300\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5813 - acc: 0.7586 - val_loss: 1.8669 - val_acc: 0.7812\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5604 - acc: 0.7636 - val_loss: 2.1664 - val_acc: 0.7550\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6996 - acc: 0.7453 - val_loss: 2.0098 - val_acc: 0.7669\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6470 - acc: 0.7484 - val_loss: 1.7952 - val_acc: 0.8000\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7056 - acc: 0.7417 - val_loss: 2.0292 - val_acc: 0.7681\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6611 - acc: 0.7494 - val_loss: 2.1586 - val_acc: 0.7600\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7127 - acc: 0.7386 - val_loss: 1.9765 - val_acc: 0.7725\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7021 - acc: 0.7433 - val_loss: 2.2057 - val_acc: 0.7525\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7095 - acc: 0.7417 - val_loss: 2.0762 - val_acc: 0.7644\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6908 - acc: 0.7472 - val_loss: 1.9764 - val_acc: 0.7812\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6380 - acc: 0.7491 - val_loss: 1.9575 - val_acc: 0.7775\n",
      "Epoch 642/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7350 - acc: 0.7352 - val_loss: 2.0018 - val_acc: 0.7725\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6961 - acc: 0.7427 - val_loss: 2.1362 - val_acc: 0.7569\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6991 - acc: 0.7391 - val_loss: 2.1164 - val_acc: 0.7613\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6393 - acc: 0.7461 - val_loss: 1.8919 - val_acc: 0.7781\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7419 - acc: 0.7372 - val_loss: 2.2438 - val_acc: 0.7412\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6750 - acc: 0.7458 - val_loss: 2.0164 - val_acc: 0.7688\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7107 - acc: 0.7475 - val_loss: 1.9517 - val_acc: 0.7744\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6285 - acc: 0.7552 - val_loss: 2.0699 - val_acc: 0.7706\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7187 - acc: 0.7394 - val_loss: 2.3094 - val_acc: 0.7700\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6654 - acc: 0.7516 - val_loss: 2.1333 - val_acc: 0.7619\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6587 - acc: 0.7494 - val_loss: 2.1221 - val_acc: 0.7631\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6669 - acc: 0.7547 - val_loss: 2.4409 - val_acc: 0.7212\n",
      "Epoch 654/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6460 - acc: 0.7530 - val_loss: 1.9998 - val_acc: 0.7713\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6280 - acc: 0.7555 - val_loss: 1.9289 - val_acc: 0.7769\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5901 - acc: 0.7580 - val_loss: 2.0669 - val_acc: 0.7681\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7355 - acc: 0.7472 - val_loss: 2.1206 - val_acc: 0.7600\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7807 - acc: 0.7433 - val_loss: 1.9449 - val_acc: 0.7756\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7484 - acc: 0.7466 - val_loss: 2.0827 - val_acc: 0.7625\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7681 - acc: 0.7434 - val_loss: 1.9325 - val_acc: 0.7738\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7010 - acc: 0.7522 - val_loss: 2.3167 - val_acc: 0.7437\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8152 - acc: 0.7380 - val_loss: 2.2483 - val_acc: 0.7500\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6364 - acc: 0.7589 - val_loss: 2.1103 - val_acc: 0.7538\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6576 - acc: 0.7511 - val_loss: 2.1893 - val_acc: 0.7487\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8006 - acc: 0.7391 - val_loss: 2.1092 - val_acc: 0.7581\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7660 - acc: 0.7391 - val_loss: 1.8476 - val_acc: 0.7819\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8179 - acc: 0.7314 - val_loss: 1.9793 - val_acc: 0.7719\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6119 - acc: 0.7628 - val_loss: 2.0557 - val_acc: 0.7663\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6788 - acc: 0.7491 - val_loss: 1.9114 - val_acc: 0.7862\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6622 - acc: 0.7495 - val_loss: 2.1065 - val_acc: 0.7650\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7386 - acc: 0.7464 - val_loss: 2.0695 - val_acc: 0.7600\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6181 - acc: 0.7570 - val_loss: 2.2689 - val_acc: 0.7406\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6501 - acc: 0.7502 - val_loss: 1.9523 - val_acc: 0.7819\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7609 - acc: 0.7392 - val_loss: 2.0305 - val_acc: 0.7694\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6772 - acc: 0.7506 - val_loss: 2.1608 - val_acc: 0.7513\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7985 - acc: 0.7323 - val_loss: 2.0265 - val_acc: 0.7638\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6579 - acc: 0.7542 - val_loss: 1.8027 - val_acc: 0.7881\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6242 - acc: 0.7544 - val_loss: 1.9097 - val_acc: 0.7856\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5999 - acc: 0.7536 - val_loss: 1.9494 - val_acc: 0.7731\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6295 - acc: 0.7511 - val_loss: 1.9947 - val_acc: 0.7675\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6859 - acc: 0.7450 - val_loss: 2.1366 - val_acc: 0.7588\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6483 - acc: 0.7545 - val_loss: 1.8674 - val_acc: 0.7875\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7481 - acc: 0.7384 - val_loss: 2.0125 - val_acc: 0.7719\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6835 - acc: 0.7459 - val_loss: 2.0633 - val_acc: 0.7588\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6716 - acc: 0.7444 - val_loss: 2.2025 - val_acc: 0.7506\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5834 - acc: 0.7566 - val_loss: 2.3475 - val_acc: 0.7294\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6493 - acc: 0.7536 - val_loss: 2.0416 - val_acc: 0.7725\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6698 - acc: 0.7467 - val_loss: 2.0349 - val_acc: 0.7556\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6082 - acc: 0.7544 - val_loss: 2.0819 - val_acc: 0.7631\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6068 - acc: 0.7561 - val_loss: 2.0726 - val_acc: 0.7625\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6403 - acc: 0.7517 - val_loss: 2.0645 - val_acc: 0.7600\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8442 - acc: 0.7272 - val_loss: 1.9642 - val_acc: 0.7663\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8035 - acc: 0.7303 - val_loss: 2.0743 - val_acc: 0.7669\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6515 - acc: 0.7511 - val_loss: 1.7846 - val_acc: 0.7944\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7289 - acc: 0.7452 - val_loss: 2.0876 - val_acc: 0.7656\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5627 - acc: 0.7639 - val_loss: 2.0261 - val_acc: 0.7619\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5587 - acc: 0.7644 - val_loss: 2.0300 - val_acc: 0.7638\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7159 - acc: 0.7419 - val_loss: 1.9745 - val_acc: 0.7688\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7029 - acc: 0.7445 - val_loss: 2.0675 - val_acc: 0.7681\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6632 - acc: 0.7478 - val_loss: 2.0013 - val_acc: 0.7688\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6988 - acc: 0.7434 - val_loss: 2.1834 - val_acc: 0.7487\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6029 - acc: 0.7573 - val_loss: 1.9004 - val_acc: 0.7812\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7152 - acc: 0.7438 - val_loss: 2.0006 - val_acc: 0.7669\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7165 - acc: 0.7447 - val_loss: 2.0025 - val_acc: 0.7706\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7061 - acc: 0.7444 - val_loss: 1.8619 - val_acc: 0.7812\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6653 - acc: 0.7477 - val_loss: 2.0052 - val_acc: 0.7694\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7425 - acc: 0.7331 - val_loss: 2.1042 - val_acc: 0.7569\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6458 - acc: 0.7477 - val_loss: 2.0334 - val_acc: 0.7681\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7372 - acc: 0.7405 - val_loss: 1.8629 - val_acc: 0.7825\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6628 - acc: 0.7444 - val_loss: 2.1318 - val_acc: 0.7569\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5608 - acc: 0.7545 - val_loss: 1.9623 - val_acc: 0.7725\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6816 - acc: 0.7408 - val_loss: 2.1160 - val_acc: 0.7500\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6723 - acc: 0.7431 - val_loss: 2.1333 - val_acc: 0.7556\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8238 - acc: 0.7264 - val_loss: 2.0800 - val_acc: 0.7650\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6200 - acc: 0.7528 - val_loss: 2.0024 - val_acc: 0.7725\n",
      "Epoch 716/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6069 - acc: 0.7538 - val_loss: 2.0050 - val_acc: 0.7750\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6810 - acc: 0.7463 - val_loss: 2.2266 - val_acc: 0.7487\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7039 - acc: 0.7434 - val_loss: 2.0784 - val_acc: 0.7638\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8184 - acc: 0.7250 - val_loss: 2.1987 - val_acc: 0.7475\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7974 - acc: 0.7291 - val_loss: 2.2591 - val_acc: 0.7381\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5861 - acc: 0.7556 - val_loss: 2.0530 - val_acc: 0.7619\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6532 - acc: 0.7419 - val_loss: 2.3989 - val_acc: 0.7337\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6697 - acc: 0.7466 - val_loss: 1.8910 - val_acc: 0.7831\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6364 - acc: 0.7486 - val_loss: 1.9743 - val_acc: 0.7669\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6459 - acc: 0.7480 - val_loss: 2.0906 - val_acc: 0.7600\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6187 - acc: 0.7516 - val_loss: 1.9168 - val_acc: 0.7837\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6599 - acc: 0.7500 - val_loss: 2.1102 - val_acc: 0.7631\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6327 - acc: 0.7484 - val_loss: 1.9363 - val_acc: 0.7800\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6094 - acc: 0.7486 - val_loss: 2.2086 - val_acc: 0.7506\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5512 - acc: 0.7578 - val_loss: 2.0176 - val_acc: 0.7800\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6460 - acc: 0.7434 - val_loss: 2.0696 - val_acc: 0.7675\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6427 - acc: 0.7484 - val_loss: 1.9420 - val_acc: 0.7812\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5756 - acc: 0.7516 - val_loss: 2.1106 - val_acc: 0.7581\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5325 - acc: 0.7606 - val_loss: 1.9752 - val_acc: 0.7794\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7180 - acc: 0.7419 - val_loss: 2.0805 - val_acc: 0.7625\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6407 - acc: 0.7506 - val_loss: 2.3779 - val_acc: 0.7437\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6333 - acc: 0.7525 - val_loss: 2.0062 - val_acc: 0.7725\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6372 - acc: 0.7539 - val_loss: 2.0090 - val_acc: 0.7769\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8166 - acc: 0.7288 - val_loss: 2.1833 - val_acc: 0.7525\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6993 - acc: 0.7438 - val_loss: 2.0007 - val_acc: 0.7744\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6790 - acc: 0.7452 - val_loss: 1.9327 - val_acc: 0.7788\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7843 - acc: 0.7364 - val_loss: 1.9757 - val_acc: 0.7788\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5930 - acc: 0.7559 - val_loss: 2.1764 - val_acc: 0.7494\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5460 - acc: 0.7631 - val_loss: 1.8541 - val_acc: 0.7931\n",
      "Epoch 745/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.6326 - acc: 0.7498 - val_loss: 1.8638 - val_acc: 0.7831\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6864 - acc: 0.7405 - val_loss: 1.7955 - val_acc: 0.7919\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6893 - acc: 0.7402 - val_loss: 1.9223 - val_acc: 0.7831\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6719 - acc: 0.7419 - val_loss: 1.9523 - val_acc: 0.7800\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5971 - acc: 0.7539 - val_loss: 2.1141 - val_acc: 0.7588\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7535 - acc: 0.7320 - val_loss: 2.1599 - val_acc: 0.7538\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6362 - acc: 0.7492 - val_loss: 1.8877 - val_acc: 0.7862\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6530 - acc: 0.7472 - val_loss: 2.0295 - val_acc: 0.7694\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7267 - acc: 0.7344 - val_loss: 1.8641 - val_acc: 0.7862\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6895 - acc: 0.7406 - val_loss: 1.9786 - val_acc: 0.7688\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5999 - acc: 0.7498 - val_loss: 2.1975 - val_acc: 0.7444\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7198 - acc: 0.7355 - val_loss: 2.0126 - val_acc: 0.7744\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5616 - acc: 0.7562 - val_loss: 2.1181 - val_acc: 0.7694\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5720 - acc: 0.7525 - val_loss: 2.0819 - val_acc: 0.7706\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7280 - acc: 0.7342 - val_loss: 2.1664 - val_acc: 0.7481\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5973 - acc: 0.7497 - val_loss: 2.1384 - val_acc: 0.7556\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6327 - acc: 0.7483 - val_loss: 2.0359 - val_acc: 0.7775\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6463 - acc: 0.7411 - val_loss: 2.0262 - val_acc: 0.7731\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5699 - acc: 0.7508 - val_loss: 2.3325 - val_acc: 0.7387\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5232 - acc: 0.7584 - val_loss: 2.0078 - val_acc: 0.7713\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6001 - acc: 0.7486 - val_loss: 2.4131 - val_acc: 0.7350\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5538 - acc: 0.7534 - val_loss: 2.1090 - val_acc: 0.7750\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6150 - acc: 0.7489 - val_loss: 1.8331 - val_acc: 0.7975\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6203 - acc: 0.7488 - val_loss: 1.8421 - val_acc: 0.7875\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5835 - acc: 0.7519 - val_loss: 2.0657 - val_acc: 0.7719\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6849 - acc: 0.7412 - val_loss: 1.9920 - val_acc: 0.7713\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5821 - acc: 0.7527 - val_loss: 1.9465 - val_acc: 0.7800\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6104 - acc: 0.7475 - val_loss: 2.3589 - val_acc: 0.7431\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6252 - acc: 0.7470 - val_loss: 2.1576 - val_acc: 0.7581\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6538 - acc: 0.7459 - val_loss: 1.9216 - val_acc: 0.7769\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6009 - acc: 0.7511 - val_loss: 2.1810 - val_acc: 0.7538\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6351 - acc: 0.7486 - val_loss: 2.1481 - val_acc: 0.7581\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6287 - acc: 0.7403 - val_loss: 2.2028 - val_acc: 0.7419\n",
      "Epoch 778/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6482 - acc: 0.7419 - val_loss: 2.0330 - val_acc: 0.7638\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6494 - acc: 0.7389 - val_loss: 2.0279 - val_acc: 0.7694\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5907 - acc: 0.7494 - val_loss: 1.9742 - val_acc: 0.7781\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6199 - acc: 0.7477 - val_loss: 1.9273 - val_acc: 0.7794\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6490 - acc: 0.7433 - val_loss: 2.0993 - val_acc: 0.7588\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7554 - acc: 0.7300 - val_loss: 1.9602 - val_acc: 0.7731\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6826 - acc: 0.7409 - val_loss: 2.1380 - val_acc: 0.7575\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5998 - acc: 0.7491 - val_loss: 2.0313 - val_acc: 0.7656\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6553 - acc: 0.7412 - val_loss: 2.1503 - val_acc: 0.7581\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.5890 - acc: 0.7473 - val_loss: 2.1445 - val_acc: 0.7613\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6541 - acc: 0.7416 - val_loss: 2.1715 - val_acc: 0.7619\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6528 - acc: 0.7416 - val_loss: 1.9575 - val_acc: 0.7763\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7439 - acc: 0.7314 - val_loss: 2.1189 - val_acc: 0.7638\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5734 - acc: 0.7572 - val_loss: 2.0263 - val_acc: 0.7706\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5941 - acc: 0.7556 - val_loss: 2.0313 - val_acc: 0.7731\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7005 - acc: 0.7411 - val_loss: 2.2626 - val_acc: 0.7513\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6041 - acc: 0.7525 - val_loss: 1.8718 - val_acc: 0.7925\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5086 - acc: 0.7625 - val_loss: 2.2655 - val_acc: 0.7387\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5177 - acc: 0.7641 - val_loss: 2.2321 - val_acc: 0.7538\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5726 - acc: 0.7536 - val_loss: 1.9499 - val_acc: 0.7812\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5452 - acc: 0.7569 - val_loss: 2.2167 - val_acc: 0.7569\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5139 - acc: 0.7619 - val_loss: 1.8325 - val_acc: 0.7894\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6087 - acc: 0.7475 - val_loss: 1.8126 - val_acc: 0.7894\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6298 - acc: 0.7455 - val_loss: 2.0821 - val_acc: 0.7694\n",
      "Epoch 802/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5573 - acc: 0.7525 - val_loss: 2.0706 - val_acc: 0.7744\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6660 - acc: 0.7389 - val_loss: 1.9670 - val_acc: 0.7850\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5469 - acc: 0.7492 - val_loss: 2.1130 - val_acc: 0.7619\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5250 - acc: 0.7573 - val_loss: 2.1624 - val_acc: 0.7631\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5994 - acc: 0.7442 - val_loss: 2.3143 - val_acc: 0.7425\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7249 - acc: 0.7305 - val_loss: 1.9514 - val_acc: 0.7788\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5654 - acc: 0.7509 - val_loss: 2.1043 - val_acc: 0.7644\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7025 - acc: 0.7333 - val_loss: 2.1214 - val_acc: 0.7569\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6897 - acc: 0.7388 - val_loss: 1.9742 - val_acc: 0.7825\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5269 - acc: 0.7614 - val_loss: 2.2793 - val_acc: 0.7400\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6601 - acc: 0.7391 - val_loss: 2.0078 - val_acc: 0.7719\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7057 - acc: 0.7330 - val_loss: 2.0527 - val_acc: 0.7669\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5990 - acc: 0.7433 - val_loss: 2.1608 - val_acc: 0.7575\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7018 - acc: 0.7328 - val_loss: 1.9709 - val_acc: 0.7731\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6478 - acc: 0.7423 - val_loss: 2.2038 - val_acc: 0.7531\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6251 - acc: 0.7470 - val_loss: 1.9933 - val_acc: 0.7794\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5615 - acc: 0.7511 - val_loss: 2.1919 - val_acc: 0.7681\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5525 - acc: 0.7536 - val_loss: 2.1860 - val_acc: 0.7631\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5978 - acc: 0.7488 - val_loss: 2.0899 - val_acc: 0.7713\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6369 - acc: 0.7444 - val_loss: 2.3122 - val_acc: 0.7475\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5281 - acc: 0.7569 - val_loss: 2.1370 - val_acc: 0.7594\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5467 - acc: 0.7503 - val_loss: 1.8024 - val_acc: 0.7981\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7220 - acc: 0.7281 - val_loss: 2.1759 - val_acc: 0.7588\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4981 - acc: 0.7573 - val_loss: 2.1694 - val_acc: 0.7606\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5103 - acc: 0.7552 - val_loss: 1.8324 - val_acc: 0.7906\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5617 - acc: 0.7475 - val_loss: 2.0479 - val_acc: 0.7725\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6040 - acc: 0.7444 - val_loss: 2.1430 - val_acc: 0.7631\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7195 - acc: 0.7283 - val_loss: 2.0860 - val_acc: 0.7681\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6107 - acc: 0.7437 - val_loss: 2.1121 - val_acc: 0.7650\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4331 - acc: 0.7686 - val_loss: 2.1242 - val_acc: 0.7656\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5618 - acc: 0.7512 - val_loss: 2.1712 - val_acc: 0.7575\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5668 - acc: 0.7483 - val_loss: 1.9667 - val_acc: 0.7831\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5460 - acc: 0.7473 - val_loss: 2.0899 - val_acc: 0.7644\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5130 - acc: 0.7547 - val_loss: 1.9460 - val_acc: 0.7825\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5254 - acc: 0.7553 - val_loss: 1.9807 - val_acc: 0.7769\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6708 - acc: 0.7314 - val_loss: 1.8985 - val_acc: 0.7912\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5822 - acc: 0.7470 - val_loss: 2.2380 - val_acc: 0.7544\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6145 - acc: 0.7394 - val_loss: 1.9033 - val_acc: 0.7956\n",
      "Epoch 840/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5522 - acc: 0.7512 - val_loss: 2.0906 - val_acc: 0.7663\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5003 - acc: 0.7555 - val_loss: 2.1039 - val_acc: 0.7544\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6726 - acc: 0.7341 - val_loss: 2.2835 - val_acc: 0.7506\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5006 - acc: 0.7545 - val_loss: 2.0945 - val_acc: 0.7663\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6482 - acc: 0.7398 - val_loss: 2.3207 - val_acc: 0.7469\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5492 - acc: 0.7530 - val_loss: 2.2555 - val_acc: 0.7475\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5339 - acc: 0.7502 - val_loss: 2.3335 - val_acc: 0.7487\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5538 - acc: 0.7505 - val_loss: 1.9114 - val_acc: 0.7937\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5738 - acc: 0.7455 - val_loss: 2.1758 - val_acc: 0.7606\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5590 - acc: 0.7489 - val_loss: 2.2279 - val_acc: 0.7506\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5129 - acc: 0.7541 - val_loss: 2.0304 - val_acc: 0.7812\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4147 - acc: 0.7675 - val_loss: 1.7801 - val_acc: 0.7987\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5813 - acc: 0.7466 - val_loss: 2.0308 - val_acc: 0.7731\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5585 - acc: 0.7472 - val_loss: 2.1854 - val_acc: 0.7694\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5596 - acc: 0.7481 - val_loss: 2.0995 - val_acc: 0.7731\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5319 - acc: 0.7458 - val_loss: 2.4572 - val_acc: 0.7281\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5293 - acc: 0.7512 - val_loss: 2.0440 - val_acc: 0.7775\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4979 - acc: 0.7545 - val_loss: 2.2251 - val_acc: 0.7575\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5712 - acc: 0.7464 - val_loss: 2.0723 - val_acc: 0.7663\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5551 - acc: 0.7444 - val_loss: 2.1298 - val_acc: 0.7750\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5505 - acc: 0.7502 - val_loss: 1.9315 - val_acc: 0.7825\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5229 - acc: 0.7520 - val_loss: 2.1023 - val_acc: 0.7719\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5788 - acc: 0.7462 - val_loss: 2.0607 - val_acc: 0.7794\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4756 - acc: 0.7573 - val_loss: 2.1226 - val_acc: 0.7725\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6287 - acc: 0.7398 - val_loss: 2.2336 - val_acc: 0.7688\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4245 - acc: 0.7662 - val_loss: 1.9374 - val_acc: 0.7950\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.5703 - acc: 0.7456 - val_loss: 2.2004 - val_acc: 0.7700\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4861 - acc: 0.7567 - val_loss: 1.9384 - val_acc: 0.7956\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6293 - acc: 0.7419 - val_loss: 1.8861 - val_acc: 0.7912\n",
      "Epoch 869/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.6178 - acc: 0.7403 - val_loss: 2.3870 - val_acc: 0.7450\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5113 - acc: 0.7537 - val_loss: 2.2528 - val_acc: 0.7544\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4718 - acc: 0.7561 - val_loss: 2.0244 - val_acc: 0.7738\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5438 - acc: 0.7452 - val_loss: 1.8866 - val_acc: 0.7931\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5831 - acc: 0.7455 - val_loss: 2.2839 - val_acc: 0.7431\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5918 - acc: 0.7433 - val_loss: 1.8455 - val_acc: 0.7956\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5257 - acc: 0.7580 - val_loss: 2.1661 - val_acc: 0.7812\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5763 - acc: 0.7505 - val_loss: 2.0704 - val_acc: 0.7794\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4991 - acc: 0.7569 - val_loss: 2.1753 - val_acc: 0.7638\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6543 - acc: 0.7359 - val_loss: 2.1985 - val_acc: 0.7669\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5594 - acc: 0.7466 - val_loss: 2.2776 - val_acc: 0.7500\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4951 - acc: 0.7594 - val_loss: 2.2014 - val_acc: 0.7613\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5781 - acc: 0.7500 - val_loss: 2.1628 - val_acc: 0.7581\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6241 - acc: 0.7367 - val_loss: 2.3473 - val_acc: 0.7500\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5671 - acc: 0.7491 - val_loss: 2.1155 - val_acc: 0.7725\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5766 - acc: 0.7475 - val_loss: 2.3617 - val_acc: 0.7456\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5158 - acc: 0.7581 - val_loss: 1.8992 - val_acc: 0.7894\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5638 - acc: 0.7527 - val_loss: 1.9627 - val_acc: 0.7812\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6114 - acc: 0.7447 - val_loss: 2.1416 - val_acc: 0.7625\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5396 - acc: 0.7502 - val_loss: 2.0594 - val_acc: 0.7738\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5324 - acc: 0.7512 - val_loss: 2.0837 - val_acc: 0.7744\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5394 - acc: 0.7553 - val_loss: 1.9867 - val_acc: 0.7837\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5316 - acc: 0.7523 - val_loss: 1.8395 - val_acc: 0.7925\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5954 - acc: 0.7411 - val_loss: 2.0136 - val_acc: 0.7744\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5728 - acc: 0.7475 - val_loss: 2.2270 - val_acc: 0.7563\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5865 - acc: 0.7486 - val_loss: 2.1211 - val_acc: 0.7650\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5706 - acc: 0.7458 - val_loss: 1.7190 - val_acc: 0.8131\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5817 - acc: 0.7445 - val_loss: 2.1765 - val_acc: 0.7594\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3982 - acc: 0.7698 - val_loss: 2.2900 - val_acc: 0.7581\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4612 - acc: 0.7594 - val_loss: 2.2162 - val_acc: 0.7606\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5315 - acc: 0.7547 - val_loss: 2.2012 - val_acc: 0.7669\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5356 - acc: 0.7491 - val_loss: 2.0720 - val_acc: 0.7750\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6020 - acc: 0.7377 - val_loss: 2.1855 - val_acc: 0.7594\n",
      "Epoch 902/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5776 - acc: 0.7444 - val_loss: 2.0852 - val_acc: 0.7725\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5240 - acc: 0.7484 - val_loss: 2.2539 - val_acc: 0.7556\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5665 - acc: 0.7458 - val_loss: 2.4919 - val_acc: 0.7256\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5476 - acc: 0.7448 - val_loss: 1.9918 - val_acc: 0.7825\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5311 - acc: 0.7487 - val_loss: 2.0225 - val_acc: 0.7819\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4812 - acc: 0.7537 - val_loss: 2.1656 - val_acc: 0.7675\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5897 - acc: 0.7411 - val_loss: 1.9368 - val_acc: 0.7881\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5769 - acc: 0.7431 - val_loss: 2.1142 - val_acc: 0.7663\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5450 - acc: 0.7469 - val_loss: 1.9311 - val_acc: 0.7906\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5923 - acc: 0.7392 - val_loss: 2.2581 - val_acc: 0.7538\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4753 - acc: 0.7591 - val_loss: 2.4321 - val_acc: 0.7387\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6042 - acc: 0.7353 - val_loss: 1.9560 - val_acc: 0.7794\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5835 - acc: 0.7367 - val_loss: 1.9929 - val_acc: 0.7812\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5503 - acc: 0.7475 - val_loss: 2.3577 - val_acc: 0.7575\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5085 - acc: 0.7508 - val_loss: 2.6412 - val_acc: 0.7306\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5101 - acc: 0.7512 - val_loss: 2.4238 - val_acc: 0.7462\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4775 - acc: 0.7623 - val_loss: 2.1860 - val_acc: 0.7656\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4937 - acc: 0.7573 - val_loss: 2.1329 - val_acc: 0.7688\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5075 - acc: 0.7545 - val_loss: 2.2898 - val_acc: 0.7656\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5239 - acc: 0.7555 - val_loss: 2.4165 - val_acc: 0.7575\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5404 - acc: 0.7566 - val_loss: 2.2204 - val_acc: 0.7513\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.6661 - acc: 0.7397 - val_loss: 1.9084 - val_acc: 0.7850\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5283 - acc: 0.7539 - val_loss: 2.0148 - val_acc: 0.7812\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4703 - acc: 0.7592 - val_loss: 2.0584 - val_acc: 0.7788\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6333 - acc: 0.7463 - val_loss: 2.6988 - val_acc: 0.7294\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6414 - acc: 0.7423 - val_loss: 2.2150 - val_acc: 0.7656\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6612 - acc: 0.7447 - val_loss: 2.2190 - val_acc: 0.7550\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5771 - acc: 0.7542 - val_loss: 2.1759 - val_acc: 0.7494\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6407 - acc: 0.7437 - val_loss: 2.0774 - val_acc: 0.7675\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5590 - acc: 0.7553 - val_loss: 2.2396 - val_acc: 0.7563\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6181 - acc: 0.7448 - val_loss: 2.2201 - val_acc: 0.7531\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5952 - acc: 0.7477 - val_loss: 2.0541 - val_acc: 0.7831\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6634 - acc: 0.7409 - val_loss: 2.0775 - val_acc: 0.7675\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5794 - acc: 0.7522 - val_loss: 1.9609 - val_acc: 0.7869\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5640 - acc: 0.7552 - val_loss: 2.4301 - val_acc: 0.7519\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5711 - acc: 0.7553 - val_loss: 2.1559 - val_acc: 0.7719\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6795 - acc: 0.7409 - val_loss: 2.0692 - val_acc: 0.7844\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5888 - acc: 0.7545 - val_loss: 2.2565 - val_acc: 0.7613\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6420 - acc: 0.7459 - val_loss: 2.0043 - val_acc: 0.7887\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6505 - acc: 0.7472 - val_loss: 2.1883 - val_acc: 0.7763\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6795 - acc: 0.7442 - val_loss: 2.1073 - val_acc: 0.7763\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7061 - acc: 0.7394 - val_loss: 2.0808 - val_acc: 0.7788\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5851 - acc: 0.7511 - val_loss: 2.1489 - val_acc: 0.7756\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6101 - acc: 0.7492 - val_loss: 2.3947 - val_acc: 0.7500\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6480 - acc: 0.7420 - val_loss: 2.2499 - val_acc: 0.7613\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4982 - acc: 0.7572 - val_loss: 2.4606 - val_acc: 0.7419\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7319 - acc: 0.7309 - val_loss: 2.1883 - val_acc: 0.7656\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5932 - acc: 0.7489 - val_loss: 2.1058 - val_acc: 0.7800\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4834 - acc: 0.7597 - val_loss: 2.2411 - val_acc: 0.7638\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5514 - acc: 0.7530 - val_loss: 2.2007 - val_acc: 0.7706\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6359 - acc: 0.7388 - val_loss: 2.1706 - val_acc: 0.7619\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5527 - acc: 0.7503 - val_loss: 2.0111 - val_acc: 0.7850\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6095 - acc: 0.7445 - val_loss: 2.2099 - val_acc: 0.7669\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6055 - acc: 0.7438 - val_loss: 2.2635 - val_acc: 0.7644\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5031 - acc: 0.7544 - val_loss: 2.0819 - val_acc: 0.7769\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5770 - acc: 0.7456 - val_loss: 1.9796 - val_acc: 0.7812\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5630 - acc: 0.7492 - val_loss: 2.3631 - val_acc: 0.7569\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5793 - acc: 0.7464 - val_loss: 1.8634 - val_acc: 0.8019\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5650 - acc: 0.7487 - val_loss: 2.4033 - val_acc: 0.7588\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6817 - acc: 0.7289 - val_loss: 2.1061 - val_acc: 0.7794\n",
      "Epoch 962/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5437 - acc: 0.7505 - val_loss: 2.1296 - val_acc: 0.7781\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5269 - acc: 0.7547 - val_loss: 2.4029 - val_acc: 0.7506\n",
      "Epoch 964/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6549 - acc: 0.7427 - val_loss: 2.1043 - val_acc: 0.7731\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6455 - acc: 0.7420 - val_loss: 2.1193 - val_acc: 0.7756\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5925 - acc: 0.7481 - val_loss: 2.3531 - val_acc: 0.7538\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5602 - acc: 0.7525 - val_loss: 2.0929 - val_acc: 0.7800\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5553 - acc: 0.7519 - val_loss: 2.1804 - val_acc: 0.7794\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6294 - acc: 0.7386 - val_loss: 2.2983 - val_acc: 0.7600\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5788 - acc: 0.7470 - val_loss: 2.3456 - val_acc: 0.7556\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6097 - acc: 0.7463 - val_loss: 2.4193 - val_acc: 0.7506\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4756 - acc: 0.7625 - val_loss: 2.2552 - val_acc: 0.7594\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6250 - acc: 0.7423 - val_loss: 2.2220 - val_acc: 0.7719\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5289 - acc: 0.7563 - val_loss: 2.1911 - val_acc: 0.7750\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6626 - acc: 0.7408 - val_loss: 2.4656 - val_acc: 0.7406\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6709 - acc: 0.7394 - val_loss: 2.3761 - val_acc: 0.7513\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5665 - acc: 0.7517 - val_loss: 2.3272 - val_acc: 0.7556\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5316 - acc: 0.7581 - val_loss: 2.1312 - val_acc: 0.7750\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5819 - acc: 0.7477 - val_loss: 2.2078 - val_acc: 0.7731\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5335 - acc: 0.7561 - val_loss: 2.0081 - val_acc: 0.7844\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5464 - acc: 0.7517 - val_loss: 2.0321 - val_acc: 0.7844\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6271 - acc: 0.7381 - val_loss: 2.0659 - val_acc: 0.7794\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5674 - acc: 0.7508 - val_loss: 2.0448 - val_acc: 0.7800\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5967 - acc: 0.7423 - val_loss: 2.0401 - val_acc: 0.7819\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5625 - acc: 0.7467 - val_loss: 1.8879 - val_acc: 0.7925\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5423 - acc: 0.7505 - val_loss: 2.2949 - val_acc: 0.7650\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6833 - acc: 0.7330 - val_loss: 2.2250 - val_acc: 0.7675\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5479 - acc: 0.7466 - val_loss: 2.2126 - val_acc: 0.7669\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5590 - acc: 0.7531 - val_loss: 2.1995 - val_acc: 0.7688\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5495 - acc: 0.7556 - val_loss: 2.2787 - val_acc: 0.7638\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5763 - acc: 0.7494 - val_loss: 2.3572 - val_acc: 0.7556\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7211 - acc: 0.7344 - val_loss: 2.3423 - val_acc: 0.7569\n",
      "Epoch 993/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.5945 - acc: 0.7477 - val_loss: 2.0294 - val_acc: 0.7881\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5442 - acc: 0.7520 - val_loss: 2.5335 - val_acc: 0.7450\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6095 - acc: 0.7447 - val_loss: 2.0728 - val_acc: 0.7850\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6233 - acc: 0.7431 - val_loss: 2.2467 - val_acc: 0.7719\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6496 - acc: 0.7405 - val_loss: 2.3086 - val_acc: 0.7675\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6425 - acc: 0.7405 - val_loss: 2.1646 - val_acc: 0.7744\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6005 - acc: 0.7503 - val_loss: 2.2726 - val_acc: 0.7631\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5940 - acc: 0.7487 - val_loss: 2.4195 - val_acc: 0.7544\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5655 - acc: 0.7517 - val_loss: 2.4942 - val_acc: 0.7444\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5040 - acc: 0.7569 - val_loss: 2.1878 - val_acc: 0.7713\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5769 - acc: 0.7473 - val_loss: 2.2900 - val_acc: 0.7713\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4270 - acc: 0.7708 - val_loss: 2.3026 - val_acc: 0.7644\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4973 - acc: 0.7572 - val_loss: 1.9873 - val_acc: 0.7831\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5187 - acc: 0.7531 - val_loss: 2.4074 - val_acc: 0.7481\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5371 - acc: 0.7495 - val_loss: 1.9865 - val_acc: 0.7962\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5296 - acc: 0.7470 - val_loss: 2.1417 - val_acc: 0.7744\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6366 - acc: 0.7377 - val_loss: 2.3111 - val_acc: 0.7606\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5537 - acc: 0.7475 - val_loss: 2.1464 - val_acc: 0.7763\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5403 - acc: 0.7473 - val_loss: 2.0902 - val_acc: 0.7850\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5187 - acc: 0.7559 - val_loss: 2.5208 - val_acc: 0.7437\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6503 - acc: 0.7372 - val_loss: 2.7690 - val_acc: 0.7219\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6783 - acc: 0.7309 - val_loss: 2.0877 - val_acc: 0.7862\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4608 - acc: 0.7605 - val_loss: 2.0479 - val_acc: 0.7919\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4962 - acc: 0.7570 - val_loss: 2.0090 - val_acc: 0.7844\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5441 - acc: 0.7502 - val_loss: 2.3877 - val_acc: 0.7550\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5484 - acc: 0.7484 - val_loss: 2.5763 - val_acc: 0.7487\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5010 - acc: 0.7528 - val_loss: 2.2768 - val_acc: 0.7681\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5293 - acc: 0.7511 - val_loss: 2.3487 - val_acc: 0.7638\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6092 - acc: 0.7344 - val_loss: 1.9701 - val_acc: 0.7937\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5433 - acc: 0.7469 - val_loss: 2.2854 - val_acc: 0.7669\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5991 - acc: 0.7389 - val_loss: 2.1716 - val_acc: 0.7800\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5166 - acc: 0.7489 - val_loss: 2.2424 - val_acc: 0.7713\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5590 - acc: 0.7472 - val_loss: 2.3234 - val_acc: 0.7613\n",
      "Epoch 1026/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4538 - acc: 0.7592 - val_loss: 2.2662 - val_acc: 0.7744\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6214 - acc: 0.7369 - val_loss: 2.3323 - val_acc: 0.7644\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6179 - acc: 0.7377 - val_loss: 2.3507 - val_acc: 0.7594\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5612 - acc: 0.7483 - val_loss: 2.1711 - val_acc: 0.7794\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5228 - acc: 0.7498 - val_loss: 2.0440 - val_acc: 0.7925\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6339 - acc: 0.7352 - val_loss: 1.9876 - val_acc: 0.7950\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5977 - acc: 0.7388 - val_loss: 2.0429 - val_acc: 0.7850\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4696 - acc: 0.7578 - val_loss: 2.5080 - val_acc: 0.7525\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5498 - acc: 0.7434 - val_loss: 2.1455 - val_acc: 0.7806\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6512 - acc: 0.7325 - val_loss: 2.4151 - val_acc: 0.7600\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5553 - acc: 0.7477 - val_loss: 2.3206 - val_acc: 0.7625\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4673 - acc: 0.7561 - val_loss: 2.1925 - val_acc: 0.7781\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4881 - acc: 0.7564 - val_loss: 2.3000 - val_acc: 0.7613\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5458 - acc: 0.7459 - val_loss: 2.3623 - val_acc: 0.7594\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5126 - acc: 0.7514 - val_loss: 2.1337 - val_acc: 0.7763\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5035 - acc: 0.7538 - val_loss: 1.8192 - val_acc: 0.8050\n",
      "Epoch 1042/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4134 - acc: 0.7650 - val_loss: 2.4633 - val_acc: 0.7519\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5812 - acc: 0.7384 - val_loss: 2.3165 - val_acc: 0.7594\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4704 - acc: 0.7578 - val_loss: 2.1503 - val_acc: 0.7763\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5855 - acc: 0.7386 - val_loss: 2.3447 - val_acc: 0.7625\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4827 - acc: 0.7516 - val_loss: 2.2484 - val_acc: 0.7719\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4828 - acc: 0.7573 - val_loss: 2.4784 - val_acc: 0.7456\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5626 - acc: 0.7408 - val_loss: 2.0503 - val_acc: 0.7881\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4365 - acc: 0.7606 - val_loss: 2.2787 - val_acc: 0.7675\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4568 - acc: 0.7598 - val_loss: 2.3891 - val_acc: 0.7581\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5617 - acc: 0.7445 - val_loss: 2.2556 - val_acc: 0.7750\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6075 - acc: 0.7355 - val_loss: 2.1363 - val_acc: 0.7769\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4874 - acc: 0.7500 - val_loss: 2.1782 - val_acc: 0.7763\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4773 - acc: 0.7509 - val_loss: 2.2519 - val_acc: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5343 - acc: 0.7431 - val_loss: 2.2867 - val_acc: 0.7719\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.5099 - acc: 0.7498 - val_loss: 2.3026 - val_acc: 0.7644\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5687 - acc: 0.7423 - val_loss: 2.0655 - val_acc: 0.7862\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5418 - acc: 0.7422 - val_loss: 2.3333 - val_acc: 0.7619\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5465 - acc: 0.7441 - val_loss: 2.0365 - val_acc: 0.7850\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4612 - acc: 0.7544 - val_loss: 2.3116 - val_acc: 0.7675\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4721 - acc: 0.7525 - val_loss: 2.5419 - val_acc: 0.7519\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4667 - acc: 0.7533 - val_loss: 2.1069 - val_acc: 0.7894\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5374 - acc: 0.7458 - val_loss: 2.1865 - val_acc: 0.7856\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4920 - acc: 0.7509 - val_loss: 2.0787 - val_acc: 0.7875\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5711 - acc: 0.7403 - val_loss: 2.1071 - val_acc: 0.7856\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5997 - acc: 0.7334 - val_loss: 2.2207 - val_acc: 0.7738\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5485 - acc: 0.7412 - val_loss: 2.2541 - val_acc: 0.7675\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5176 - acc: 0.7427 - val_loss: 2.4811 - val_acc: 0.7500\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4509 - acc: 0.7511 - val_loss: 1.9973 - val_acc: 0.7931\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4920 - acc: 0.7503 - val_loss: 2.5320 - val_acc: 0.7475\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5168 - acc: 0.7495 - val_loss: 2.4879 - val_acc: 0.7513\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5615 - acc: 0.7452 - val_loss: 2.2038 - val_acc: 0.7738\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4372 - acc: 0.7520 - val_loss: 2.2613 - val_acc: 0.7706\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5029 - acc: 0.7480 - val_loss: 2.3224 - val_acc: 0.7663\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4084 - acc: 0.7600 - val_loss: 2.2243 - val_acc: 0.7788\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3456 - acc: 0.7667 - val_loss: 2.2895 - val_acc: 0.7688\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6651 - acc: 0.7231 - val_loss: 2.2426 - val_acc: 0.7725\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5037 - acc: 0.7439 - val_loss: 2.1653 - val_acc: 0.7788\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5068 - acc: 0.7439 - val_loss: 2.1529 - val_acc: 0.7812\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6076 - acc: 0.7302 - val_loss: 2.3170 - val_acc: 0.7663\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4394 - acc: 0.7567 - val_loss: 2.2187 - val_acc: 0.7744\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5859 - acc: 0.7322 - val_loss: 2.5480 - val_acc: 0.7437\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5029 - acc: 0.7469 - val_loss: 2.3707 - val_acc: 0.7606\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4100 - acc: 0.7617 - val_loss: 2.3940 - val_acc: 0.7600\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4106 - acc: 0.7600 - val_loss: 2.4240 - val_acc: 0.7563\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5201 - acc: 0.7420 - val_loss: 2.1233 - val_acc: 0.7837\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4960 - acc: 0.7463 - val_loss: 2.1213 - val_acc: 0.7844\n",
      "Epoch 1088/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4762 - acc: 0.7511 - val_loss: 2.2164 - val_acc: 0.7719\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4826 - acc: 0.7497 - val_loss: 2.1570 - val_acc: 0.7794\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4011 - acc: 0.7588 - val_loss: 2.5169 - val_acc: 0.7506\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4678 - acc: 0.7533 - val_loss: 2.5853 - val_acc: 0.7462\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6051 - acc: 0.7320 - val_loss: 2.1948 - val_acc: 0.7769\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4542 - acc: 0.7495 - val_loss: 2.3905 - val_acc: 0.7581\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5136 - acc: 0.7441 - val_loss: 2.4511 - val_acc: 0.7563\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4169 - acc: 0.7563 - val_loss: 2.3767 - val_acc: 0.7631\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3861 - acc: 0.7658 - val_loss: 2.5086 - val_acc: 0.7481\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5835 - acc: 0.7384 - val_loss: 2.1000 - val_acc: 0.7862\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4815 - acc: 0.7511 - val_loss: 2.2534 - val_acc: 0.7706\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4860 - acc: 0.7484 - val_loss: 2.4039 - val_acc: 0.7556\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5082 - acc: 0.7489 - val_loss: 1.9282 - val_acc: 0.7994\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4253 - acc: 0.7564 - val_loss: 2.1033 - val_acc: 0.7850\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5287 - acc: 0.7442 - val_loss: 2.4962 - val_acc: 0.7462\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5715 - acc: 0.7384 - val_loss: 2.4503 - val_acc: 0.7444\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3680 - acc: 0.7623 - val_loss: 2.3252 - val_acc: 0.7681\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4499 - acc: 0.7545 - val_loss: 2.0477 - val_acc: 0.7856\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4776 - acc: 0.7511 - val_loss: 2.3260 - val_acc: 0.7625\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4615 - acc: 0.7520 - val_loss: 2.0447 - val_acc: 0.7919\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4818 - acc: 0.7488 - val_loss: 2.0428 - val_acc: 0.7862\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4416 - acc: 0.7519 - val_loss: 2.3635 - val_acc: 0.7550\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4008 - acc: 0.7598 - val_loss: 2.2158 - val_acc: 0.7750\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5363 - acc: 0.7417 - val_loss: 2.2686 - val_acc: 0.7650\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5548 - acc: 0.7417 - val_loss: 2.2927 - val_acc: 0.7700\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5441 - acc: 0.7456 - val_loss: 2.5482 - val_acc: 0.7506\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5637 - acc: 0.7463 - val_loss: 2.2758 - val_acc: 0.7719\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4919 - acc: 0.7534 - val_loss: 2.1670 - val_acc: 0.7788\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.5642 - acc: 0.7459 - val_loss: 2.2966 - val_acc: 0.7738\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4233 - acc: 0.7619 - val_loss: 2.5083 - val_acc: 0.7481\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5211 - acc: 0.7486 - val_loss: 2.4600 - val_acc: 0.7569\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4158 - acc: 0.7656 - val_loss: 2.5870 - val_acc: 0.7419\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4656 - acc: 0.7541 - val_loss: 2.5826 - val_acc: 0.7406\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6074 - acc: 0.7350 - val_loss: 2.4652 - val_acc: 0.7550\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4968 - acc: 0.7475 - val_loss: 2.2048 - val_acc: 0.7681\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4387 - acc: 0.7545 - val_loss: 2.4861 - val_acc: 0.7487\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4190 - acc: 0.7561 - val_loss: 2.1399 - val_acc: 0.7731\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5906 - acc: 0.7352 - val_loss: 2.1709 - val_acc: 0.7856\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5766 - acc: 0.7361 - val_loss: 2.2727 - val_acc: 0.7575\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4497 - acc: 0.7511 - val_loss: 2.3373 - val_acc: 0.7563\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4705 - acc: 0.7502 - val_loss: 2.0869 - val_acc: 0.7788\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4687 - acc: 0.7531 - val_loss: 2.2232 - val_acc: 0.7694\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4563 - acc: 0.7534 - val_loss: 2.1608 - val_acc: 0.7750\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4340 - acc: 0.7547 - val_loss: 2.0489 - val_acc: 0.7794\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5778 - acc: 0.7434 - val_loss: 2.3086 - val_acc: 0.7594\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5251 - acc: 0.7502 - val_loss: 2.2106 - val_acc: 0.7588\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5284 - acc: 0.7456 - val_loss: 2.2541 - val_acc: 0.7569\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4253 - acc: 0.7627 - val_loss: 2.1849 - val_acc: 0.7625\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6454 - acc: 0.7336 - val_loss: 2.0421 - val_acc: 0.7781\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6165 - acc: 0.7386 - val_loss: 2.2179 - val_acc: 0.7569\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5819 - acc: 0.7405 - val_loss: 2.1224 - val_acc: 0.7763\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5469 - acc: 0.7481 - val_loss: 2.2245 - val_acc: 0.7606\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5730 - acc: 0.7367 - val_loss: 2.1604 - val_acc: 0.7531\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4813 - acc: 0.7567 - val_loss: 2.2843 - val_acc: 0.7500\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5818 - acc: 0.7370 - val_loss: 2.3131 - val_acc: 0.7475\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5434 - acc: 0.7402 - val_loss: 2.2423 - val_acc: 0.7550\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4932 - acc: 0.7498 - val_loss: 2.0359 - val_acc: 0.7788\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5489 - acc: 0.7423 - val_loss: 2.2545 - val_acc: 0.7700\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5790 - acc: 0.7344 - val_loss: 2.2520 - val_acc: 0.7625\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5095 - acc: 0.7488 - val_loss: 2.1414 - val_acc: 0.7688\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4561 - acc: 0.7531 - val_loss: 2.1436 - val_acc: 0.7706\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5226 - acc: 0.7411 - val_loss: 1.9508 - val_acc: 0.7806\n",
      "Epoch 1150/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5496 - acc: 0.7400 - val_loss: 2.1930 - val_acc: 0.7638\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6343 - acc: 0.7253 - val_loss: 2.3705 - val_acc: 0.7556\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4657 - acc: 0.7502 - val_loss: 2.2532 - val_acc: 0.7619\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4858 - acc: 0.7452 - val_loss: 2.2304 - val_acc: 0.7700\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4554 - acc: 0.7544 - val_loss: 2.3175 - val_acc: 0.7581\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5150 - acc: 0.7444 - val_loss: 2.1366 - val_acc: 0.7781\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4505 - acc: 0.7517 - val_loss: 2.0119 - val_acc: 0.7844\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5606 - acc: 0.7375 - val_loss: 2.4999 - val_acc: 0.7400\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5488 - acc: 0.7420 - val_loss: 2.0561 - val_acc: 0.7831\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4955 - acc: 0.7473 - val_loss: 2.2761 - val_acc: 0.7575\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5848 - acc: 0.7313 - val_loss: 2.5470 - val_acc: 0.7344\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5203 - acc: 0.7405 - val_loss: 2.0509 - val_acc: 0.7725\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4264 - acc: 0.7561 - val_loss: 2.2004 - val_acc: 0.7631\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5193 - acc: 0.7406 - val_loss: 2.1629 - val_acc: 0.7631\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4297 - acc: 0.7578 - val_loss: 1.9595 - val_acc: 0.7925\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4816 - acc: 0.7445 - val_loss: 2.1039 - val_acc: 0.7800\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4242 - acc: 0.7530 - val_loss: 2.3263 - val_acc: 0.7563\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4738 - acc: 0.7467 - val_loss: 1.8723 - val_acc: 0.7994\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5418 - acc: 0.7420 - val_loss: 2.2229 - val_acc: 0.7656\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4688 - acc: 0.7463 - val_loss: 2.3609 - val_acc: 0.7556\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3862 - acc: 0.7586 - val_loss: 2.1622 - val_acc: 0.7738\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5422 - acc: 0.7350 - val_loss: 2.3292 - val_acc: 0.7581\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5947 - acc: 0.7272 - val_loss: 2.4099 - val_acc: 0.7481\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4170 - acc: 0.7541 - val_loss: 2.2813 - val_acc: 0.7644\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6255 - acc: 0.7295 - val_loss: 2.2349 - val_acc: 0.7713\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5405 - acc: 0.7389 - val_loss: 2.0648 - val_acc: 0.7756\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.4816 - acc: 0.7473 - val_loss: 2.2702 - val_acc: 0.7450\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5253 - acc: 0.7392 - val_loss: 2.1678 - val_acc: 0.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4514 - acc: 0.7472 - val_loss: 1.9040 - val_acc: 0.7975\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4088 - acc: 0.7553 - val_loss: 2.2349 - val_acc: 0.7694\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4595 - acc: 0.7491 - val_loss: 2.3487 - val_acc: 0.7581\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4671 - acc: 0.7458 - val_loss: 2.4060 - val_acc: 0.7513\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4116 - acc: 0.7552 - val_loss: 2.1979 - val_acc: 0.7738\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4795 - acc: 0.7484 - val_loss: 2.3269 - val_acc: 0.7556\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4023 - acc: 0.7562 - val_loss: 2.0382 - val_acc: 0.7881\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4766 - acc: 0.7455 - val_loss: 2.1456 - val_acc: 0.7812\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4490 - acc: 0.7514 - val_loss: 2.1761 - val_acc: 0.7788\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4050 - acc: 0.7589 - val_loss: 1.9690 - val_acc: 0.7919\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4321 - acc: 0.7530 - val_loss: 2.2736 - val_acc: 0.7581\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4423 - acc: 0.7458 - val_loss: 2.0940 - val_acc: 0.7812\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5147 - acc: 0.7402 - val_loss: 2.1802 - val_acc: 0.7731\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4554 - acc: 0.7500 - val_loss: 2.3048 - val_acc: 0.7631\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4366 - acc: 0.7513 - val_loss: 2.2568 - val_acc: 0.7581\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4822 - acc: 0.7483 - val_loss: 2.0286 - val_acc: 0.7781\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4078 - acc: 0.7555 - val_loss: 2.0550 - val_acc: 0.7862\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4905 - acc: 0.7478 - val_loss: 2.3512 - val_acc: 0.7613\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3858 - acc: 0.7600 - val_loss: 2.2864 - val_acc: 0.7525\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5287 - acc: 0.7403 - val_loss: 2.1554 - val_acc: 0.7775\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5042 - acc: 0.7406 - val_loss: 2.3179 - val_acc: 0.7531\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4254 - acc: 0.7534 - val_loss: 2.2378 - val_acc: 0.7688\n",
      "Epoch 1200/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4400 - acc: 0.7531 - val_loss: 2.3358 - val_acc: 0.7550\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4586 - acc: 0.7500 - val_loss: 2.1311 - val_acc: 0.7869\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.4911 - acc: 0.7430 - val_loss: 2.1402 - val_acc: 0.7725\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3649 - acc: 0.7595 - val_loss: 2.1677 - val_acc: 0.7731\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5500 - acc: 0.7334 - val_loss: 2.2039 - val_acc: 0.7650\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4850 - acc: 0.7442 - val_loss: 2.0529 - val_acc: 0.7769\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3957 - acc: 0.7553 - val_loss: 2.6654 - val_acc: 0.7256\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4885 - acc: 0.7445 - val_loss: 2.2187 - val_acc: 0.7706\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4452 - acc: 0.7511 - val_loss: 2.3050 - val_acc: 0.7613\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4775 - acc: 0.7475 - val_loss: 2.3025 - val_acc: 0.7588\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4486 - acc: 0.7509 - val_loss: 2.2214 - val_acc: 0.7756\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4410 - acc: 0.7523 - val_loss: 2.4875 - val_acc: 0.7350\n",
      "Epoch 1212/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5139 - acc: 0.7394 - val_loss: 2.2587 - val_acc: 0.7613\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4993 - acc: 0.7442 - val_loss: 2.1419 - val_acc: 0.7725\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4579 - acc: 0.7458 - val_loss: 2.1445 - val_acc: 0.7731\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4737 - acc: 0.7447 - val_loss: 2.1572 - val_acc: 0.7750\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4780 - acc: 0.7455 - val_loss: 2.1723 - val_acc: 0.7644\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4161 - acc: 0.7531 - val_loss: 2.2088 - val_acc: 0.7700\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3224 - acc: 0.7703 - val_loss: 2.1063 - val_acc: 0.7819\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4866 - acc: 0.7405 - val_loss: 2.2594 - val_acc: 0.7675\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3960 - acc: 0.7578 - val_loss: 2.2359 - val_acc: 0.7719\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4927 - acc: 0.7444 - val_loss: 1.7870 - val_acc: 0.8075\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6047 - acc: 0.7361 - val_loss: 2.4308 - val_acc: 0.7588\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4861 - acc: 0.7619 - val_loss: 2.1877 - val_acc: 0.7775\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4616 - acc: 0.7589 - val_loss: 2.1846 - val_acc: 0.7794\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5994 - acc: 0.7372 - val_loss: 2.3381 - val_acc: 0.7675\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6171 - acc: 0.7359 - val_loss: 2.3888 - val_acc: 0.7700\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4742 - acc: 0.7534 - val_loss: 2.3737 - val_acc: 0.7794\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4554 - acc: 0.7542 - val_loss: 2.1842 - val_acc: 0.7881\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5276 - acc: 0.7516 - val_loss: 2.4055 - val_acc: 0.7538\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6181 - acc: 0.7469 - val_loss: 2.3066 - val_acc: 0.7588\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6263 - acc: 0.7430 - val_loss: 2.1695 - val_acc: 0.7756\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4821 - acc: 0.7592 - val_loss: 2.2127 - val_acc: 0.7769\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5150 - acc: 0.7569 - val_loss: 2.2054 - val_acc: 0.7606\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4938 - acc: 0.7591 - val_loss: 2.3289 - val_acc: 0.7544\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5603 - acc: 0.7452 - val_loss: 2.1310 - val_acc: 0.7831\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4867 - acc: 0.7544 - val_loss: 2.1405 - val_acc: 0.7706\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5303 - acc: 0.7484 - val_loss: 2.3057 - val_acc: 0.7581\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5271 - acc: 0.7497 - val_loss: 2.2406 - val_acc: 0.7619\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4554 - acc: 0.7602 - val_loss: 2.2545 - val_acc: 0.7500\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4717 - acc: 0.7552 - val_loss: 2.1441 - val_acc: 0.7725\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4555 - acc: 0.7552 - val_loss: 1.9993 - val_acc: 0.7812\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4105 - acc: 0.7653 - val_loss: 2.2353 - val_acc: 0.7613\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4905 - acc: 0.7541 - val_loss: 2.2177 - val_acc: 0.7669\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4706 - acc: 0.7569 - val_loss: 2.5271 - val_acc: 0.7331\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4563 - acc: 0.7592 - val_loss: 2.1271 - val_acc: 0.7738\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4109 - acc: 0.7614 - val_loss: 2.1040 - val_acc: 0.7725\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4214 - acc: 0.7592 - val_loss: 2.2613 - val_acc: 0.7638\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5021 - acc: 0.7473 - val_loss: 2.3292 - val_acc: 0.7575\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4644 - acc: 0.7567 - val_loss: 2.2317 - val_acc: 0.7644\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5573 - acc: 0.7409 - val_loss: 2.0710 - val_acc: 0.7763\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5715 - acc: 0.7439 - val_loss: 2.3968 - val_acc: 0.7531\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5152 - acc: 0.7489 - val_loss: 2.0528 - val_acc: 0.7794\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4956 - acc: 0.7512 - val_loss: 2.0313 - val_acc: 0.7794\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4304 - acc: 0.7614 - val_loss: 1.9486 - val_acc: 0.7894\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4734 - acc: 0.7553 - val_loss: 2.3483 - val_acc: 0.7569\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4928 - acc: 0.7511 - val_loss: 2.2115 - val_acc: 0.7688\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4497 - acc: 0.7625 - val_loss: 2.0879 - val_acc: 0.7763\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4594 - acc: 0.7542 - val_loss: 2.4165 - val_acc: 0.7462\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4796 - acc: 0.7522 - val_loss: 2.2181 - val_acc: 0.7638\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5547 - acc: 0.7378 - val_loss: 2.2164 - val_acc: 0.7756\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4788 - acc: 0.7534 - val_loss: 1.9790 - val_acc: 0.7881\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4245 - acc: 0.7563 - val_loss: 2.1449 - val_acc: 0.7663\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4661 - acc: 0.7500 - val_loss: 2.1670 - val_acc: 0.7644\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4712 - acc: 0.7494 - val_loss: 2.2310 - val_acc: 0.7663\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5070 - acc: 0.7462 - val_loss: 2.1947 - val_acc: 0.7550\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5123 - acc: 0.7477 - val_loss: 2.2997 - val_acc: 0.7531\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3867 - acc: 0.7644 - val_loss: 2.6915 - val_acc: 0.7200\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5357 - acc: 0.7442 - val_loss: 2.0649 - val_acc: 0.7819\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5044 - acc: 0.7481 - val_loss: 2.0639 - val_acc: 0.7731\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4120 - acc: 0.7592 - val_loss: 1.9824 - val_acc: 0.7925\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4943 - acc: 0.7477 - val_loss: 2.1197 - val_acc: 0.7756\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5357 - acc: 0.7400 - val_loss: 2.3074 - val_acc: 0.7500\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4860 - acc: 0.7461 - val_loss: 2.2164 - val_acc: 0.7638\n",
      "Epoch 1274/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5607 - acc: 0.7388 - val_loss: 2.0494 - val_acc: 0.7769\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4884 - acc: 0.7456 - val_loss: 2.2228 - val_acc: 0.7538\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4366 - acc: 0.7550 - val_loss: 2.1301 - val_acc: 0.7788\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4384 - acc: 0.7514 - val_loss: 2.1497 - val_acc: 0.7756\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4360 - acc: 0.7547 - val_loss: 2.3486 - val_acc: 0.7506\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4638 - acc: 0.7527 - val_loss: 2.2946 - val_acc: 0.7569\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4151 - acc: 0.7586 - val_loss: 1.7217 - val_acc: 0.8194\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3598 - acc: 0.7645 - val_loss: 2.0537 - val_acc: 0.7806\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4065 - acc: 0.7605 - val_loss: 2.3094 - val_acc: 0.7569\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3979 - acc: 0.7581 - val_loss: 2.1521 - val_acc: 0.7594\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4668 - acc: 0.7505 - val_loss: 2.0848 - val_acc: 0.7781\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5067 - acc: 0.7433 - val_loss: 1.9516 - val_acc: 0.7837\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4406 - acc: 0.7530 - val_loss: 2.2602 - val_acc: 0.7575\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3585 - acc: 0.7648 - val_loss: 2.0486 - val_acc: 0.7806\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4481 - acc: 0.7523 - val_loss: 2.2532 - val_acc: 0.7575\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4750 - acc: 0.7483 - val_loss: 1.9334 - val_acc: 0.7925\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4831 - acc: 0.7450 - val_loss: 2.2251 - val_acc: 0.7600\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4476 - acc: 0.7487 - val_loss: 1.9358 - val_acc: 0.7912\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4920 - acc: 0.7428 - val_loss: 2.0936 - val_acc: 0.7788\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4295 - acc: 0.7503 - val_loss: 2.2535 - val_acc: 0.7519\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4562 - acc: 0.7517 - val_loss: 2.6438 - val_acc: 0.7269\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4822 - acc: 0.7420 - val_loss: 2.1235 - val_acc: 0.7788\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4604 - acc: 0.7475 - val_loss: 2.1567 - val_acc: 0.7744\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5679 - acc: 0.7330 - val_loss: 2.1446 - val_acc: 0.7794\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5331 - acc: 0.7338 - val_loss: 2.3728 - val_acc: 0.7469\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3881 - acc: 0.7597 - val_loss: 2.0209 - val_acc: 0.7850\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3766 - acc: 0.7567 - val_loss: 1.9233 - val_acc: 0.7919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4688 - acc: 0.7478 - val_loss: 2.7479 - val_acc: 0.7362\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4514 - acc: 0.7488 - val_loss: 2.0980 - val_acc: 0.7819\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4675 - acc: 0.7431 - val_loss: 2.0141 - val_acc: 0.7875\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4827 - acc: 0.7459 - val_loss: 2.1624 - val_acc: 0.7706\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4587 - acc: 0.7459 - val_loss: 2.2451 - val_acc: 0.7563\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4194 - acc: 0.7534 - val_loss: 2.3530 - val_acc: 0.7462\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4987 - acc: 0.7417 - val_loss: 2.5123 - val_acc: 0.7369\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3655 - acc: 0.7606 - val_loss: 2.2402 - val_acc: 0.7638\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4781 - acc: 0.7439 - val_loss: 2.3210 - val_acc: 0.7481\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4783 - acc: 0.7480 - val_loss: 2.3296 - val_acc: 0.7525\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4818 - acc: 0.7442 - val_loss: 2.3962 - val_acc: 0.7525\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4036 - acc: 0.7572 - val_loss: 2.4625 - val_acc: 0.7381\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5175 - acc: 0.7384 - val_loss: 2.0937 - val_acc: 0.7744\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4943 - acc: 0.7423 - val_loss: 2.1362 - val_acc: 0.7744\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4218 - acc: 0.7548 - val_loss: 2.1233 - val_acc: 0.7800\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5457 - acc: 0.7352 - val_loss: 2.2153 - val_acc: 0.7744\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4227 - acc: 0.7503 - val_loss: 2.1328 - val_acc: 0.7775\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4884 - acc: 0.7458 - val_loss: 2.3185 - val_acc: 0.7638\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4996 - acc: 0.7394 - val_loss: 2.1723 - val_acc: 0.7800\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4898 - acc: 0.7427 - val_loss: 2.5250 - val_acc: 0.7381\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4972 - acc: 0.7406 - val_loss: 1.9736 - val_acc: 0.7900\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4690 - acc: 0.7455 - val_loss: 2.3792 - val_acc: 0.7606\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4358 - acc: 0.7488 - val_loss: 2.3025 - val_acc: 0.7675\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4371 - acc: 0.7512 - val_loss: 2.3436 - val_acc: 0.7531\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4648 - acc: 0.7448 - val_loss: 2.0416 - val_acc: 0.7919\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4481 - acc: 0.7487 - val_loss: 2.1956 - val_acc: 0.7731\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3705 - acc: 0.7612 - val_loss: 2.1820 - val_acc: 0.7769\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4206 - acc: 0.7495 - val_loss: 2.0923 - val_acc: 0.7812\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3979 - acc: 0.7556 - val_loss: 2.3414 - val_acc: 0.7619\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3870 - acc: 0.7561 - val_loss: 2.2468 - val_acc: 0.7756\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4345 - acc: 0.7483 - val_loss: 2.2586 - val_acc: 0.7588\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4382 - acc: 0.7492 - val_loss: 2.2369 - val_acc: 0.7744\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4736 - acc: 0.7467 - val_loss: 2.4079 - val_acc: 0.7444\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.5123 - acc: 0.7370 - val_loss: 2.2407 - val_acc: 0.7688\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4170 - acc: 0.7525 - val_loss: 2.2819 - val_acc: 0.7575\n",
      "Epoch 1336/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4647 - acc: 0.7469 - val_loss: 2.1116 - val_acc: 0.7744\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.3721 - acc: 0.7592 - val_loss: 2.0535 - val_acc: 0.7881\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4908 - acc: 0.7417 - val_loss: 2.1807 - val_acc: 0.7675\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4508 - acc: 0.7452 - val_loss: 2.3565 - val_acc: 0.7681\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5092 - acc: 0.7378 - val_loss: 2.1683 - val_acc: 0.7763\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3951 - acc: 0.7547 - val_loss: 2.5102 - val_acc: 0.7544\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3894 - acc: 0.7552 - val_loss: 2.4300 - val_acc: 0.7494\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4882 - acc: 0.7428 - val_loss: 2.3717 - val_acc: 0.7475\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4397 - acc: 0.7481 - val_loss: 2.0557 - val_acc: 0.7806\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4348 - acc: 0.7463 - val_loss: 1.9500 - val_acc: 0.7931\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5146 - acc: 0.7375 - val_loss: 2.5527 - val_acc: 0.7369\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4260 - acc: 0.7477 - val_loss: 2.3329 - val_acc: 0.7613\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4122 - acc: 0.7500 - val_loss: 1.8589 - val_acc: 0.8094\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4668 - acc: 0.7434 - val_loss: 2.2962 - val_acc: 0.7600\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3484 - acc: 0.7620 - val_loss: 2.1714 - val_acc: 0.7738\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4665 - acc: 0.7398 - val_loss: 2.2833 - val_acc: 0.7619\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3197 - acc: 0.7619 - val_loss: 2.3011 - val_acc: 0.7694\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4939 - acc: 0.7355 - val_loss: 2.5286 - val_acc: 0.7487\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4159 - acc: 0.7539 - val_loss: 2.0675 - val_acc: 0.7869\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4759 - acc: 0.7416 - val_loss: 2.3581 - val_acc: 0.7575\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5021 - acc: 0.7408 - val_loss: 1.8733 - val_acc: 0.8081\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3288 - acc: 0.7636 - val_loss: 2.5787 - val_acc: 0.7350\n",
      "Epoch 1358/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3810 - acc: 0.7550 - val_loss: 2.1508 - val_acc: 0.7750\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4301 - acc: 0.7500 - val_loss: 1.9487 - val_acc: 0.7887\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3274 - acc: 0.7666 - val_loss: 2.3575 - val_acc: 0.7631\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3933 - acc: 0.7506 - val_loss: 2.3285 - val_acc: 0.7594\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4115 - acc: 0.7503 - val_loss: 2.1107 - val_acc: 0.7750\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4258 - acc: 0.7456 - val_loss: 2.2769 - val_acc: 0.7706\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5005 - acc: 0.7369 - val_loss: 2.2193 - val_acc: 0.7681\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3480 - acc: 0.7578 - val_loss: 2.4809 - val_acc: 0.7481\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3084 - acc: 0.7611 - val_loss: 2.2509 - val_acc: 0.7713\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4621 - acc: 0.7459 - val_loss: 2.3025 - val_acc: 0.7606\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4238 - acc: 0.7448 - val_loss: 2.0464 - val_acc: 0.7931\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4153 - acc: 0.7522 - val_loss: 2.1232 - val_acc: 0.7894\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3758 - acc: 0.7522 - val_loss: 2.2442 - val_acc: 0.7788\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4505 - acc: 0.7438 - val_loss: 2.1705 - val_acc: 0.7794\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4480 - acc: 0.7456 - val_loss: 1.9720 - val_acc: 0.7894\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3555 - acc: 0.7584 - val_loss: 2.1575 - val_acc: 0.7844\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4253 - acc: 0.7481 - val_loss: 2.3187 - val_acc: 0.7650\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4303 - acc: 0.7422 - val_loss: 2.1268 - val_acc: 0.7906\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4081 - acc: 0.7486 - val_loss: 2.0564 - val_acc: 0.7819\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4178 - acc: 0.7481 - val_loss: 2.3293 - val_acc: 0.7531\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4051 - acc: 0.7527 - val_loss: 1.9483 - val_acc: 0.8006\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3649 - acc: 0.7534 - val_loss: 2.0208 - val_acc: 0.7844\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4508 - acc: 0.7433 - val_loss: 2.2398 - val_acc: 0.7725\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4076 - acc: 0.7444 - val_loss: 2.4796 - val_acc: 0.7381\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3847 - acc: 0.7477 - val_loss: 2.2932 - val_acc: 0.7744\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4296 - acc: 0.7437 - val_loss: 2.0791 - val_acc: 0.7763\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4607 - acc: 0.7395 - val_loss: 2.2137 - val_acc: 0.7781\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4156 - acc: 0.7478 - val_loss: 2.3042 - val_acc: 0.7631\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.4157 - acc: 0.7483 - val_loss: 2.2534 - val_acc: 0.7756\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3563 - acc: 0.7588 - val_loss: 2.0199 - val_acc: 0.7862\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4048 - acc: 0.7458 - val_loss: 2.1375 - val_acc: 0.7800\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3670 - acc: 0.7520 - val_loss: 2.5417 - val_acc: 0.7456\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3310 - acc: 0.7567 - val_loss: 2.1993 - val_acc: 0.7706\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3746 - acc: 0.7530 - val_loss: 2.0501 - val_acc: 0.7831\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4473 - acc: 0.7409 - val_loss: 2.3700 - val_acc: 0.7606\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2673 - acc: 0.7706 - val_loss: 2.4145 - val_acc: 0.7506\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3109 - acc: 0.7672 - val_loss: 2.3075 - val_acc: 0.7700\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4122 - acc: 0.7477 - val_loss: 2.3042 - val_acc: 0.7650\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4804 - acc: 0.7366 - val_loss: 2.2210 - val_acc: 0.7781\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3913 - acc: 0.7500 - val_loss: 2.2193 - val_acc: 0.7706\n",
      "Epoch 1398/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4280 - acc: 0.7450 - val_loss: 2.1754 - val_acc: 0.7763\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3823 - acc: 0.7547 - val_loss: 2.1005 - val_acc: 0.7844\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3514 - acc: 0.7573 - val_loss: 2.0741 - val_acc: 0.7881\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4692 - acc: 0.7395 - val_loss: 2.2650 - val_acc: 0.7719\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3564 - acc: 0.7561 - val_loss: 2.1104 - val_acc: 0.7794\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3845 - acc: 0.7491 - val_loss: 2.2760 - val_acc: 0.7663\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3989 - acc: 0.7456 - val_loss: 2.0216 - val_acc: 0.7869\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3325 - acc: 0.7588 - val_loss: 2.1524 - val_acc: 0.7744\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3450 - acc: 0.7567 - val_loss: 2.1718 - val_acc: 0.7812\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4035 - acc: 0.7494 - val_loss: 6.3076 - val_acc: 0.5031\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3926 - acc: 0.7484 - val_loss: 2.2867 - val_acc: 0.7669\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4202 - acc: 0.7450 - val_loss: 2.2143 - val_acc: 0.7750\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3876 - acc: 0.7513 - val_loss: 2.1920 - val_acc: 0.7719\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3744 - acc: 0.7511 - val_loss: 2.0671 - val_acc: 0.7819\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3469 - acc: 0.7577 - val_loss: 2.2114 - val_acc: 0.7675\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4214 - acc: 0.7439 - val_loss: 2.4542 - val_acc: 0.7444\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3703 - acc: 0.7566 - val_loss: 2.4057 - val_acc: 0.7531\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3563 - acc: 0.7580 - val_loss: 2.0093 - val_acc: 0.7912\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3507 - acc: 0.7564 - val_loss: 2.1186 - val_acc: 0.7750\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4730 - acc: 0.7420 - val_loss: 2.3325 - val_acc: 0.7613\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4438 - acc: 0.7431 - val_loss: 2.1213 - val_acc: 0.7781\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2901 - acc: 0.7653 - val_loss: 2.1145 - val_acc: 0.7781\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3225 - acc: 0.7570 - val_loss: 2.4855 - val_acc: 0.7538\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3730 - acc: 0.7525 - val_loss: 2.3190 - val_acc: 0.7619\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4305 - acc: 0.7467 - val_loss: 1.9223 - val_acc: 0.8006\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4236 - acc: 0.7459 - val_loss: 2.3098 - val_acc: 0.7688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3660 - acc: 0.7528 - val_loss: 2.2690 - val_acc: 0.7525\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5127 - acc: 0.7361 - val_loss: 1.9497 - val_acc: 0.7969\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3725 - acc: 0.7477 - val_loss: 1.7967 - val_acc: 0.8169\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4214 - acc: 0.7470 - val_loss: 2.2248 - val_acc: 0.7631\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3437 - acc: 0.7595 - val_loss: 2.4384 - val_acc: 0.7531\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3132 - acc: 0.7622 - val_loss: 2.1104 - val_acc: 0.7881\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3251 - acc: 0.7600 - val_loss: 2.1511 - val_acc: 0.7788\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4112 - acc: 0.7495 - val_loss: 2.2795 - val_acc: 0.7638\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3278 - acc: 0.7612 - val_loss: 2.2538 - val_acc: 0.7750\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4152 - acc: 0.7469 - val_loss: 2.2170 - val_acc: 0.7644\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3181 - acc: 0.7597 - val_loss: 2.2509 - val_acc: 0.7731\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3730 - acc: 0.7542 - val_loss: 2.0372 - val_acc: 0.7900\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3925 - acc: 0.7494 - val_loss: 2.4397 - val_acc: 0.7412\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3869 - acc: 0.7492 - val_loss: 2.3172 - val_acc: 0.7631\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3079 - acc: 0.7636 - val_loss: 2.2323 - val_acc: 0.7781\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4012 - acc: 0.7497 - val_loss: 2.1972 - val_acc: 0.7700\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3715 - acc: 0.7536 - val_loss: 2.4554 - val_acc: 0.7475\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3639 - acc: 0.7492 - val_loss: 2.2506 - val_acc: 0.7688\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3522 - acc: 0.7559 - val_loss: 2.1719 - val_acc: 0.7750\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3274 - acc: 0.7609 - val_loss: 2.4982 - val_acc: 0.7487\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3539 - acc: 0.7573 - val_loss: 2.3893 - val_acc: 0.7606\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4536 - acc: 0.7392 - val_loss: 2.3581 - val_acc: 0.7563\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4225 - acc: 0.7427 - val_loss: 2.4875 - val_acc: 0.7481\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4249 - acc: 0.7392 - val_loss: 2.3463 - val_acc: 0.7506\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4398 - acc: 0.7417 - val_loss: 2.0738 - val_acc: 0.7906\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3949 - acc: 0.7459 - val_loss: 2.0472 - val_acc: 0.7956\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3302 - acc: 0.7584 - val_loss: 2.1066 - val_acc: 0.7869\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3371 - acc: 0.7575 - val_loss: 2.2416 - val_acc: 0.7731\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3125 - acc: 0.7592 - val_loss: 2.2352 - val_acc: 0.7775\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2874 - acc: 0.7645 - val_loss: 2.0158 - val_acc: 0.7912\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4868 - acc: 0.7355 - val_loss: 2.3547 - val_acc: 0.7613\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3597 - acc: 0.7534 - val_loss: 2.2232 - val_acc: 0.7775\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2682 - acc: 0.7664 - val_loss: 2.2658 - val_acc: 0.7694\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2870 - acc: 0.7647 - val_loss: 2.4022 - val_acc: 0.7550\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3580 - acc: 0.7528 - val_loss: 2.3245 - val_acc: 0.7606\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4006 - acc: 0.7497 - val_loss: 2.5217 - val_acc: 0.7444\n",
      "Epoch 1460/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4200 - acc: 0.7455 - val_loss: 1.9275 - val_acc: 0.8056\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2807 - acc: 0.7658 - val_loss: 2.4690 - val_acc: 0.7544\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3701 - acc: 0.7514 - val_loss: 2.3104 - val_acc: 0.7606\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3785 - acc: 0.7491 - val_loss: 2.2996 - val_acc: 0.7650\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3837 - acc: 0.7495 - val_loss: 2.5667 - val_acc: 0.7375\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4216 - acc: 0.7478 - val_loss: 1.9159 - val_acc: 0.8019\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3937 - acc: 0.7467 - val_loss: 2.3230 - val_acc: 0.7725\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4130 - acc: 0.7448 - val_loss: 2.1674 - val_acc: 0.7731\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2324 - acc: 0.7700 - val_loss: 2.2891 - val_acc: 0.7663\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4261 - acc: 0.7444 - val_loss: 2.0778 - val_acc: 0.7856\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3543 - acc: 0.7547 - val_loss: 2.0262 - val_acc: 0.7881\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2843 - acc: 0.7616 - val_loss: 2.2932 - val_acc: 0.7713\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5245 - acc: 0.7323 - val_loss: 2.4777 - val_acc: 0.7425\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3415 - acc: 0.7531 - val_loss: 2.2669 - val_acc: 0.7725\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3137 - acc: 0.7591 - val_loss: 2.0204 - val_acc: 0.8031\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3249 - acc: 0.7650 - val_loss: 2.2960 - val_acc: 0.7731\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5032 - acc: 0.7363 - val_loss: 2.2273 - val_acc: 0.7669\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4383 - acc: 0.7422 - val_loss: 2.2171 - val_acc: 0.7788\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4692 - acc: 0.7353 - val_loss: 2.0073 - val_acc: 0.7931\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3669 - acc: 0.7506 - val_loss: 2.3800 - val_acc: 0.7588\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3304 - acc: 0.7578 - val_loss: 2.5115 - val_acc: 0.7563\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3532 - acc: 0.7519 - val_loss: 2.4167 - val_acc: 0.7575\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3574 - acc: 0.7561 - val_loss: 2.1653 - val_acc: 0.7812\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3781 - acc: 0.7523 - val_loss: 2.3676 - val_acc: 0.7462\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3880 - acc: 0.7488 - val_loss: 2.4573 - val_acc: 0.7669\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3682 - acc: 0.7500 - val_loss: 2.1664 - val_acc: 0.7844\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3866 - acc: 0.7448 - val_loss: 2.2072 - val_acc: 0.7769\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3640 - acc: 0.7539 - val_loss: 2.2075 - val_acc: 0.7706\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3764 - acc: 0.7495 - val_loss: 2.0967 - val_acc: 0.7856\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4162 - acc: 0.7442 - val_loss: 2.2186 - val_acc: 0.7806\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4044 - acc: 0.7459 - val_loss: 1.7835 - val_acc: 0.8106\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2986 - acc: 0.7602 - val_loss: 2.2085 - val_acc: 0.7731\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3418 - acc: 0.7522 - val_loss: 2.0042 - val_acc: 0.7944\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4487 - acc: 0.7372 - val_loss: 3.8318 - val_acc: 0.6612\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3416 - acc: 0.7573 - val_loss: 2.0331 - val_acc: 0.7906\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4115 - acc: 0.7461 - val_loss: 2.4078 - val_acc: 0.7513\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3783 - acc: 0.7487 - val_loss: 1.9485 - val_acc: 0.7962\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3888 - acc: 0.7466 - val_loss: 2.1927 - val_acc: 0.7750\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4500 - acc: 0.7389 - val_loss: 2.2496 - val_acc: 0.7781\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3987 - acc: 0.7461 - val_loss: 1.9765 - val_acc: 0.7962\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3413 - acc: 0.7559 - val_loss: 2.3808 - val_acc: 0.7506\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3797 - acc: 0.7498 - val_loss: 2.3299 - val_acc: 0.7625\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4082 - acc: 0.7417 - val_loss: 2.3858 - val_acc: 0.7569\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3775 - acc: 0.7489 - val_loss: 2.3786 - val_acc: 0.7688\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3582 - acc: 0.7545 - val_loss: 2.2496 - val_acc: 0.7769\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3219 - acc: 0.7597 - val_loss: 2.2372 - val_acc: 0.7650\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4359 - acc: 0.7413 - val_loss: 2.2860 - val_acc: 0.7525\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3728 - acc: 0.7473 - val_loss: 2.0533 - val_acc: 0.7812\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4239 - acc: 0.7461 - val_loss: 2.5061 - val_acc: 0.7450\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3648 - acc: 0.7511 - val_loss: 2.2155 - val_acc: 0.7731\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3036 - acc: 0.7591 - val_loss: 2.3106 - val_acc: 0.7763\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3318 - acc: 0.7542 - val_loss: 2.3420 - val_acc: 0.7613\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3033 - acc: 0.7605 - val_loss: 2.1951 - val_acc: 0.7825\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3425 - acc: 0.7559 - val_loss: 2.0159 - val_acc: 0.8062\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3688 - acc: 0.7530 - val_loss: 2.3031 - val_acc: 0.7706\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2516 - acc: 0.7656 - val_loss: 2.1025 - val_acc: 0.7987\n",
      "Epoch 1516/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3495 - acc: 0.7555 - val_loss: 2.0892 - val_acc: 0.7881\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3374 - acc: 0.7545 - val_loss: 2.2845 - val_acc: 0.7738\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4424 - acc: 0.7411 - val_loss: 2.1249 - val_acc: 0.7987\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4808 - acc: 0.7322 - val_loss: 1.9431 - val_acc: 0.8019\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2667 - acc: 0.7641 - val_loss: 2.1893 - val_acc: 0.7775\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3609 - acc: 0.7494 - val_loss: 2.1510 - val_acc: 0.7812\n",
      "Epoch 1522/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3020 - acc: 0.7589 - val_loss: 2.4869 - val_acc: 0.7563\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3631 - acc: 0.7525 - val_loss: 2.2261 - val_acc: 0.7681\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3510 - acc: 0.7480 - val_loss: 2.1628 - val_acc: 0.7850\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3657 - acc: 0.7502 - val_loss: 2.1481 - val_acc: 0.7875\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3254 - acc: 0.7520 - val_loss: 2.1360 - val_acc: 0.7800\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3618 - acc: 0.7459 - val_loss: 2.3001 - val_acc: 0.7681\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3484 - acc: 0.7473 - val_loss: 2.5575 - val_acc: 0.7406\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4579 - acc: 0.7372 - val_loss: 2.1344 - val_acc: 0.7800\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4071 - acc: 0.7519 - val_loss: 2.6907 - val_acc: 0.7369\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4334 - acc: 0.7394 - val_loss: 2.2574 - val_acc: 0.7706\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3917 - acc: 0.7452 - val_loss: 2.1951 - val_acc: 0.7806\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4620 - acc: 0.7350 - val_loss: 2.4600 - val_acc: 0.7506\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4024 - acc: 0.7438 - val_loss: 2.0591 - val_acc: 0.7850\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3102 - acc: 0.7553 - val_loss: 2.4882 - val_acc: 0.7656\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4483 - acc: 0.7442 - val_loss: 2.2493 - val_acc: 0.7594\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3621 - acc: 0.7534 - val_loss: 2.3569 - val_acc: 0.7588\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4101 - acc: 0.7489 - val_loss: 2.3424 - val_acc: 0.7656\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3246 - acc: 0.7631 - val_loss: 2.1241 - val_acc: 0.7912\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3337 - acc: 0.7603 - val_loss: 2.3054 - val_acc: 0.7700\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3768 - acc: 0.7552 - val_loss: 2.2750 - val_acc: 0.7669\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3693 - acc: 0.7517 - val_loss: 2.3147 - val_acc: 0.7625\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2985 - acc: 0.7631 - val_loss: 2.2783 - val_acc: 0.7625\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3287 - acc: 0.7581 - val_loss: 2.2881 - val_acc: 0.7713\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4996 - acc: 0.7387 - val_loss: 2.2155 - val_acc: 0.7788\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3288 - acc: 0.7592 - val_loss: 2.3599 - val_acc: 0.7688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3611 - acc: 0.7561 - val_loss: 2.1155 - val_acc: 0.7844\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3256 - acc: 0.7597 - val_loss: 2.4151 - val_acc: 0.7575\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3470 - acc: 0.7567 - val_loss: 2.2705 - val_acc: 0.7713\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3800 - acc: 0.7533 - val_loss: 2.3318 - val_acc: 0.7694\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4868 - acc: 0.7361 - val_loss: 2.2280 - val_acc: 0.7769\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3448 - acc: 0.7572 - val_loss: 2.2500 - val_acc: 0.7825\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2559 - acc: 0.7680 - val_loss: 2.4356 - val_acc: 0.7644\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4904 - acc: 0.7352 - val_loss: 2.2385 - val_acc: 0.7719\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3230 - acc: 0.7603 - val_loss: 1.9655 - val_acc: 0.8150\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3676 - acc: 0.7527 - val_loss: 2.6070 - val_acc: 0.7394\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3153 - acc: 0.7597 - val_loss: 2.3986 - val_acc: 0.7631\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3616 - acc: 0.7508 - val_loss: 2.1869 - val_acc: 0.7800\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4094 - acc: 0.7447 - val_loss: 1.9192 - val_acc: 0.8006\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3665 - acc: 0.7503 - val_loss: 2.3021 - val_acc: 0.7700\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4015 - acc: 0.7478 - val_loss: 2.3149 - val_acc: 0.7531\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4220 - acc: 0.7448 - val_loss: 2.2825 - val_acc: 0.7775\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3726 - acc: 0.7498 - val_loss: 2.2116 - val_acc: 0.7781\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3436 - acc: 0.7547 - val_loss: 1.9310 - val_acc: 0.8075\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3382 - acc: 0.7572 - val_loss: 2.4135 - val_acc: 0.7638\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3297 - acc: 0.7577 - val_loss: 2.2840 - val_acc: 0.7744\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3401 - acc: 0.7547 - val_loss: 2.2330 - val_acc: 0.7756\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3211 - acc: 0.7527 - val_loss: 2.3846 - val_acc: 0.7606\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4246 - acc: 0.7436 - val_loss: 2.3990 - val_acc: 0.7581\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3195 - acc: 0.7613 - val_loss: 2.4317 - val_acc: 0.7550\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3301 - acc: 0.7534 - val_loss: 2.4976 - val_acc: 0.7456\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4039 - acc: 0.7477 - val_loss: 2.2006 - val_acc: 0.7800\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3396 - acc: 0.7555 - val_loss: 2.4388 - val_acc: 0.7513\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4079 - acc: 0.7441 - val_loss: 2.4249 - val_acc: 0.7631\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3451 - acc: 0.7534 - val_loss: 2.1814 - val_acc: 0.7694\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3349 - acc: 0.7533 - val_loss: 2.4020 - val_acc: 0.7656\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3777 - acc: 0.7514 - val_loss: 2.4925 - val_acc: 0.7569\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3856 - acc: 0.7508 - val_loss: 2.4184 - val_acc: 0.7600\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3445 - acc: 0.7512 - val_loss: 2.1586 - val_acc: 0.7769\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2951 - acc: 0.7625 - val_loss: 2.1549 - val_acc: 0.7819\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3143 - acc: 0.7597 - val_loss: 2.2181 - val_acc: 0.7756\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3768 - acc: 0.7484 - val_loss: 2.3498 - val_acc: 0.7688\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3013 - acc: 0.7609 - val_loss: 2.3913 - val_acc: 0.7625\n",
      "Epoch 1584/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3181 - acc: 0.7553 - val_loss: 2.1762 - val_acc: 0.7900\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4187 - acc: 0.7394 - val_loss: 2.0747 - val_acc: 0.7894\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3555 - acc: 0.7512 - val_loss: 2.4033 - val_acc: 0.7663\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3840 - acc: 0.7503 - val_loss: 2.5148 - val_acc: 0.7444\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4270 - acc: 0.7416 - val_loss: 2.2644 - val_acc: 0.7675\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2107 - acc: 0.7767 - val_loss: 2.2703 - val_acc: 0.7788\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3712 - acc: 0.7477 - val_loss: 2.4703 - val_acc: 0.7556\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3329 - acc: 0.7517 - val_loss: 2.4159 - val_acc: 0.7550\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3611 - acc: 0.7531 - val_loss: 2.4475 - val_acc: 0.7650\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3141 - acc: 0.7567 - val_loss: 2.2605 - val_acc: 0.7744\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4373 - acc: 0.7408 - val_loss: 2.3035 - val_acc: 0.7713\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3315 - acc: 0.7542 - val_loss: 2.3658 - val_acc: 0.7650\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2975 - acc: 0.7600 - val_loss: 2.1502 - val_acc: 0.7850\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3824 - acc: 0.7486 - val_loss: 2.4325 - val_acc: 0.7663\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.3161 - acc: 0.7634 - val_loss: 2.2948 - val_acc: 0.7825\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4081 - acc: 0.7475 - val_loss: 2.2916 - val_acc: 0.7694\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3531 - acc: 0.7520 - val_loss: 2.1181 - val_acc: 0.7875\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4489 - acc: 0.7367 - val_loss: 2.3305 - val_acc: 0.7725\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3647 - acc: 0.7517 - val_loss: 2.4398 - val_acc: 0.7606\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3484 - acc: 0.7500 - val_loss: 2.4397 - val_acc: 0.7588\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3947 - acc: 0.7445 - val_loss: 2.0784 - val_acc: 0.7919\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3051 - acc: 0.7611 - val_loss: 2.2394 - val_acc: 0.7700\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4153 - acc: 0.7434 - val_loss: 2.0776 - val_acc: 0.7950\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4504 - acc: 0.7339 - val_loss: 2.6088 - val_acc: 0.7412\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3364 - acc: 0.7505 - val_loss: 2.1321 - val_acc: 0.7825\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2971 - acc: 0.7564 - val_loss: 2.2166 - val_acc: 0.7831\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2965 - acc: 0.7567 - val_loss: 2.2048 - val_acc: 0.7844\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3768 - acc: 0.7484 - val_loss: 2.1956 - val_acc: 0.7800\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2921 - acc: 0.7561 - val_loss: 2.5867 - val_acc: 0.7425\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3558 - acc: 0.7488 - val_loss: 2.2128 - val_acc: 0.7731\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3435 - acc: 0.7491 - val_loss: 2.5889 - val_acc: 0.7412\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2767 - acc: 0.7602 - val_loss: 2.7995 - val_acc: 0.7194\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2898 - acc: 0.7558 - val_loss: 2.5207 - val_acc: 0.7425\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4583 - acc: 0.7334 - val_loss: 2.4259 - val_acc: 0.7600\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3194 - acc: 0.7591 - val_loss: 2.0970 - val_acc: 0.7831\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3075 - acc: 0.7558 - val_loss: 2.2299 - val_acc: 0.7806\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3137 - acc: 0.7573 - val_loss: 2.3454 - val_acc: 0.7694\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3173 - acc: 0.7539 - val_loss: 2.7477 - val_acc: 0.7312\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3308 - acc: 0.7523 - val_loss: 2.5534 - val_acc: 0.7500\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3188 - acc: 0.7544 - val_loss: 2.3268 - val_acc: 0.7681\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4335 - acc: 0.7406 - val_loss: 2.1747 - val_acc: 0.7806\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5021 - acc: 0.7280 - val_loss: 1.9737 - val_acc: 0.8031\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3438 - acc: 0.7530 - val_loss: 2.1885 - val_acc: 0.7850\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4207 - acc: 0.7391 - val_loss: 2.2819 - val_acc: 0.7619\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3536 - acc: 0.7509 - val_loss: 2.3868 - val_acc: 0.7644\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2676 - acc: 0.7636 - val_loss: 2.3339 - val_acc: 0.7663\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3567 - acc: 0.7453 - val_loss: 2.0881 - val_acc: 0.7950\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3361 - acc: 0.7508 - val_loss: 2.3944 - val_acc: 0.7681\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3689 - acc: 0.7461 - val_loss: 2.3121 - val_acc: 0.7675\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2923 - acc: 0.7575 - val_loss: 2.3277 - val_acc: 0.7675\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2832 - acc: 0.7584 - val_loss: 2.2525 - val_acc: 0.7675\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4274 - acc: 0.7370 - val_loss: 2.2460 - val_acc: 0.7719\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2331 - acc: 0.7670 - val_loss: 2.1985 - val_acc: 0.7744\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2812 - acc: 0.7586 - val_loss: 2.1165 - val_acc: 0.7894\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3153 - acc: 0.7545 - val_loss: 2.5521 - val_acc: 0.7456\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3656 - acc: 0.7553 - val_loss: 2.1432 - val_acc: 0.7950\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3238 - acc: 0.7577 - val_loss: 2.2265 - val_acc: 0.7769\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3828 - acc: 0.7469 - val_loss: 2.1341 - val_acc: 0.7887\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4473 - acc: 0.7363 - val_loss: 2.1688 - val_acc: 0.7869\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3524 - acc: 0.7469 - val_loss: 2.4061 - val_acc: 0.7638\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3712 - acc: 0.7413 - val_loss: 2.2734 - val_acc: 0.7738\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3317 - acc: 0.7562 - val_loss: 2.1788 - val_acc: 0.7800\n",
      "Epoch 1646/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3217 - acc: 0.7478 - val_loss: 2.3231 - val_acc: 0.7663\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3665 - acc: 0.7434 - val_loss: 2.2663 - val_acc: 0.7744\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2729 - acc: 0.7631 - val_loss: 2.5960 - val_acc: 0.7494\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4026 - acc: 0.7395 - val_loss: 2.2987 - val_acc: 0.7738\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3669 - acc: 0.7534 - val_loss: 2.2725 - val_acc: 0.7825\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3386 - acc: 0.7530 - val_loss: 2.2230 - val_acc: 0.7831\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3929 - acc: 0.7456 - val_loss: 2.2396 - val_acc: 0.7806\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2896 - acc: 0.7588 - val_loss: 2.1107 - val_acc: 0.7937\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3753 - acc: 0.7452 - val_loss: 2.0398 - val_acc: 0.8000\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2821 - acc: 0.7638 - val_loss: 2.5678 - val_acc: 0.7638\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3891 - acc: 0.7498 - val_loss: 7.0658 - val_acc: 0.4750\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5304 - acc: 0.7383 - val_loss: 2.3948 - val_acc: 0.7656\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4649 - acc: 0.7472 - val_loss: 2.1609 - val_acc: 0.8006\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5759 - acc: 0.7300 - val_loss: 2.5685 - val_acc: 0.7575\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3895 - acc: 0.7556 - val_loss: 2.0436 - val_acc: 0.8037\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3609 - acc: 0.7531 - val_loss: 2.3450 - val_acc: 0.7750\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3697 - acc: 0.7536 - val_loss: 2.4779 - val_acc: 0.7606\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.4398 - acc: 0.7423 - val_loss: 2.5860 - val_acc: 0.7513\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3703 - acc: 0.7500 - val_loss: 2.4139 - val_acc: 0.7663\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3859 - acc: 0.7502 - val_loss: 2.1338 - val_acc: 0.7956\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3365 - acc: 0.7586 - val_loss: 2.0451 - val_acc: 0.7962\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4216 - acc: 0.7494 - val_loss: 2.3681 - val_acc: 0.7731\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3795 - acc: 0.7544 - val_loss: 2.0927 - val_acc: 0.8019\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4854 - acc: 0.7356 - val_loss: 2.3668 - val_acc: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2402 - acc: 0.7700 - val_loss: 2.3163 - val_acc: 0.7781\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3083 - acc: 0.7573 - val_loss: 2.2642 - val_acc: 0.7837\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4289 - acc: 0.7427 - val_loss: 2.3521 - val_acc: 0.7638\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3964 - acc: 0.7423 - val_loss: 2.8096 - val_acc: 0.7362\n",
      "Epoch 1674/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3897 - acc: 0.7469 - val_loss: 2.3333 - val_acc: 0.7775\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4080 - acc: 0.7498 - val_loss: 2.3637 - val_acc: 0.7731\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3575 - acc: 0.7572 - val_loss: 2.3090 - val_acc: 0.7775\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3280 - acc: 0.7586 - val_loss: 2.2722 - val_acc: 0.7763\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3887 - acc: 0.7548 - val_loss: 2.5308 - val_acc: 0.7487\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3353 - acc: 0.7581 - val_loss: 1.8178 - val_acc: 0.8219\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3996 - acc: 0.7472 - val_loss: 2.3790 - val_acc: 0.7650\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3211 - acc: 0.7567 - val_loss: 2.3387 - val_acc: 0.7713\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4108 - acc: 0.7444 - val_loss: 2.3462 - val_acc: 0.7694\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3887 - acc: 0.7502 - val_loss: 2.3452 - val_acc: 0.7738\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3132 - acc: 0.7567 - val_loss: 2.4360 - val_acc: 0.7600\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3000 - acc: 0.7608 - val_loss: 2.2775 - val_acc: 0.7669\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3481 - acc: 0.7564 - val_loss: 2.3680 - val_acc: 0.7644\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4476 - acc: 0.7416 - val_loss: 2.2565 - val_acc: 0.7844\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3387 - acc: 0.7528 - val_loss: 2.2802 - val_acc: 0.7713\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3418 - acc: 0.7523 - val_loss: 2.2446 - val_acc: 0.7788\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3819 - acc: 0.7508 - val_loss: 2.4083 - val_acc: 0.7625\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3253 - acc: 0.7550 - val_loss: 2.2579 - val_acc: 0.7781\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3930 - acc: 0.7469 - val_loss: 2.7622 - val_acc: 0.7337\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4635 - acc: 0.7333 - val_loss: 2.2803 - val_acc: 0.7644\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3429 - acc: 0.7537 - val_loss: 2.5277 - val_acc: 0.7481\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4825 - acc: 0.7350 - val_loss: 2.1162 - val_acc: 0.7837\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3623 - acc: 0.7486 - val_loss: 2.3374 - val_acc: 0.7656\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3281 - acc: 0.7580 - val_loss: 2.2166 - val_acc: 0.7844\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4741 - acc: 0.7342 - val_loss: 2.3819 - val_acc: 0.7631\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2923 - acc: 0.7611 - val_loss: 2.2474 - val_acc: 0.7694\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2637 - acc: 0.7659 - val_loss: 2.4096 - val_acc: 0.7638\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4059 - acc: 0.7470 - val_loss: 2.2195 - val_acc: 0.7719\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4599 - acc: 0.7347 - val_loss: 2.2528 - val_acc: 0.7788\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3667 - acc: 0.7511 - val_loss: 2.1676 - val_acc: 0.7844\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4289 - acc: 0.7394 - val_loss: 1.9826 - val_acc: 0.7994\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5097 - acc: 0.7283 - val_loss: 2.3120 - val_acc: 0.7594\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4985 - acc: 0.7323 - val_loss: 2.5052 - val_acc: 0.7419\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4262 - acc: 0.7463 - val_loss: 2.0792 - val_acc: 0.7862\n",
      "Epoch 1708/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4035 - acc: 0.7483 - val_loss: 2.2121 - val_acc: 0.7781\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3957 - acc: 0.7452 - val_loss: 2.0959 - val_acc: 0.7831\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4150 - acc: 0.7472 - val_loss: 2.0987 - val_acc: 0.7638\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3950 - acc: 0.7450 - val_loss: 2.1209 - val_acc: 0.7800\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3229 - acc: 0.7545 - val_loss: 2.1166 - val_acc: 0.7781\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3006 - acc: 0.7583 - val_loss: 2.1644 - val_acc: 0.7812\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3617 - acc: 0.7508 - val_loss: 2.5333 - val_acc: 0.7425\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3572 - acc: 0.7516 - val_loss: 2.2195 - val_acc: 0.7738\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3705 - acc: 0.7425 - val_loss: 2.2353 - val_acc: 0.7750\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3825 - acc: 0.7425 - val_loss: 2.3978 - val_acc: 0.7513\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3830 - acc: 0.7428 - val_loss: 2.1509 - val_acc: 0.7719\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3377 - acc: 0.7525 - val_loss: 2.3786 - val_acc: 0.7631\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2921 - acc: 0.7569 - val_loss: 2.2305 - val_acc: 0.7731\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3691 - acc: 0.7466 - val_loss: 2.1961 - val_acc: 0.7694\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3526 - acc: 0.7512 - val_loss: 2.2303 - val_acc: 0.7644\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3484 - acc: 0.7506 - val_loss: 2.4696 - val_acc: 0.7513\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3452 - acc: 0.7473 - val_loss: 2.2995 - val_acc: 0.7606\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2942 - acc: 0.7611 - val_loss: 2.5104 - val_acc: 0.7437\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2894 - acc: 0.7584 - val_loss: 2.6892 - val_acc: 0.7244\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3586 - acc: 0.7498 - val_loss: 2.6039 - val_acc: 0.7381\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2843 - acc: 0.7575 - val_loss: 2.2177 - val_acc: 0.7788\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.2984 - acc: 0.7534 - val_loss: 2.4205 - val_acc: 0.7462\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3201 - acc: 0.7531 - val_loss: 2.2517 - val_acc: 0.7775\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3775 - acc: 0.7466 - val_loss: 2.2615 - val_acc: 0.7744\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3280 - acc: 0.7522 - val_loss: 2.1496 - val_acc: 0.7719\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3046 - acc: 0.7573 - val_loss: 2.2456 - val_acc: 0.7744\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3487 - acc: 0.7505 - val_loss: 2.1959 - val_acc: 0.7781\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3428 - acc: 0.7475 - val_loss: 2.1347 - val_acc: 0.7781\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2533 - acc: 0.7620 - val_loss: 2.1218 - val_acc: 0.7862\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2943 - acc: 0.7528 - val_loss: 2.0717 - val_acc: 0.7850\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4135 - acc: 0.7369 - val_loss: 2.1510 - val_acc: 0.7869\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3349 - acc: 0.7472 - val_loss: 2.2057 - val_acc: 0.7681\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3491 - acc: 0.7477 - val_loss: 2.1840 - val_acc: 0.7731\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3116 - acc: 0.7500 - val_loss: 2.0773 - val_acc: 0.7806\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4088 - acc: 0.7403 - val_loss: 2.4823 - val_acc: 0.7419\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2530 - acc: 0.7625 - val_loss: 1.9377 - val_acc: 0.8019\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2709 - acc: 0.7595 - val_loss: 2.4853 - val_acc: 0.7431\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3639 - acc: 0.7461 - val_loss: 2.3788 - val_acc: 0.7644\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3897 - acc: 0.7455 - val_loss: 2.5728 - val_acc: 0.7362\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3557 - acc: 0.7511 - val_loss: 2.1304 - val_acc: 0.7794\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2732 - acc: 0.7616 - val_loss: 2.2914 - val_acc: 0.7681\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3609 - acc: 0.7473 - val_loss: 2.1654 - val_acc: 0.7837\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4645 - acc: 0.7355 - val_loss: 2.2979 - val_acc: 0.7644\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2895 - acc: 0.7602 - val_loss: 2.4236 - val_acc: 0.7525\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2866 - acc: 0.7591 - val_loss: 2.3955 - val_acc: 0.7519\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2640 - acc: 0.7627 - val_loss: 2.2187 - val_acc: 0.7713\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3512 - acc: 0.7495 - val_loss: 2.3359 - val_acc: 0.7644\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.3621 - acc: 0.7478 - val_loss: 2.2676 - val_acc: 0.7731\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2930 - acc: 0.7523 - val_loss: 2.1148 - val_acc: 0.7869\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3079 - acc: 0.7525 - val_loss: 2.2507 - val_acc: 0.7775\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4411 - acc: 0.7342 - val_loss: 2.4542 - val_acc: 0.7531\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2404 - acc: 0.7666 - val_loss: 2.5157 - val_acc: 0.7581\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4185 - acc: 0.7458 - val_loss: 2.1949 - val_acc: 0.7950\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4584 - acc: 0.7330 - val_loss: 2.6250 - val_acc: 0.7419\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3835 - acc: 0.7470 - val_loss: 2.3353 - val_acc: 0.7713\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3246 - acc: 0.7531 - val_loss: 2.2741 - val_acc: 0.7862\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3372 - acc: 0.7488 - val_loss: 2.1749 - val_acc: 0.7844\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3649 - acc: 0.7448 - val_loss: 2.2938 - val_acc: 0.7706\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4036 - acc: 0.7439 - val_loss: 2.1641 - val_acc: 0.7844\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3280 - acc: 0.7552 - val_loss: 2.4170 - val_acc: 0.7513\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4433 - acc: 0.7411 - val_loss: 2.4616 - val_acc: 0.7431\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3453 - acc: 0.7503 - val_loss: 2.4653 - val_acc: 0.7487\n",
      "Epoch 1770/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4599 - acc: 0.7366 - val_loss: 2.0966 - val_acc: 0.7800\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3392 - acc: 0.7559 - val_loss: 2.2271 - val_acc: 0.7738\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3350 - acc: 0.7563 - val_loss: 2.2198 - val_acc: 0.7738\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4170 - acc: 0.7448 - val_loss: 2.3054 - val_acc: 0.7569\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3985 - acc: 0.7430 - val_loss: 2.4305 - val_acc: 0.7594\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3881 - acc: 0.7517 - val_loss: 2.3318 - val_acc: 0.7613\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.3019 - acc: 0.7630 - val_loss: 2.4776 - val_acc: 0.7513\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3692 - acc: 0.7472 - val_loss: 2.2087 - val_acc: 0.7775\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3667 - acc: 0.7480 - val_loss: 2.2621 - val_acc: 0.7613\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2738 - acc: 0.7642 - val_loss: 2.3870 - val_acc: 0.7563\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3950 - acc: 0.7461 - val_loss: 2.2372 - val_acc: 0.7744\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3321 - acc: 0.7525 - val_loss: 2.4040 - val_acc: 0.7519\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3646 - acc: 0.7480 - val_loss: 2.1791 - val_acc: 0.7800\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2583 - acc: 0.7634 - val_loss: 2.0962 - val_acc: 0.7844\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4029 - acc: 0.7436 - val_loss: 2.3564 - val_acc: 0.7725\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3923 - acc: 0.7423 - val_loss: 2.4418 - val_acc: 0.7475\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4348 - acc: 0.7362 - val_loss: 2.4234 - val_acc: 0.7569\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3232 - acc: 0.7534 - val_loss: 2.1724 - val_acc: 0.7763\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3158 - acc: 0.7545 - val_loss: 2.0329 - val_acc: 0.7931\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3374 - acc: 0.7506 - val_loss: 2.5383 - val_acc: 0.7444\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.3498 - acc: 0.7480 - val_loss: 2.2349 - val_acc: 0.7750\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3229 - acc: 0.7522 - val_loss: 2.3631 - val_acc: 0.7713\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2611 - acc: 0.7623 - val_loss: 2.2560 - val_acc: 0.7769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3536 - acc: 0.7475 - val_loss: 2.3901 - val_acc: 0.7575\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3419 - acc: 0.7486 - val_loss: 2.1788 - val_acc: 0.7725\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3880 - acc: 0.7427 - val_loss: 2.4670 - val_acc: 0.7519\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2634 - acc: 0.7633 - val_loss: 2.1928 - val_acc: 0.7719\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3576 - acc: 0.7463 - val_loss: 2.2281 - val_acc: 0.7563\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3225 - acc: 0.7541 - val_loss: 2.2594 - val_acc: 0.7694\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3809 - acc: 0.7467 - val_loss: 2.3706 - val_acc: 0.7538\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3257 - acc: 0.7563 - val_loss: 2.2759 - val_acc: 0.7700\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3947 - acc: 0.7428 - val_loss: 2.3285 - val_acc: 0.7588\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2145 - acc: 0.7717 - val_loss: 2.4328 - val_acc: 0.7606\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2757 - acc: 0.7634 - val_loss: 2.2154 - val_acc: 0.7763\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3814 - acc: 0.7416 - val_loss: 2.4793 - val_acc: 0.7344\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2761 - acc: 0.7627 - val_loss: 2.2529 - val_acc: 0.7769\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2693 - acc: 0.7575 - val_loss: 2.1435 - val_acc: 0.7837\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3975 - acc: 0.7433 - val_loss: 2.5042 - val_acc: 0.7513\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2524 - acc: 0.7650 - val_loss: 2.1349 - val_acc: 0.7919\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2960 - acc: 0.7559 - val_loss: 2.3109 - val_acc: 0.7638\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3447 - acc: 0.7489 - val_loss: 2.1517 - val_acc: 0.7769\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3065 - acc: 0.7548 - val_loss: 2.0449 - val_acc: 0.7931\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2723 - acc: 0.7636 - val_loss: 2.2683 - val_acc: 0.7750\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3172 - acc: 0.7520 - val_loss: 2.1950 - val_acc: 0.7869\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2822 - acc: 0.7570 - val_loss: 2.2103 - val_acc: 0.7819\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3308 - acc: 0.7502 - val_loss: 2.3862 - val_acc: 0.7556\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3220 - acc: 0.7514 - val_loss: 2.4349 - val_acc: 0.7544\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4200 - acc: 0.7364 - val_loss: 2.4689 - val_acc: 0.7531\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3952 - acc: 0.7416 - val_loss: 2.0824 - val_acc: 0.7831\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3225 - acc: 0.7533 - val_loss: 2.4359 - val_acc: 0.7419\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3752 - acc: 0.7437 - val_loss: 2.4266 - val_acc: 0.7519\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3114 - acc: 0.7556 - val_loss: 2.2179 - val_acc: 0.7775\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3653 - acc: 0.7486 - val_loss: 2.0463 - val_acc: 0.7937\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4283 - acc: 0.7430 - val_loss: 2.2751 - val_acc: 0.7606\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3722 - acc: 0.7505 - val_loss: 2.1002 - val_acc: 0.7906\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.3337 - acc: 0.7514 - val_loss: 2.1932 - val_acc: 0.7781\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4104 - acc: 0.7427 - val_loss: 2.2968 - val_acc: 0.7744\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2998 - acc: 0.7562 - val_loss: 2.1161 - val_acc: 0.7931\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3608 - acc: 0.7509 - val_loss: 2.2791 - val_acc: 0.7619\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3440 - acc: 0.7511 - val_loss: 2.3750 - val_acc: 0.7644\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3918 - acc: 0.7433 - val_loss: 2.2723 - val_acc: 0.7638\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2979 - acc: 0.7589 - val_loss: 2.0554 - val_acc: 0.7937\n",
      "Epoch 1832/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2714 - acc: 0.7636 - val_loss: 2.1155 - val_acc: 0.7750\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3445 - acc: 0.7495 - val_loss: 2.0690 - val_acc: 0.7912\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3041 - acc: 0.7520 - val_loss: 2.3302 - val_acc: 0.7581\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2925 - acc: 0.7569 - val_loss: 2.1917 - val_acc: 0.7806\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3270 - acc: 0.7525 - val_loss: 2.3869 - val_acc: 0.7544\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4058 - acc: 0.7441 - val_loss: 2.2688 - val_acc: 0.7594\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3758 - acc: 0.7472 - val_loss: 2.3698 - val_acc: 0.7481\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3002 - acc: 0.7572 - val_loss: 2.2004 - val_acc: 0.7800\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3746 - acc: 0.7425 - val_loss: 2.1806 - val_acc: 0.7719\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2698 - acc: 0.7648 - val_loss: 2.2860 - val_acc: 0.7706\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2918 - acc: 0.7538 - val_loss: 2.2339 - val_acc: 0.7756\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3033 - acc: 0.7541 - val_loss: 2.2492 - val_acc: 0.7700\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2791 - acc: 0.7594 - val_loss: 2.2589 - val_acc: 0.7763\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3682 - acc: 0.7459 - val_loss: 2.0379 - val_acc: 0.7956\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3801 - acc: 0.7467 - val_loss: 2.3817 - val_acc: 0.7506\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2349 - acc: 0.7625 - val_loss: 2.2157 - val_acc: 0.7756\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2697 - acc: 0.7573 - val_loss: 2.2878 - val_acc: 0.7631\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3015 - acc: 0.7575 - val_loss: 2.2603 - val_acc: 0.7688\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3066 - acc: 0.7527 - val_loss: 2.0759 - val_acc: 0.7837\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3627 - acc: 0.7441 - val_loss: 2.3149 - val_acc: 0.7719\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2815 - acc: 0.7580 - val_loss: 2.1947 - val_acc: 0.7806\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3604 - acc: 0.7448 - val_loss: 2.0182 - val_acc: 0.7869\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4579 - acc: 0.7306 - val_loss: 2.0951 - val_acc: 0.7900\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3158 - acc: 0.7531 - val_loss: 2.1583 - val_acc: 0.7894\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2838 - acc: 0.7567 - val_loss: 2.0372 - val_acc: 0.7831\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3709 - acc: 0.7400 - val_loss: 2.4610 - val_acc: 0.7563\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2708 - acc: 0.7544 - val_loss: 2.0219 - val_acc: 0.7887\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4436 - acc: 0.7297 - val_loss: 2.2701 - val_acc: 0.7794\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2900 - acc: 0.7587 - val_loss: 2.2750 - val_acc: 0.7663\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2766 - acc: 0.7586 - val_loss: 2.2470 - val_acc: 0.7775\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3769 - acc: 0.7467 - val_loss: 2.2627 - val_acc: 0.7725\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2596 - acc: 0.7586 - val_loss: 2.3334 - val_acc: 0.7713\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3058 - acc: 0.7527 - val_loss: 2.3352 - val_acc: 0.7638\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2341 - acc: 0.7633 - val_loss: 2.2435 - val_acc: 0.7594\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3066 - acc: 0.7541 - val_loss: 2.2398 - val_acc: 0.7812\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2991 - acc: 0.7542 - val_loss: 2.4119 - val_acc: 0.7606\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2541 - acc: 0.7564 - val_loss: 2.2704 - val_acc: 0.7725\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3262 - acc: 0.7534 - val_loss: 2.3964 - val_acc: 0.7569\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2709 - acc: 0.7589 - val_loss: 2.1445 - val_acc: 0.7763\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3743 - acc: 0.7423 - val_loss: 2.2137 - val_acc: 0.7812\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2946 - acc: 0.7542 - val_loss: 2.0213 - val_acc: 0.7931\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3180 - acc: 0.7475 - val_loss: 2.4725 - val_acc: 0.7506\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3112 - acc: 0.7517 - val_loss: 2.0036 - val_acc: 0.7975\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3439 - acc: 0.7456 - val_loss: 2.2066 - val_acc: 0.7750\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2980 - acc: 0.7541 - val_loss: 2.2595 - val_acc: 0.7763\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3286 - acc: 0.7472 - val_loss: 2.2482 - val_acc: 0.7675\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3681 - acc: 0.7452 - val_loss: 2.1904 - val_acc: 0.7788\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3336 - acc: 0.7480 - val_loss: 2.1366 - val_acc: 0.7781\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2550 - acc: 0.7605 - val_loss: 2.1402 - val_acc: 0.7750\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3490 - acc: 0.7503 - val_loss: 2.3522 - val_acc: 0.7581\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3123 - acc: 0.7480 - val_loss: 2.2597 - val_acc: 0.7688\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2948 - acc: 0.7539 - val_loss: 2.3713 - val_acc: 0.7675\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3285 - acc: 0.7502 - val_loss: 2.2385 - val_acc: 0.7750\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3261 - acc: 0.7480 - val_loss: 2.1390 - val_acc: 0.7731\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3416 - acc: 0.7480 - val_loss: 2.3294 - val_acc: 0.7644\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3971 - acc: 0.7380 - val_loss: 2.2825 - val_acc: 0.7544\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3024 - acc: 0.7500 - val_loss: 2.5303 - val_acc: 0.7506\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3273 - acc: 0.7464 - val_loss: 2.2720 - val_acc: 0.7806\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2921 - acc: 0.7522 - val_loss: 2.2969 - val_acc: 0.7600\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2813 - acc: 0.7534 - val_loss: 2.3219 - val_acc: 0.7694\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3787 - acc: 0.7409 - val_loss: 2.1827 - val_acc: 0.7706\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2905 - acc: 0.7566 - val_loss: 1.9656 - val_acc: 0.8012\n",
      "Epoch 1894/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3304 - acc: 0.7494 - val_loss: 2.4202 - val_acc: 0.7544\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3251 - acc: 0.7473 - val_loss: 2.2544 - val_acc: 0.7644\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3479 - acc: 0.7455 - val_loss: 2.0718 - val_acc: 0.7844\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2853 - acc: 0.7567 - val_loss: 2.2116 - val_acc: 0.7700\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3624 - acc: 0.7481 - val_loss: 2.2392 - val_acc: 0.7719\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3038 - acc: 0.7528 - val_loss: 2.3715 - val_acc: 0.7581\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2728 - acc: 0.7573 - val_loss: 2.1608 - val_acc: 0.7725\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3255 - acc: 0.7516 - val_loss: 2.4416 - val_acc: 0.7481\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3063 - acc: 0.7516 - val_loss: 2.3075 - val_acc: 0.7644\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3089 - acc: 0.7505 - val_loss: 2.1572 - val_acc: 0.7725\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3486 - acc: 0.7480 - val_loss: 2.3214 - val_acc: 0.7575\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3295 - acc: 0.7503 - val_loss: 2.1198 - val_acc: 0.7806\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3726 - acc: 0.7419 - val_loss: 2.5248 - val_acc: 0.7506\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.3157 - acc: 0.7516 - val_loss: 2.1249 - val_acc: 0.7794\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2967 - acc: 0.7505 - val_loss: 2.4113 - val_acc: 0.7556\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3314 - acc: 0.7456 - val_loss: 2.1810 - val_acc: 0.7731\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2694 - acc: 0.7570 - val_loss: 2.1958 - val_acc: 0.7862\n",
      "Epoch 1911/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3074 - acc: 0.7489 - val_loss: 2.2046 - val_acc: 0.7769\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4264 - acc: 0.7356 - val_loss: 2.3320 - val_acc: 0.7706\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3130 - acc: 0.7520 - val_loss: 2.2395 - val_acc: 0.7738\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4420 - acc: 0.7347 - val_loss: 2.3300 - val_acc: 0.7525\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2682 - acc: 0.7581 - val_loss: 2.1494 - val_acc: 0.7881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2844 - acc: 0.7517 - val_loss: 2.1939 - val_acc: 0.7750\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2969 - acc: 0.7498 - val_loss: 2.1950 - val_acc: 0.7725\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3216 - acc: 0.7448 - val_loss: 2.2346 - val_acc: 0.7650\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.3383 - acc: 0.7456 - val_loss: 2.3755 - val_acc: 0.7625\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2494 - acc: 0.7552 - val_loss: 2.3308 - val_acc: 0.7694\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2410 - acc: 0.7572 - val_loss: 2.1980 - val_acc: 0.7844\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.3531 - acc: 0.7444 - val_loss: 2.1779 - val_acc: 0.7819\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2639 - acc: 0.7564 - val_loss: 2.0829 - val_acc: 0.7781\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.4590 - acc: 0.7284 - val_loss: 2.3883 - val_acc: 0.7481\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.2433 - acc: 0.7617 - val_loss: 2.1156 - val_acc: 0.7931\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2662 - acc: 0.7592 - val_loss: 2.3865 - val_acc: 0.7606\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.2636 - acc: 0.7572 - val_loss: 2.4841 - val_acc: 0.7475\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2092 - acc: 0.7653 - val_loss: 2.1980 - val_acc: 0.7831\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2940 - acc: 0.7562 - val_loss: 2.2724 - val_acc: 0.7638\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2767 - acc: 0.7556 - val_loss: 2.4630 - val_acc: 0.7513\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.2317 - acc: 0.7595 - val_loss: 2.3663 - val_acc: 0.7663\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3442 - acc: 0.7527 - val_loss: 2.4620 - val_acc: 0.7531\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2812 - acc: 0.7542 - val_loss: 2.2362 - val_acc: 0.7781\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3127 - acc: 0.7487 - val_loss: 2.5525 - val_acc: 0.7506\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.2483 - acc: 0.7589 - val_loss: 2.4093 - val_acc: 0.7531\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.4041 - acc: 0.7378 - val_loss: 2.0899 - val_acc: 0.7831\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2646 - acc: 0.7569 - val_loss: 2.4009 - val_acc: 0.7650\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2616 - acc: 0.7566 - val_loss: 2.2619 - val_acc: 0.7675\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.1819 - acc: 0.7720 - val_loss: 2.1621 - val_acc: 0.7844\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2902 - acc: 0.7580 - val_loss: 2.3025 - val_acc: 0.7713\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.3384 - acc: 0.7441 - val_loss: 2.1454 - val_acc: 0.7781\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2726 - acc: 0.7572 - val_loss: 2.3702 - val_acc: 0.7588\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2238 - acc: 0.7602 - val_loss: 2.4436 - val_acc: 0.7513\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2192 - acc: 0.7636 - val_loss: 2.1849 - val_acc: 0.7781\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2321 - acc: 0.7606 - val_loss: 2.2599 - val_acc: 0.7794\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2722 - acc: 0.7559 - val_loss: 2.2270 - val_acc: 0.7788\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3512 - acc: 0.7466 - val_loss: 2.2247 - val_acc: 0.7631\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2700 - acc: 0.7564 - val_loss: 2.4655 - val_acc: 0.7506\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3948 - acc: 0.7377 - val_loss: 2.3378 - val_acc: 0.7719\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2590 - acc: 0.7598 - val_loss: 2.3453 - val_acc: 0.7656\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2257 - acc: 0.7617 - val_loss: 2.1653 - val_acc: 0.7912\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2794 - acc: 0.7577 - val_loss: 2.4312 - val_acc: 0.7581\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2711 - acc: 0.7519 - val_loss: 2.4766 - val_acc: 0.7581\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3430 - acc: 0.7403 - val_loss: 2.1912 - val_acc: 0.7794\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2410 - acc: 0.7550 - val_loss: 2.2306 - val_acc: 0.7744\n",
      "Epoch 1956/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.1908 - acc: 0.7637 - val_loss: 2.4448 - val_acc: 0.7594\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2178 - acc: 0.7620 - val_loss: 2.2372 - val_acc: 0.7744\n",
      "Epoch 1958/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2043 - acc: 0.7672 - val_loss: 2.0828 - val_acc: 0.7937\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3331 - acc: 0.7455 - val_loss: 2.3861 - val_acc: 0.7719\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.1703 - acc: 0.7658 - val_loss: 2.2921 - val_acc: 0.7713\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3312 - acc: 0.7483 - val_loss: 2.5153 - val_acc: 0.7444\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.2441 - acc: 0.7525 - val_loss: 2.0400 - val_acc: 0.7944\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3268 - acc: 0.7480 - val_loss: 2.3713 - val_acc: 0.7613\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2458 - acc: 0.7564 - val_loss: 2.1934 - val_acc: 0.7825\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.3534 - acc: 0.7419 - val_loss: 2.1521 - val_acc: 0.7856\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2270 - acc: 0.7569 - val_loss: 2.0738 - val_acc: 0.7919\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2641 - acc: 0.7552 - val_loss: 2.4722 - val_acc: 0.7487\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2652 - acc: 0.7542 - val_loss: 2.1061 - val_acc: 0.7894\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2735 - acc: 0.7536 - val_loss: 2.0757 - val_acc: 0.7919\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2173 - acc: 0.7611 - val_loss: 2.2549 - val_acc: 0.7675\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3510 - acc: 0.7445 - val_loss: 2.3330 - val_acc: 0.7675\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3162 - acc: 0.7467 - val_loss: 2.0112 - val_acc: 0.7987\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2423 - acc: 0.7603 - val_loss: 2.0642 - val_acc: 0.7912\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.1740 - acc: 0.7672 - val_loss: 2.6624 - val_acc: 0.7394\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2004 - acc: 0.7600 - val_loss: 2.2902 - val_acc: 0.7788\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2608 - acc: 0.7520 - val_loss: 2.1606 - val_acc: 0.7775\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3130 - acc: 0.7484 - val_loss: 2.2132 - val_acc: 0.7825\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2444 - acc: 0.7558 - val_loss: 2.4939 - val_acc: 0.7481\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2375 - acc: 0.7613 - val_loss: 2.4924 - val_acc: 0.7581\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2341 - acc: 0.7552 - val_loss: 2.2912 - val_acc: 0.7719\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2088 - acc: 0.7572 - val_loss: 2.4538 - val_acc: 0.7444\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3100 - acc: 0.7447 - val_loss: 2.3978 - val_acc: 0.7606\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2482 - acc: 0.7570 - val_loss: 2.4368 - val_acc: 0.7631\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3662 - acc: 0.7363 - val_loss: 2.2822 - val_acc: 0.7688\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.1743 - acc: 0.7652 - val_loss: 2.2343 - val_acc: 0.7713\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2676 - acc: 0.7497 - val_loss: 2.2751 - val_acc: 0.7681\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.1930 - acc: 0.7653 - val_loss: 2.4103 - val_acc: 0.7625\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.3220 - acc: 0.7458 - val_loss: 2.2759 - val_acc: 0.7644\n",
      "Epoch 1989/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3308 - acc: 0.7444 - val_loss: 2.4297 - val_acc: 0.7531\n",
      "Epoch 1990/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.1894 - acc: 0.7631 - val_loss: 2.1974 - val_acc: 0.7769\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.3436 - acc: 0.7411 - val_loss: 2.4084 - val_acc: 0.7650\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2386 - acc: 0.7572 - val_loss: 2.2282 - val_acc: 0.7631\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3236 - acc: 0.7450 - val_loss: 2.4565 - val_acc: 0.7450\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.3504 - acc: 0.7414 - val_loss: 2.1380 - val_acc: 0.7881\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.3559 - acc: 0.7420 - val_loss: 2.0019 - val_acc: 0.7975\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2386 - acc: 0.7547 - val_loss: 2.0697 - val_acc: 0.7931\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2211 - acc: 0.7627 - val_loss: 2.2497 - val_acc: 0.7700\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2479 - acc: 0.7563 - val_loss: 2.4020 - val_acc: 0.7556\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2851 - acc: 0.7473 - val_loss: 2.4166 - val_acc: 0.7569\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.2405 - acc: 0.7566 - val_loss: 2.0301 - val_acc: 0.7962\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(tdg, callbacks=[mc,tb], initial_epoch=0\n",
    "                           ,steps_per_epoch=train_steps_per_epoch\n",
    "                           ,validation_data=vdg\n",
    "                           ,validation_steps=val_steps_per_epoch\n",
    "                           ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# acc = hist.history['acc']\n",
    "# loss = hist.history['loss']\n",
    "\n",
    "# # Create count of the number of epochs\n",
    "# epoch_count = range(1, len(acc) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# # plt.plot(epoch_count, acc, 'b-')\n",
    "# fig, ax = plt.subplots(ncols=2,sharex=True)\n",
    "# ax[0].plot(epoch_count, loss, 'r--')\n",
    "# ax[0].legend(['Loss'])\n",
    "# ax[0].set_xlabel('Epoch')\n",
    "# ax[0].set_ylabel('Loss')\n",
    "# ax[1].plot(epoch_count, acc, 'b-')\n",
    "# ax[1].legend(['Accuracy'])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_xlabel('Accuracy')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.DataFrame(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['acc','val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `evaluate_generator` call to the Keras 2 API: `evaluate_generator(<generator..., use_multiprocessing=True, steps=5)`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.17778000831604, 0.7424799919128418]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('weights/dnf300_sa_sent_hd_word_gl.hdf5')\n",
    "model.evaluate_generator(test_dg,steps=5,pickle_safe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_dg)\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_idx = np.random.randint(50)\n",
    "# test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 94 : assange confirms: wikileaks didnt get emails from russian govt\n",
      "1 : 36 : hillary clintons sudden move of $1.8 billion to qatar central bank stuns financial world\n",
      "2 : 34 : (video) female college students protesting because trump is a rapist\n",
      "3 : 28 : hes never sold an original painting until nowand this ones going in the white house\n",
      "4 : 27 : trump accuses obama, hillary clinton of founding daesh\n",
      "5 : 10 : physician confirms hillary clinton has parkinson's disease\n",
      "6 : 97 : hillary sold weapons to isis, wikileaks confirms\n",
      "7 : 13 : hillary clinton in 2013: 'i would like to see people like donald trump run for office\n",
      "8 : 94 : assange confirms: wikileaks didnt get emails from russian govt\n",
      "9 : 7 : hillary clinton used hand signals to rig debate?\n",
      "10 : 38 : hillarys (islamic) america is already here where muslim no-go zones are popping up all over michiganistan\n",
      "11 : 91 : us officials see no link between trump and russia\n",
      "12 : 18 : clinton camp demands 'compliant citizenry' for master plan\n",
      "13 : 29 : lol! british wife of lib actor who said: there will never be a president donald trumpwarns americans about president-elect trump [video]\n",
      "14 : 27 : trump accuses obama, hillary clinton of founding daesh\n",
      "15 : 95 : us threatens military hacks on russias electric, communications grids over election\n",
      "16 : 92 : pentagon seeks another $6 billion for overseas troop deployments\n",
      "17 : 93 : former nato chief: we need us as worlds policeman\n",
      "18 : 30 : nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative\n",
      "19 : 0 : wikileaks confirms hillary sold weapons to isis... then drops another bombshell! breaking news\n",
      "20 : 13 : hillary clinton in 2013: 'i would like to see people like donald trump run for office\n",
      "21 : 26 : wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting\n",
      "22 : 26 : wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting\n",
      "23 : 21 : isis leader calls for american muslim voters to support hillary clinton\n",
      "24 : 6 : clinton received debate questions week before debate\n",
      "25 : 99 : hillary personally ordered donald duck troll campaign\n",
      "26 : 100 : hillary friend bribed fbi agent and his wife\n",
      "27 : 26 : wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting\n",
      "28 : 19 : leaked 2013 trump tax return shows he paid over 40 million in taxes\n",
      "29 : 28 : hes never sold an original painting until nowand this ones going in the white house\n",
      "30 : 2 : president obama confirms he will refuse to leave office if trump is elected\n",
      "31 : 30 : nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative\n",
      "32 : 14 : department of homeland security chairman officially indicts hillary clinton of treason\n",
      "33 : 30 : nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative\n",
      "34 : 37 : julian assange makes very suspect post election announcement, seeks pardon from trump\n",
      "35 : 0 : wikileaks confirms hillary sold weapons to isis... then drops another bombshell! breaking news\n",
      "36 : 15 : hillary clinton's 'sudden move' of $1.8 billion to qatar central bank stuns financial world\n",
      "37 : 3 : breaking: fraudulent clinton votes discovered by the tens of thousands\n",
      "38 : 14 : department of homeland security chairman officially indicts hillary clinton of treason\n",
      "39 : 14 : department of homeland security chairman officially indicts hillary clinton of treason\n",
      "40 : 3 : breaking: fraudulent clinton votes discovered by the tens of thousands\n",
      "41 : 7 : hillary clinton used hand signals to rig debate?\n",
      "42 : 29 : lol! british wife of lib actor who said: there will never be a president donald trumpwarns americans about president-elect trump [video]\n",
      "43 : 99 : hillary personally ordered donald duck troll campaign\n",
      "44 : 8 : hillary clinton cut her tax bill by 'donating' $1 million to herself via the clinton foundation?\n",
      "45 : 33 : kremlin: putin congratulates trump, hopes to work together major issues\n",
      "46 : 3 : breaking: fraudulent clinton votes discovered by the tens of thousands\n",
      "47 : 100 : hillary friend bribed fbi agent and his wife\n",
      "48 : 37 : julian assange makes very suspect post election announcement, seeks pardon from trump\n",
      "49 : 2 : president obama confirms he will refuse to leave office if trump is elected\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x['headline'])):\n",
    "    \n",
    "    print(i,\":\",x['article_id'][i],':',x['headline'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An intriguing Ministry of Finance (MoF) report circulating in the Kremlin today says that elite Western bankers were stunned/bewildered a few hours ago after the Bank For International Settlements (BIS) registered a $1.8 billion transfer from the Clinton Foundation (CF) to the Qatar Central Bank (QCB) through the facilitation/abetment of JP Morgan Chase & Company (JPM)and for reasons yet to be firmly established. [',\n",
       " 'Note: Some words and/or phrases appearing in quotes in this report are English language approximations of Russian words/phrases having no exact counterpart.]',\n",
       " 'According to this report, the Bank for International Settlements is the worlds oldest international financial organization and acts as a prime counterparty for central banks in their financial transactions; the Qatar Central Bank is the bank of that Gulf State nations government and their bank of banks; JP Morgan Chase & Company is the United States largest megabank; and the Clinton Foundation is an international criminal money laundering organization whose clients include the Russian mafia.',\n",
       " 'With Hillary Clintons US presidential campaign Chairman John Podesta having longstanding ties to the Russian mafia and money laundering, this report continues, the Foreign Intelligence Service (SVR) maintains complete/all times/all ways surveillance of him and his criminal associatesincluding both Hillary Clinton and her husband, and former US President, Bill Clinton, and who are collectively designated as the Clinton Crime Family.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 36\n",
    "x['sentences'][test_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(model.inputs,model.get_layer(name='ca1').output)\n",
    "model_2 = Model(model.inputs,model.get_layer(name='ca2').output)\n",
    "model_3 = Model(model.inputs,model.get_layer(name='ca3').output)\n",
    "model_4 = Model(model.inputs,model.get_layer(name='ca4').output)\n",
    "model_1.summary()\n",
    "model_2.summary()\n",
    "model_3.summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, b1, g1 = model_1.predict(x)\n",
    "_, b2, g2 = model_2.predict(x)\n",
    "_, b3, g3 = model_3.predict(x)\n",
    "_, b4, g4 = model_4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1,g2,g3,g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b1+b2+b3+b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_N = 5\n",
    "t = b[test_idx][0][:len(x['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-93.868286"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "b[test_idx][0][:len(x['sentences'][test_idx])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hillary clinton's 'sudden move' of $1.8 billion to qatar central bank stuns financial world\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x['headline'][test_idx])\n",
    "display(x['claims'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : According to this report, the Bank for International Settlements is the worlds oldest international financial organization and acts as a prime counterparty for central banks in their financial transactions; the Qatar Central Bank is the bank of that Gulf State nations government and their bank of banks; JP Morgan Chase & Company is the United States largest megabank; and the Clinton Foundation is an international criminal money laundering organization whose clients include the Russian mafia.\n",
      "3 : With Hillary Clintons US presidential campaign Chairman John Podesta having longstanding ties to the Russian mafia and money laundering, this report continues, the Foreign Intelligence Service (SVR) maintains complete/all times/all ways surveillance of him and his criminal associatesincluding both Hillary Clinton and her husband, and former US President, Bill Clinton, and who are collectively designated as the Clinton Crime Family.\n",
      "1 : Note: Some words and/or phrases appearing in quotes in this report are English language approximations of Russian words/phrases having no exact counterpart.]\n",
      "0 : An intriguing Ministry of Finance (MoF) report circulating in the Kremlin today says that elite Western bankers were stunned/bewildered a few hours ago after the Bank For International Settlements (BIS) registered a $1.8 billion transfer from the Clinton Foundation (CF) to the Qatar Central Bank (QCB) through the facilitation/abetment of JP Morgan Chase & Company (JPM)and for reasons yet to be firmly established. [\n"
     ]
    }
   ],
   "source": [
    "for s in t:\n",
    "    if s>=len(x['sentences'][test_idx]):continue\n",
    "    print(s,':',x['sentences'][test_idx][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-93.868286"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "h_s_attended_vector = b[test_idx][0][:len(x['sentences'][test_idx])]\n",
    "h_s_attended_vector.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h_s_attended_vector = pd.DataFrame(h_s_attended_vector)\n",
    "\n",
    "\n",
    "xw = df_h_s_attended_vector.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xw_scaled = min_max_scaler.fit_transform(xw)\n",
    "df_h_s_attended_vector = pd.DataFrame(xw_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f92159af780>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(2.0,7.0)})\n",
    "sns.heatmap(df_h_s_attended_vector, annot=True, cmap='YlGnBu', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa1 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa2 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa3 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa4 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s1 = Model(model.inputs,model.get_layer(name='sa1').output)\n",
    "model_s2 = Model(model.inputs,model.get_layer(name='sa2').output)\n",
    "model_s3 = Model(model.inputs,model.get_layer(name='sa3').output)\n",
    "model_s4 = Model(model.inputs,model.get_layer(name='sa4').output)\n",
    "model_s1.summary()\n",
    "model_s2.summary()\n",
    "model_s3.summary()\n",
    "model_s4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sb1, sg1 = model_s1.predict([x['sentence_vectors'],x['input_headline_vector']])\n",
    "_, sb2, sg2 = model_s2.predict(x)\n",
    "_, sb3, sg3 = model_s3.predict(x)\n",
    "_, sb4, sg4 = model_s4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335,\n",
       "        0.00789335, 0.00789335, 0.00789335, 0.00789335, 0.00789335],\n",
       "       dtype=float32),\n",
       " array([0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326,\n",
       "        0.00588326, 0.00588326, 0.00588326, 0.00588326, 0.00588326],\n",
       "       dtype=float32),\n",
       " array([-0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014,\n",
       "        -0.00755014, -0.00755014, -0.00755014, -0.00755014, -0.00755014],\n",
       "       dtype=float32),\n",
       " array([-0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447,\n",
       "        -0.00746447, -0.00746447, -0.00746447, -0.00746447, -0.00746447],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg1,sg2, sg3, sg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = sb1[test_idx]+sb2[test_idx]+sb3[test_idx]+sb4[test_idx]\n",
    "sb = sb[:len(x['sentences'][test_idx]),:len(x['sentences'][test_idx])]\n",
    "\n",
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb = pd.DataFrame(sb)\n",
    "\n",
    "\n",
    "zx = df_sb.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "zx_scaled = min_max_scaler.fit_transform(zx)\n",
    "df_sb = pd.DataFrame(zx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9215a9f7f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAK0CAYAAACDRsJEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3XeYnWWdP/73mUmblElMIGGSACGUkAVRaYqCYKhqIISqwf1FWYMNLOtSRCEEsURXkWJZdxHhG2QRUTCRJpZFpBchS+gkhpAGKUx6mczvj6Nxx0kCRDKTO3m9vM51Oc+5z3Pu81z3RT7zns/9nEpzc3NzAACAYtW09wQAAIB/jKIeAAAKp6gHAIDCKeoBAKBwinoAACicoh4AAAqnqAcAgMIp6gEAoHCKegAAaAPjx4/PsGHDMmTIkDz99NPrHNPU1JRx48blsMMOy+GHH57rr7/+NZ1bUQ8AAG3g0EMPzTXXXJMBAwasd8zEiRMzffr03H777bnuuuty2WWXZcaMGa96bkU9AAC0gX333TcNDQ0bHHPzzTfnxBNPTE1NTXr37p3DDjsst95666ueu8MbNUkAANjaNDY2prGxsdXx+vr61NfXv+7zzZo1K/3791/7c0NDQ2bPnv2qr2vjon7dvUMAAGzOdmvvCaxX3Q4fbNf3/8aZ78zll1/e6vjpp5+eM844o83mIakHAICNNHr06IwcObLV8Y1J6ZNqMj9z5szstddeSVon9+ujqAcAgI20sW0263PUUUfl+uuvzxFHHJGFCxfmjjvuyDXXXPOqr7NRFgCAYlUqNe36eD0uuuiivPvd787s2bPzkY98JO9///uTJGPGjMnkyZOTJCNGjMjAgQNzxBFH5KSTTsqnPvWpbL/99q9+HZqbm5tf/+XbWHrqAQDKs/n21Hfd8ZR2ff+lf371FL0tSOoBAKBweuoBAChWRUadRFIPAADFk9QDAFCs17tZdUvlKgAAQOEU9QAAUDjtNwAAFEv7TZWrAAAAhZPUAwBQrEql0t5T2CxI6gEAoHCKegAAKJz2GwAACiajTlwFAAAonqQeAIBiuaVllasAAACFU9QDAEDhtN8AAFAs7TdVrgIAABROUg8AQLEqMuokknoAACieoh4AAAqn/QYAgGLZKFvlKgAAQOEU9QAAUDjtNwAAFEv7TZWrAAAAhZPUAwBQLEl9lasAAACFU9QDAEDhtN8AAFCsSirtPYXNgqQeAAAKJ6kHAKBYNspWuQoAAFA4RT0AABRO+w0AAMXSflPlKgAAQOEk9QAAFEtSX+UqAABA4RT1AABQOO03AAAUTEaduAoAAFA8ST0AAMWyUbbKVQAAgMIp6gEAoHDabwAAKJb2mypXAQAACiepBwCgWBUZdRJJPQAAFE9RDwAAhdN+AwBAsWyUrXIVAACgcIp6AAAonPYbAACKValU2nsKmwVJPQAAFE5SDwBAsWyUrXIVAACgcIp6AAAonPYbAACKVZFRJ5HUAwBA8ST1AAAUy0bZKlcBAAAKp6gHAIDCab8BAKBY2m+qXAUAACicpB4AgGK5pWWVqwAAAIVT1AMAQOG03wAAUC4bZZNI6gEAoHiSegAAiuWWllWuAgAAFE5RvxlbuHBRPvWpr+Stbz0h73nPqZk48fftPSW2YNYbbcl6o61Zc2zptN9sxi688Afp2LFD/vjH/5cnnng+H/vYhdl9952y6647tvfU2AJZb7Ql6422Zs1tuSqVSntPYbMgqd9MLV26PLfffnc+85kPpVu3uuy77x4ZNmz/3HTT79p7amyBrDfakvVGW7Pm2Bq8pqR+wYIFmT17dpJku+22y5ve9KZNOimSadNeTE1NTXbaacDaY7vvvlMeeOB/23FWbKmsN9qS9UZbs+a2bL5RtmqDRf306dNz3nnnZcqUKenbt2+SZO7cufmnf/qnjBs3LoMGDWqLOW6Vli5dnh49urY41qNHtyxZsqydZsSWzHqjLVlvtDVrjq3BBov6s846K6NGjcqVV16Zmprqb0Fr1qzJxIkTc/bZZ+e6665rk0lujbp27ZLFi5e2OLZ48dJ061bXTjNiS2a90ZasN9qaNcfWYIN/r1i4cGGOOeaYtQV9ktTU1GTEiBF55ZVXNvnktmaDBg1IU9OaTJs2c+2xJ5+cml122aEdZ8WWynqjLVlvtDVrbstWqdS062NzscGZ9OrVK5MmTUpzc/PaY83NzfnlL3+Z+vr6TT65rVnXrl1y+OEH5NJLr8nSpcvz0ENT8pvf3JcRI97T3lNjC2S90ZasN9qaNcfWoNL8fyv2vzNt2rSMHTs2TzzxRPr165ckmTNnTnbfffdccMEFGTx48Ot8u6f/kbludRYuXJRzz70kd9/9p/Tq1SOf//zoHH30Ie09LbZQ1httyXqjrVlz/6jd2nsC67Xbft9t1/d/+oFPtev7/9UGi/q/mj9/fmbNmpUkaWhoSO/evTfy7RT1AADl2YyL+v2/167v//T9n2zX9/+r13RLy969e/8DhTwAALAp+UZZAADKtfnsVW1XLgMAABROUQ8AAIXTfgMAQLkqlfaewWZBUg8AAIWT1AMAUC5JfRJJPQAAFE9RDwAAhdN+AwBAuUTUSVwGAAAonqQeAIBiNdsom0RSDwAAxVPUAwBA4bTfAABQLt03SST1AABQPEk9AADlqhHVJ5J6AAAonqIeAAAKp/0GAIByuU99Ekk9AAAUT1IPAEC5BPVJJPUAAFA8RT0AABRO+w0AAOVyn/okknoAACieoh4AAAqn/QYAgHK5T30SST0AABRPUg8AQLkE9Ukk9QAAUDxFPQAAFE77DQAA5XKf+iSSegAAKJ6kHgCAcgnqk0jqAQCgeIp6AAAonPYbAACK1ewbZZNI6gEAoHiSegAAyuWWlkkk9QAAUDxJPQAAtJGpU6fmnHPOycKFC9OrV6+MHz8+gwYNajFm3rx5+cIXvpBZs2Zl1apVecc73pEvfelL6dBh/aW7pB4AgHJV2vnxOo0dOzajRo3KbbfdllGjRuX8889vNeYHP/hBdt5550ycODETJ07M448/nttvv32D51XUAwDARmpsbMyMGTNaPRobG1uNnTdvXqZMmZLhw4cnSYYPH54pU6Zk/vz5LcZVKpUsWbIka9asycqVK7Nq1ar069dvg/PQfgMAQLna+ZaWV111VS6//PJWx08//fScccYZLY7NmjUr/fr1S21tbZKktrY2ffv2zaxZs9K7d++14z75yU/mjDPOyIEHHphly5bllFNOyT777LPBeSjqAQBgI40ePTojR45sdby+vn6jz3nrrbdmyJAhueqqq7JkyZKMGTMmt956a4466qj1vkZRDwAAG6m+vv41F/ANDQ2ZM2dOmpqaUltbm6ampsydOzcNDQ0txk2YMCFf/epXU1NTkx49emTYsGG57777NljU66kHAKBcNZX2fbwOffr0ydChQzNp0qQkyaRJkzJ06NAWrTdJMnDgwNx5551JkpUrV+aee+7JrrvuuuHL8LpmAgAAbLQLLrggEyZMyJFHHpkJEyZk3LhxSZIxY8Zk8uTJSZJzzz03Dz30UI4++ugce+yxGTRoUE466aQNnrfS3NzcvMlnv9bTbfdWAAC8QXZr7wms1y7HXt2u7//sjf9fu77/X+mpBwCgXO1785vNhvYbAAAonKQeAIBytfN96jcXknoAACicoh4AAAqn/QYAgHJpv0kiqQcAgOJJ6gEAKJeIOonLAAAAxVPUAwBA4bTfAABQLhtlk0jqAQCgeJJ6AADKJahPIqkHAIDiKeoBAKBw2m8AAChWc43+m0RSDwAAxZPUAwBQLre0TCKpBwCA4inqAQCgcNpvAAAol+6bJJJ6AAAonqQeAIByuaVlEkk9AAAUT1EPAACF034DAEC53Kc+iaQeAACK16ZJ/R/nPNOWb8dW7LIpPdp7Cmxlbhr9/faeAsAms2z6te09BV6F9hsAAMql+yaJ9hsAACiepB4AgHK5T30SST0AABRPUQ8AAIXTfgMAQLm03ySR1AMAQPEk9QAAFKtZUJ9EUg8AAMVT1AMAQOG03wAAUC4bZZNI6gEAoHiSegAAylWR1CeSegAAKJ6iHgAACqf9BgCActkom0RSDwAAxZPUAwBQLhF1EpcBAACKp6gHAIDCab8BAKBc7lOfRFIPAADFk9QDAFAut7RMIqkHAIDiKeoBAKBw2m8AAChWs42ySST1AABQPEU9AAAUTvsNAADlElEncRkAAKB4knoAAMrlPvVJJPUAAFA8RT0AABRO+w0AAOVyn/okknoAACiepB4AgHLZKJtEUg8AAMVT1AMAQOG03wAAUC7dN0kk9QAAUDxJPQAAxWq2UTaJpB4AAIqnqAcAgMJpvwEAoFzab5JI6gEAoHiSegAAylWR1CeSegAAKJ6iHgAACqf9BgCAcomok7gMAABQPEU9AAAUTvsNAADlcvebJJJ6AAAonqQeAIBy+UbZJJJ6AAAonqIeAAAKp/0GAIByab9JIqkHAIDiSeoBAChWs1taJpHUAwBA8RT1AABQOO03AACUS0SdxGUAAIDiSeoBACiXjbJJJPUAAFA8RT0AABRO+w0AAOXyjbJJJPUAAFA8ST0AAOWS1CeR1AMAQPEU9QAAUDjtNwAAlEv3TRJJPQAAFE9SDwBAsZptlE0iqQcAgOJJ6tvB4sYluXL8dXn8gafTo2e3HH/a+/KOw/dpNe6Wa3+bu299MC/PXpAePbvlPSPfmfd+cFiLMb++/s78+vo707hwcfr07ZUzvnZqttu+b1t9FAqxesmSTL/6x1n0xJTUdu+e/scel977v32949esXp0nvzwua1Ysz55f/+ba4498fExqOnVKKtVU5E377pcd/nn0Jp8/W56Pjz4iHzrx4Ow5ZPv89Jd357TP/6C9p8QWzHpja6CobwcTLv55OnTokO/cOC7Tn30xl5z9X9l+lwEZsNN2LQc2Jx89d1QG7tyQuTPn5duf/4/07vumvP3QtyVJ7px0b/7wq/vymW98NP137JeXZs5L1x517fCJ2Ny9cO01qXTokD2/8a0sm/FCnrv8stQNHJi6/gPWOX7u7belQ48eWblieavndv/S2HTu6xdH/jGz5izI+Et/kcMO3it1XTq193TYwllvW7iK9ptE+02bW7FsRR76n8cy8qNHpUvXztltr8F567v2yN23Pdhq7HtHDcuOQwamtkNtGnbom7ceuEeenTw1SbJmzZrcdOXt+cAZIzJg0HapVCrpO2CbdK/v1tYfic1c04oVeeWRh9NwzIjUdumS7rvsmp5veUvm33fvOsevePmlzL//3vQ76r1tPFO2Jjfd+kAm3v5g5i9Y3N5TYStgvbE1kNS3sdkvvJSamkqLFpntd+6fpx59boOva25uzjOPTc3BxxyQJFnw0itZ8NLCvPj87Fzx1f9ObW1N3nnUvjnmw0ekpsbvavzNijlzkpqadOn3t78E1Q0YmMXPPL3O8TOuuzb9R4xMTcd1p1lPf+sbSXNzug3eOQNOOCmdt9lmk8wbAHjtFPVtbMWylanr3rJFpq57lyxfumKDr7vpytuyZs2aHPje/ZMkC+YuTJI8/sBT+fKPz8zSxcvyrc//R960bc8cfPQBm2byFGnNiuWprWu55mrr6rJmeevWmoWPPJzmpjXp9ba9s+ipp1o9v+vnz0zXnQZnzcqVmXXTjXn+e5dl9y+en0pt7SabPwBskLvfJPkH2m+OPvroN3IeW43OdZ2yfEnLYmrZkhXp0rXzel/zmxv+kLtvfTCfHT8mHTtVfw/r2LljkuS9o96Trj3qsk1D7xx8zAF57N4nNt3kKVJN5y5pWtZyzTUtX56aLl1aHluxIjN/fkMGnvzB9Z6r+667paZDh3To2jUDT/5AVr78cpbPnrVJ5g0AvHYbTOqfffbZ9T63YMGCN3wyW4Pttt82TU1rMueFl9Jv+22TJC88NzP9B223zvF/+NV9ufknv83Zl52e3n17/e08O/RNh4618TVqvJrO/fola5qyfM6cdOnXL0mybMYL6dK/f4txK+bOyYp58/LMt76RJGlevTpNy5Zl8lmfz25nfWHdbTaVStK8yT8CAKyfUijJqxT1w4cPz4ABA9Lc3Ppf7YULF26ySW3JOtd1zj7vfnN+8aNb85GzTsr0Z2fmT3f9b8793qdbjb3n9odyw3/enLO+88n07d+n5Xm6dMp+w96WW679XXbYbUCWLV6eOyfdm6M+cEgbfRJKUdu5c3q+be/MmnhTdvjn0Vn2wgt55dFHs9tZZ7cYV9d/QPb82vi1Py95/rm88N8/ye7nnpcOPXpk2cwX09zUlLoBA6vtN7+8MR179UqXhnX/QgobUltbkw4dalNbW5Pa2pp07twxq1c3palpTXtPjS2Q9cbWYINF/YABA/KTn/wk/f6S7v1fBx988Cab1JbuQ/96fK78+nX5zIix6V7fNf/8r8dnwE7b5elHn8/FZ/0w37/t60mSX/zXLVnyypJ8+WMXr33tAYfvk//v306snuezx+Wqb/40/zpyXLp2r8vBR789B71//fceZ+u1/QdPyfSrf5z/PfNfU9ute7YfdUrq+g/I4meeznOXX5q3XHJ5KrW16diz59rX1HbtlkqlsvbY6sbGvHDtNVm1YEFqOndOt8E7Z/Anz0il1tYcXr9zPj0yX/rcCWt/HnXcQbno4p/lKxff0I6zYktlvbE1qDSvK4b/i/Hjx+fwww/P3nvv3eq5iy66KF/60pde15v9cc6vXv8MYSNcNqVHe0+BrcxNo7/f3lMA2GSWTb+2vaewXoMu/592ff9pp28eQfcGI7azzz57vc+93oIeAADYNPzdHACAYvlC2SrfUgQAAIVT1AMAQOG03wAAUCztN1WSegAAKJykHgCAYlVE9Ukk9QAAUDxFPQAAtJGpU6fm5JNPzpFHHpmTTz4506ZNW+e4m2++OUcffXSGDx+eo48+Oi+//PIGz6v9BgCAYpXWfTN27NiMGjUqI0aMyE033ZTzzz8/V199dYsxkydPzuWXX56rrroq2267bRYtWpROnTpt8LySegAAaAPz5s3LlClTMnz48CTJ8OHDM2XKlMyfP7/FuB//+Mc59dRTs+222yZJevTokc6dO2/w3JJ6AACK1d5JfWNjYxobG1sdr6+vT319fYtjs2bNSr9+/VJbW5skqa2tTd++fTNr1qz07t177bjnnnsuAwcOzCmnnJKlS5fm8MMPzyc+8YkNbgpW1AMAwEa66qqrcvnll7c6fvrpp+eMM87YqHM2NTXlqaeeypVXXpmVK1fmox/9aPr3759jjz12va9R1AMAwEYaPXp0Ro4c2er436f0SdLQ0JA5c+akqakptbW1aWpqyty5c9PQ0NBiXP/+/XPUUUelU6dO6dSpUw499NA89thjGyzq9dQDAFCsSk37Purr6zNw4MBWj3UV9X369MnQoUMzadKkJMmkSZMydOjQFq03SbXX/q677kpzc3NWrVqVe++9N7vvvvsGr4OiHgAA2sgFF1yQCRMm5Mgjj8yECRMybty4JMmYMWMyefLkJMn73//+9OnTJ+973/ty7LHHZpdddskJJ5ywwfNWmpubmzf57P/ij3N+1VZvxVbusik92nsKbGVuGv399p4CwCazbPq17T2F9RryX3e26/s/9dF3t+v7/5WkHgAACqeoBwCAwrn7DQAAxaop7BtlNxVJPQAAFE5RDwAAhdN+AwBAsSrab5JI6gEAoHiSegAAiiWpr5LUAwBA4RT1AABQOO03AAAUq6L/JomkHgAAiiepBwCgWBURdRJJPQAAFE9RDwAAhdN+AwBAseyTrZLUAwBA4ST1AAAUS1JfJakHAIDCKeoBAKBw2m8AACiW9psqST0AABROUg8AQLFqJPVJJPUAAFA8RT0AABRO+w0AAMWyUbZKUg8AAIVT1AMAQOG03wAAUCztN1WSegAAKJykHgCAYlXcqD6JpB4AAIqnqAcAgMJpvwEAoFg2ylZJ6gEAoHCSegAAiiWpr5LUAwBA4RT1AABQOO03AAAUS/tNlaQeAAAKJ6kHAKBYvlC2SlIPAACFU9QDAEDhtN8AAFAsG2WrJPUAAFA4ST0AAMWqiKiTSOoBAKB4inoAACic9hsAAIplo2yVpB4AAAonqQcAoFgVUX0SST0AABRPUQ8AAIXTfgMAQLF031RJ6gEAoHCKegAAKJz2GwAAiqX9pkpSDwAAhZPUAwBQLEl9laQeAAAK16ZJ/UeO/nNbvh1bsQWvPNPeU2ArU99tYHtPga1It0Pf2d5TADYz2m8AAChWjfabJNpvAACgeJJ6AACKJamvktQDAEDhFPUAAFA47TcAABSrptLc3lPYLEjqAQCgcJJ6AACKZaNslaQeAAAKp6gHAIDCab8BAKBYEuoq1wEAAAonqQcAoFhuaVklqQcAgMIp6gEAoHDabwAAKJb71FdJ6gEAoHCSegAAiiWhrnIdAACgcIp6AAAonPYbAACKZaNslaQeAAAKp6gHAIDCab8BAKBYlUpze09hsyCpBwCAwknqAQAolo2yVZJ6AAAonKIeAAAKp/0GAIBiSairXAcAACicpB4AgGLVuKVlEkk9AAAUT1EPAACF034DAECx3Ke+SlIPAACFk9QDAFAsCXWV6wAAAIVT1AMAQOG03wAAUCwbZask9QAAUDhJPQAAxfKNslWSegAAKJyiHgAACqf9BgCAYtkoWyWpBwCAwinqAQCgcNpvAAAoloS6ynUAAIDCSeoBACiW+9RXSeoBAKBwinoAACic9hsAAIrlPvVVknoAACicpB4AgGJJ6qsk9QAAUDhFPQAAFE77DQAAxZJQV7kOAABQOEk9AADF8o2yVZJ6AAAonKIeAAAKp6gHAKBYNZX2fbxeU6dOzcknn5wjjzwyJ598cqZNm7besc8//3ze8pa3ZPz48a9+HV7/VAAAgI0xduzYjBo1KrfddltGjRqV888/f53jmpqaMnbs2Bx22GGv6bw2ygIAUKz2TqgbGxvT2NjY6nh9fX3q6+tbHJs3b16mTJmSK6+8MkkyfPjwfPnLX878+fPTu3fvFmN/+MMf5pBDDsnSpUuzdOnSV51He18HAAAo1lVXXZVDDz201eOqq65qNXbWrFnp169famtrkyS1tbXp27dvZs2a1WLck08+mbvuuisf/vCHX/M8JPUAALCRRo8enZEjR7Y6/vcp/Wu1atWqnHfeefna1762tvh/LRT1AAAUa2M2q76R1tVmsz4NDQ2ZM2dOmpqaUltbm6ampsydOzcNDQ1rx7z00kuZPn16TjvttCTV9p7m5uYsXrw4X/7yl9d7bkU9AAC0gT59+mTo0KGZNGlSRowYkUmTJmXo0KEt+un79++f++67b+3Pl112WZYuXZqzzz57g+fWUw8AQLEqleZ2fbxeF1xwQSZMmJAjjzwyEyZMyLhx45IkY8aMyeTJkzf6OkjqAQCgjey88865/vrrWx3/z//8z3WOP+OMM17TeSX1AABQOEk9AADFau+NspsLST0AABROUQ8AAIXTfgMAQLEk1FWK+nbQs75zvvql9+Rdb98+CxYuz7e+d28m3fZMq3EdO9bkS58/KIcfvFM6dKjJw4/Nztiv/0/mvLQkSfLI78e0GN+lc21+csP/5sv/flebfA7K0atn13znKyfnkHcNyfwFS3LRt3+Vn096uNW4+h5d8tUvHpdh7949SXLlT/6Yb15+29rnH/rNedl2m+5Z01S9hdf9j0zLSf/yg7b5EBSjV8+6XHzRSTnknbtl3sIl+eq3b87Pf/WnVuPqe3TJReeOyKEH/WW9XXt3/v27v2417oD9BufGqz+Ri39wR75+yW2tnmfr1rNrx3z9lL1z0O59s2DJynzzl4/nlw/OaDXuR584IPvtss3anzvW1mTq3EV571d/mz7dO+X8E/bK/rtuk66dOuSpmY35ys8n59E/L2jLjwL/EEV9Oxh75ruzatWavPOoKzN0t23yw4vfnyefeTnPPt/yPx6jP7BX3vbmfjn6lOuyaPHKfOXcQ3Levx2U08++NUnytkP+duujui4dcvetH8ktv3muTT8LZRh//vFZtaope7zr/Ow5dEB+8h9j8viTM/PUs7NbjLvoC8emrq5j9hn25WzTp3tu+PEnM2Pmglz78/vXjvnQx6/Infc83dYfgYJ8/byRWbVqdfY4aFz23L1/rvnBqXn8qVl56tk5LcZdeM4xqevSMfse9tVs07t7fnblxzJj5oL89y8eXDumQ4eaXPSFEXno0T+39cegEBee9JasWr0m+3/h5vzTwF654hMH5IkZr+SZ2YtajDv1+/e0+Pknnzkw9zz1UpKka+cOeWz6wlz088mZt2hFTnrnoFzxiQPy7vNvy9KVTW32Wdg4NRtxr/gtkb9YtLG6Lh1yxLDB+c5/3Jely1bnoUdn57d3Tsux7x3SauzA/vX5w70vZN78ZVm5sim/+vWz2WXwm9Z53qMO3TnzFyzNg4/M2tQfgcJ0reuU4Ufsla9dckuWLF2Z+x6amlt/+3hOGrFvq7FHDNsjl/3Xb7Ns+aq88OKC/ORn92XU8W9vh1lTqq51HfP+w9+cr196W5YuXZn7H56W2343JSces3ersUe855/y3St+X11vMxfkJzfcnw8et1+LMZ/48MH5/d1P55nnX2qrj0BB6jrV5si3DsjFv3oiS1c25cHn5+WOybMycv8dNvi6Ab27Zr+dt8kvHnghSfLCvKW54rfP5qXGFVnTnPz3H6elY21NBvfr0RYfA94Qivo2NmiHXlnT1Jxp019Ze+yJZ+Zll8G9W4392S+fyN57bZe+23RNl84dcvRRu+bOu6ev87zHvn9IbrxZekprOw/aNk1r1uT5aX8rih5/8sUM2WW7dY6v5G/3BqtUkt13bTnu+//+oTxxz5fz0ys+nj2G9N80k6ZYgwdtm6Y1zXl+2strjz3+5Kz1r7fK+tfbwP698sHj98u3vte6JQeSZKe+3bNmTXOmzl289tgTL76SXRs2XIwft//2eeC5lzNj3tJ1Pj90QM906lCTP7+0eJ3Pw+Zog0X9ggUL8sUvfjGnnnpqrrnmmhbPvdZvt6Klbl07ZtGSlS2OLV68It03xRdqAAAZSUlEQVS6dmw1dur0hZk1e3HuuvnDefh3H83Og96U717xYKtxDf26Z/+39c8vfvXkJps35erWtXMWLVre4ljjouXp3q1zq7G//cOT+fRph6Zbt87ZaYdt8sHj3566uk5rn//EmROyz7AvZ+/3XJg/3vdMfnrFx1Lfo8sm/wyUY13rbdHiZem2jvX2uz88lTPGvCfdunbOoB365IPH7d9ivX3l3GMz/i+JP6xLt84dsmj5qhbHFi1bnW5dNtxdPPLtO+SGe9cdknXv0iHfHr1PLr3lySxavvoNmyubTk2lfR+biw0W9WPHjk3Pnj3zgQ98IHfccUdOP/30rF5dXeAvvPBCm0xwS7Nk6ap079aygO/erVOWLF3Vauy4sw9O58612e+wK/KWg3+Y23/3fP7rO8NbjTv2/UPy0KOzMmPmolbPwZKlK9K9e8vCu0f3Llm8ZEWrsede9IssX7Eq9992bq7+3r/kF796ODNnL1z7/P0PT83yFauybPmqXPLD3+SVRcvyjn133uSfgXJU11vLAr57ty5Zso719sWv3pjly1fl3lvPzlXf/XB+cfMjmTW7+lfMIw4Zmu7dOuemWx5tk3lTpiUrVqf73xXw3bt0yJINFOP7Du6Tbeu75JZHXmz1XOeONfnPjx2QR6YuyPdv99dvyrLBX2X//Oc/59JLL02SHH744bnwwgvzsY99LN/73vfaZHJbomnTF6a2tiY7bt8zf36h+o/X7rttk2efn99q7O679snF378vrzRW/zH8fz+dnM9+/O15U88uWfDK35KwY983JD+8qvWdTCBJnpv2UjrU1mTwjtvk+T9XWyL22L1/q02ySbLwlaX5xL9NWPvzFz/3vjzy2LrTrCRpbq62TMBfPf+X9bbTjttk6quut2X55FnXrv353M8elUcmV9fbQQfsmrfsOTCT7zw/SdKjR5esaVqTobs2ZPTpP970H4QiTJ27OLU1NRm0bbdM+8ud4YYO6JlnZq0/5Dru7Tvktj/NbLUBtlOHmvzHae/InFeW5Yv//cgmnTdvrM0pLW9PG0zqV6782588K5VKxo4dm9122y2nnXZaVqxonbrw6pYtX51f/+75fOa0/VPXpUP23mu7HPruQbnxlqdajZ08ZW6Ofd+QdO/WKR1qa3LKCXtmztzFLQr6t715u/Tbtltuddcb1mPpspX51a8fy9mffm+61nXK/nvvlPceumd+elPrVq5B2/fJm3p1TU1NJYe+e/f888kH5Nvfr/YzD2jolf333ikdO9amc6cO+dS/vCe939Qt9z88ta0/EpuxpctW5eY7/jdnn3FEutZ1zH5vG5Sjhv1Trv9l6+Bhx/+z3oYdNCQfOukdufgHv0mSfP2S23LAe7+RYcddnGHHXZzbf/d4Jvzsvnzmi9e19UdiM7ZsZVNue3RmPvf+oanrVJt9BvfO4Xs15Bf3rzuM6NyxJu97W//ccF/Luyl1qKnku/+yf5avbMrnr34ozW6mQoE2WNRvv/32eeCBB1ocO/vss/PWt74106ZN25Tz2qJd8I0706VLbe657SP59kWHZ+z4O/Ps8wuy71sbWtx7fvyld2fFyqb8+oZRuff2j+Tgd+6YT511a4tzjXz/kPz6d8+vs30H/uqscTekS5eOmXL3hfmPb/1zzrzgZ3nq2dl5xz6DM+3hr68d95Y9t8+dE8/K1Ie/ni/96/B84t8mrE1Yu3frkm9ccEKeuf8reezOCzLsoN3zgTE/zIKF695oxtbr7At/ni6dO+bxuy7ID/59VM4e9/M89eycvH2fnfL8gxetHfeWPQbk9zf9a5578KJ88XPvyyfP/Mna214uWboiL728aO1j2fLVWbpsZRa+sqydPhWbq/Ov+1M6d6zNA197Xy758H4577o/5ZnZi7Lfzn0y+VtHtxh7xF79s2j56tzz9Mstju89uHcOfXNDDhraN3/65vBM/tbRmfyto7Pfzn3a8qPAP6TS3Lz+30cXLlyYSqWSnj17tnru2WefzS677PK63my3/bXt0DYWvNL6y7xgU6qp8bUftJ1uh76zvafAVub5y0e29xTW66JH7mjX9//S2w5r1/f/qw3+K9SrV6/1Pvd6C3oAAGDTEC0BAFAs3yhb5cunAACgcIp6AAAonPYbAACK5T71VZJ6AAAonKQeAIBiSeqrJPUAAFA4RT0AABRO+w0AAMWq1X6TRFIPAADFk9QDAFAsG2WrJPUAAFA4RT0AABRO+w0AAMWqqTS39xQ2C5J6AAAonKIeAAAKp/0GAIBiuftNlaQeAAAKJ6kHAKBYte09gc2EpB4AAAqnqAcAgMJpvwEAoFg2ylZJ6gEAoHCSegAAiuUbZask9QAAUDhFPQAAFE77DQAAxaq1UTaJpB4AAIonqQcAoFhuaVklqQcAgMIp6gEAoHDabwAAKJb2mypJPQAAFE5SDwBAsST1VZJ6AAAonKIeAAAKp/0GAIBi1Vaa23sKmwVJPQAAFE5SDwBAsSTUVa4DAAAUTlEPAACF034DAECx3Ke+SlIPAACFU9QDAEDhtN8AAFAs7TdVknoAACicpB4AgGL5RtkqST0AABROUQ8AAIXTfgMAQLFslK2S1AMAQOEk9QAAFEtSXyWpBwCAwinqAQCgcNpvAAAolvabKkk9AAAUTlIPAECxaiX1SST1AABQPEU9AAAUTvsNAADFqqk0t/cUNguSegAAKJykHgCAYkmoq1wHAAAonKIeAAAKp/0GAIBi+UbZKkk9AAAUTlEPAACF034DAECxarXfJJHUAwBA8ST1AAAUyzfKVknqAQCgcIp6AAAonPYbAACK5T71VZJ6AAAonKQeAIBiSeqrJPUAAFC4Nk3qX5j9h7Z8O4A20//AY9p7CmxNlq1u7xkAmxntNwAAFEvbSZXrAAAAhZPUAwBQrIqNskkk9QAAUDxFPQAAFE77DQAAxdJ9UyWpBwCAwknqAQAolo2yVZJ6AAAonKIeAAAKp/0GAIBiSairXAcAACicpB4AgGJVKs3tPYXNgqQeAAAKp6gHAIDCab8BAKBYblNfJakHAIDCKeoBAKBw2m8AAChWRf9NEkk9AAAUT1IPAECxBPVVknoAACicoh4AAAqn/QYAgGLV6L9JIqkHAIDiSeoBACiWoL5KUg8AAIVT1AMAQOG03wAAUKzSvlF26tSpOeecc7Jw4cL06tUr48ePz6BBg1qM+e53v5ubb745tbW16dChQz73uc/loIMO2uB5FfUAANBGxo4dm1GjRmXEiBG56aabcv755+fqq69uMWavvfbKqaeemrq6ujz55JP50Ic+lLvuuitdunRZ73m13wAAUKxKOz9ej3nz5mXKlCkZPnx4kmT48OGZMmVK5s+f32LcQQcdlLq6uiTJkCFD0tzcnIULF27w3JJ6AADYSI2NjWlsbGx1vL6+PvX19S2OzZo1K/369UttbW2SpLa2Nn379s2sWbPSu3fvdZ7/xhtvzA477JDttttug/NQ1AMAwEa66qqrcvnll7c6fvrpp+eMM874h859//3355JLLsmPfvSjVx2rqAcAoFjtvU929OjRGTlyZKvjf5/SJ0lDQ0PmzJmTpqam1NbWpqmpKXPnzk1DQ0OrsY888kjOPPPMfO9738vgwYNfdR6KegAA2EjrarNZnz59+mTo0KGZNGlSRowYkUmTJmXo0KGtWm8ee+yxfO5zn8ull16aPfbY4zWdu9Lc3Nz8ume/kep2+GBbvRVAm+p/4DHtPQW2JnUyOdrWc1ec2N5TWK+nX5nUru+/W8/hr2v8c889l3POOSeNjY2pr6/P+PHjM3jw4IwZMyaf/vSn8+Y3vznHH398XnzxxfTr12/t677xjW9kyJAh6z2voh7gDaCop00p6mljivr1e71F/abilpYAAFA4v+oDAFCs9t4ou7mQ1AMAQOEk9QAAFKtSabPtoZs1ST0AABROUQ8AAIXTfgMAQLFslK2S1AMAQOEU9QAAUDjtNwAAFKui/yaJpB4AAIonqQcAoFgS6irXAQAACqeoBwCAwmm/AQCgWDbKVknqAQCgcJJ6AACKJaivktQDAEDhFPUAAFA47TcAABTLRtkqST0AABROUg8AQLEE9VWSegAAKJyiHgAACqf9BgCAYtXov0kiqQcAgOJJ6gEAKJagvkpSDwAAhVPUAwBA4bTfAABQrEqlub2nsFmQ1AMAQOEU9QAAUDjtNwAAFMvdb6ok9QAAUDhJPQAAxaqI6pNI6gEAoHiKegAAKJz2GwAAiqX7pkpRv5n6+Ogj8qETD86eQ7bPT395d077/A/ae0ps4aw53ig9u3XK10/bPwe+uSELFq3IN697NBPv/nOrcT866+Dsu/u2a3/u2KEmU2cuyvvOuWXtsQ8ftVs+fNSQ9KnvkpnzluRj3/pDps1e1CafgzL07NYxX//wfjlwj35ZsHhFvnnD5Ey874VW43702QOz765/t95mL8r7xt7eYtz+u22Ta89+T747aUq+/YvHN/n84Y2iqN9MzZqzIOMv/UUOO3iv1HXp1N7TYStgzfFGGfeRfbNq9Zq8/RO/yNBBvXLFmQfnyT8vyDMvNrYYd+o3/qfFz9d8aVjueXzO2p9POmRwTjxk53z0m/+TZ19szA59u+eVJSvb5DNQjnGn7F1db5/7ZYZu3ytXfOagPPnCK3lm5t+tt+/c1eLna848OPc8ObfFsQ61lZz3wbflkefmbfJ588bRS17lOmymbrr1gUy8/cHMX7C4vafCVsKa441Q17k2R+4/MN++fnKWrlidh556OXc89GKOPWinDb5uwDbdst/u2+bGu6Ylqd7N4tPH75mv/L+H8+xffhmYPnexop4W6jrV5sh9BubbN/5vlq5oykPPzssdj87MsQfsuMHXDejTNfvttm1uvKflX5D+5Yjdctfjs/O8vwZRoNdd1L/yyiubYh4AbAF22q4+a9Y0t2iReXL6wuw6sOcGXzfyoEF54MmXMuOlJUmS7Xp3TUOfbtlt+56567Jj8vvvHJ3PHL+nW9fRwk7b9aiutzl/CyOefGFhdu1fv8HXjXznjnng6Zcy4+Wla4/179M1Jx64Uy6bOGWTzRc2pQ0W9U8++WSOO+64nHDCCXnuuedy2mmn5d3vfncOPvjgPPHEE201RwAK0bVLhyxauqrFsUVLV6Vblw13ex530E75+Z1T1/7c0LtrkuTAN2+X9559S0656Lc5+p075qRDdn7jJ02xunbukEXL/m69LXsN6+2AQfn53dNaHDv/g2/NxX9J/ClLpdK+j83FBov6iy66KJ/61KfyoQ99KB/96EczfPjwPProoxk7dmzGjx/fVnMEoBBLl69O97qOLY51r+uYJctXr/c1+wzZJtv06pJb/s/mxuUrq4XVDyc+kUVLV+XFl5fk2t88l0Pe2rBpJk6Rlq5Yne5/V8B37/Iq622XPtmmZ5fc8uCMtceGvaUh3bt0zK8emLHe18HmboO/yi5ZsiSHHnpokuSSSy7JMccckyQZNmxYLr300k0/OwCKMnV2Y2prKxm0XfdMm11tiRi6Y688M2P9rZvHH7RTbn9gRpau+Fsh9vysxqxY1ZTmTT5jSjZ19qLU1tZkUN/umTb3L+tt+56tNsn+X8e/a1Buf3hGi0T+nUP7Zs9Bb8q93z46SdKjrmOa1jRntwE98/HL7960H4I3wGYUl7ejDSb1zc1/+8/pu971rhbPrVmzZtPMiCRJbW1NOnfumNramhb/HzYVa443wrIVTbn9gRn57Al7pa5zbfbZbZscts+A3PiHqesc37ljbd779h1yw/+0fH75yqbcfO/0nDZ8aLp16ZDtetfl5GE757ePzGyLj0Ehlq1syu0Pz8hnj90jdZ1qs88ufXLYWwe02gD7V5071uS9+w7MDX+c1uL4xTc+nsPOvSXDL7g9wy+4Pb/508xcd+fzOfvKB9rgU8AbY4P/Yg8YMCCLF1d/873ooovWHp89e3bq6uo27cy2cud8emQWPnN1zvzUiIw67qAsfObqnPPpke09LbZg1hxvlPN/9GC6dKrN/d8/Lt85/Z0570cP5pkXG7PvkG3z2I9OaDH2iH0HZtHSVblnypxW57ngxw9m6YrVufu7x+Zn4w7PL/84Ldf//vm2+hgU4vwJD1fX23eOyXdOe0fOm/BQnpnZmH133SaPfbflf8OOeNuALFq2Kvc8+VKL40uWr87LjSvWPpavasqylavzypKW/fqwOas0/984/jVaunRpli1blj59+ryu19Xt8MHX+1YAReh/4DHtPQW2JnW+Zoa29dwVJ7b3FNZrwYpJ7fr+b+o8vF3f/6826r8KXbt2TdeuXd/ouQAAABvBr/oAABSrUrH/K/GNsgAAUDxFPQAAFE77DQAABXOf+kRSDwAAxZPUAwBQrIqkPomkHgAAiqeoBwCAwmm/AQCgYNpvEkk9AAAUT1EPAACF034DAECxKhUZdSKpBwCA4knqAQAomI2yiaQeAACKp6gHAIDCab8BAKBYFe03SST1AABQPEk9AADFktRXSeoBAKBwinoAACic9hsAAAomo05cBQAAKJ6kHgCAYlUqNsomknoAACieoh4AAAqn/QYAgIJpv0kk9QAAUDxJPQAAxfKNslWSegAAKJyiHgAACqf9BgCAgsmoE1cBAACKJ6kHAKBYNspWSeoBAKBwinoAACic9hsAAIpVqWi/SST1AABQPEU9AAAUTvsNAAAF036TSOoBAKB4knoAAIpVkVEnkdQDAEDxFPUAAFA47TcAABTMRtlEUg8AAMWT1AMAUCzfKFslqQcAgMIp6gEAoHDabwAAKJj2m0RSDwAAxZPUAwBQLN8oW+UqAABA4RT1AABQOO03AAAUzEbZRFIPAADFk9QDAFCsiqQ+iaQeAACKp6gHAIDCab8BAKBYlYr2m0RSDwAAxVPUAwBA4bTfAABQMBl14ioAAEDxJPUAABTLfeqrJPUAAFA4RT0AABRO+w0AAAXTfpNI6gEAoHiSegAAiuUbZask9QAAUDhFPQAAFE77DQAABZNRJ64CAAC0malTp+bkk0/OkUcemZNPPjnTpk1rNaapqSnjxo3LYYcdlsMPPzzXX3/9q55XUQ8AQLEq7fy/12vs2LEZNWpUbrvttowaNSrnn39+qzETJ07M9OnTc/vtt+e6667LZZddlhkzZmzwvIp6AADYSI2NjZkxY0arR2NjY6ux8+bNy5QpUzJ8+PAkyfDhwzNlypTMnz+/xbibb745J554YmpqatK7d+8cdthhufXWWzc4jzbtqV82/dq2fDsAALZ4u7Xru1911WW5/PLLWx0//fTTc8YZZ7Q4NmvWrPTr1y+1tbVJktra2vTt2zezZs1K7969W4zr37//2p8bGhoye/bsDc7DRlkAANhIo0ePzsiRI1sdr6+vb9N5KOoBAGAj1dfXv+YCvqGhIXPmzElTU1Nqa2vT1NSUuXPnpqGhodW4mTNnZq+99krSOrlfFz31AADQBvr06ZOhQ4dm0qRJSZJJkyZl6NChLVpvkuSoo47K9ddfnzVr1mT+/Pm54447cuSRR27w3JXm5ubmTTZzAABgreeeey7nnHNOGhsbU19fn/Hjx2fw4MEZM2ZMPv3pT+fNb35zmpqacuGFF+aPf/xjkmTMmDE5+eSTN3heRT0AABRO+w0AABROUQ8AAIVT1AMAQOEU9QAAUDj3qd+MTZ06Neecc04WLlyYXr16Zfz48Rk0aFB7T4st1Pjx43PbbbflxRdfzMSJE7Pbbu37DX1s2RYsWJCzzjor06dPT6dOnbLjjjvmwv+/vft3SSYO4Dj+6YQIIb0IitAh2o6WhqC9+aCgsfAPcHNKkJZ+gS21HDQ0tTRFBLpIREuD0CiCREMQHoX9LpqsZ3h4Wlqv5+t9eb82t/ekH88vX1dXf1zrBkQln8/r5uZGjuMomUxqZWVFnueZzgIiw+03PSyXy2lhYUFzc3M6Pj7W4eGh9vf3TWfBUhcXF8pkMlpcXNTu7i6jHr/q6elJrVZLMzMzkv5+qXx+ftbm5qbhMtjq9fVVg4ODkqSTkxMFQaCjoyPDVUB0OH7To+7v79VsNuX7viTJ9301m009PDwYLoOtpqenf/yjHfBbXNf9HvSSNDU1pXa7bbAItvs36CXp7e1NfX19BmuA6HH8pkeFYajR0VElEglJUiKR0MjIiMIw5OdpAFb5/PzUwcGBZmdnTafAcqVSSefn5/r6+tLe3p7pHCBSPKkHABi1tramZDKppaUl0ymw3MbGhs7OzlQoFLS1tWU6B4gUo75HjY2N6fb2Vt1uV5LU7XZ1d3fH8QgAVimXy7q+vtbOzo4ch48k/B/z8/Oq1+t6fHw0nQJEhnfQHjU8PCzP81SpVCRJlUpFnudx9AaANba3t9VoNBQEgfr7+03nwGLv7+8Kw/D79enpqdLptFzXNVgFRIvbb3rY1dWVisWiXl5elEqlVC6XNTExYToLllpfX1etVlOn09HQ0JBc11W1WjWdBUtdXl7K932Nj49rYGBAkpTNZhUEgeEy2KjT6Sifz+vj40OO4yidTmt5eVmTk5Om04DIMOoBAACAmOP4DQAAABBzjHoAAAAg5hj1AAAAQMwx6gEAAICYY9QDAAAAMceoBwAAAGKOUQ8AAADEHKMeAAAAiLk/AoKeJJrT1GQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14.0,12.0)})\n",
    "sns.heatmap(pd.DataFrame(df_sb),annot=True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An intriguing Ministry of Finance (MoF) report circulating in the Kremlin today says that elite Western bankers were stunned/bewildered a few hours ago after the Bank For International Settlements (BIS) registered a $1.8 billion transfer from the Clinton Foundation (CF) to the Qatar Central Bank (QCB) through the facilitation/abetment of JP Morgan Chase &amp; Company (JPM)and for reasons yet to be firmly established. [</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Note: Some words and/or phrases appearing in quotes in this report are English language approximations of Russian words/phrases having no exact counterpart.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to this report, the Bank for International Settlements is the worlds oldest international financial organization and acts as a prime counterparty for central banks in their financial transactions; the Qatar Central Bank is the bank of that Gulf State nations government and their bank of banks; JP Morgan Chase &amp; Company is the United States largest megabank; and the Clinton Foundation is an international criminal money laundering organization whose clients include the Russian mafia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With Hillary Clintons US presidential campaign Chairman John Podesta having longstanding ties to the Russian mafia and money laundering, this report continues, the Foreign Intelligence Service (SVR) maintains complete/all times/all ways surveillance of him and his criminal associatesincluding both Hillary Clinton and her husband, and former US President, Bill Clinton, and who are collectively designated as the Clinton Crime Family.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0\n",
       "0  An intriguing Ministry of Finance (MoF) report circulating in the Kremlin today says that elite Western bankers were stunned/bewildered a few hours ago after the Bank For International Settlements (BIS) registered a $1.8 billion transfer from the Clinton Foundation (CF) to the Qatar Central Bank (QCB) through the facilitation/abetment of JP Morgan Chase & Company (JPM)and for reasons yet to be firmly established. [                                                                              \n",
       "1  Note: Some words and/or phrases appearing in quotes in this report are English language approximations of Russian words/phrases having no exact counterpart.]                                                                                                                                                                                                                                                                                                                                                        \n",
       "2  According to this report, the Bank for International Settlements is the worlds oldest international financial organization and acts as a prime counterparty for central banks in their financial transactions; the Qatar Central Bank is the bank of that Gulf State nations government and their bank of banks; JP Morgan Chase & Company is the United States largest megabank; and the Clinton Foundation is an international criminal money laundering organization whose clients include the Russian mafia.\n",
       "3  With Hillary Clintons US presidential campaign Chairman John Podesta having longstanding ties to the Russian mafia and money laundering, this report continues, the Foreign Intelligence Service (SVR) maintains complete/all times/all ways surveillance of him and his criminal associatesincluding both Hillary Clinton and her husband, and former US President, Bill Clinton, and who are collectively designated as the Clinton Crime Family.                                                            "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x['sentences'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf_eval():\n",
    "\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "\n",
    "    for idx in dnf_eval.id: \n",
    "        hd = dnf_eval[dnf_eval.id==idx]['headline'].values[0].lower()\n",
    "        ar_id = dnf_eval[dnf_eval.id==idx]['id'].values[0]\n",
    "        cl = dnf_eval[dnf_eval.id==idx]['claim_ids'].values[0]\n",
    "        ar_claims.append(cl)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "\n",
    "\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "    #         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "\n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "\n",
    "        inputs = {\n",
    "            'article_id': np.array(ar_ids)\n",
    "            ,'headline': np.array(hds)\n",
    "            ,'sentence_vectors' : np.array(ar_sents)\n",
    "            ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "            ,'claims':np.array(ar_claims)\n",
    "            ,'sentences':np.array(ar_sentences)\n",
    "        }\n",
    "        outputs = {\n",
    "            'headline_token_classes': np.array(ar_head_classes)\n",
    "            ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "        }\n",
    "    return inputs,outputs\n",
    "testX,testY = datagen_dnf_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38499999999999995, 0.532, 0.4467175572519083)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(testX)\n",
    "_, b2, g2 = model_2.predict(testX)\n",
    "_, b3, g3 = model_3.predict(testX)\n",
    "_, b4, g4 = model_4.predict(testX)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in range(len(testX['headline'])):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(testX['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    pred = b[0][:len(testX['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "    \n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for p in pred:\n",
    "        if p in claims:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    for c in claims:\n",
    "        if c not in pred:\n",
    "            fn+=1\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "#     counter+=1\n",
    "#     if counter==5:\n",
    "#         break\n",
    "#     print(\"----------------------------\")\n",
    "#     for s in t:\n",
    "#         if s>=len(x['sentences'][test_idx]):continue\n",
    "#         x['sentences'][test_idx][s]\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4664e815594f7fa2aa826194848a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b6e0d3ae034cb186d804cc5f429ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24680851063829795, 0.10813559962496133, 0.150383035067809)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hd_tp_cdc = pd.read_csv('evaluation_set/cdc_ibm/headline_topic_mapping.csv')\n",
    "df_ar_cl_cdc = pd.read_csv('evaluation_set/cdc_ibm/article_claim_mapping.csv')\n",
    "df_hd_tp_dnf = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "df_hd_tp_dnf.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls']\n",
    "with open('evaluation_set/cdc_ibm/articles.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/cdc_ibm/article_vectors.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "df_hd_tp_cdc.keys(),df_ar_cl_cdc.keys(), len(articles.keys()), len(article_vectors.keys()), df_hd_tp_dnf.keys()\n",
    "test_titles = []\n",
    "for ar in df_ar_cl_cdc.Article.unique():\n",
    "    if len(df_ar_cl_cdc[df_ar_cl_cdc.Article==ar]['Claim'].values)>8:\n",
    "        test_titles.append(ar)\n",
    "ar_ids,ar_sents,ar_sentences,ar_head_vectors,ar_head_classes,hds,claims=[],[],[],[],[],[],[]\n",
    "for idx in tqdm_notebook(test_titles):\n",
    "#     print(idx)\n",
    "    hd = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['Headline'].values[0].lower()\n",
    "    hds.append(hd)\n",
    "    ar_id = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['article Id'].values[0]\n",
    "    cl = df_ar_cl_cdc[df_ar_cl_cdc.Article==idx]['Claim'].values\n",
    "    claims.append(cl)\n",
    "#     sentences=articles[ar_id]\n",
    "#     ar_sentences.append(ar_sentences)\n",
    "    #         print(len(sentences))\n",
    "    sents = np.zeros((max_sentences,300))\n",
    "    vectors = article_vectors[ar_id]\n",
    "    sents[:len(vectors)] = vectors[:max_sentences]\n",
    "    ar_ids.append(ar_id)\n",
    "    ar_sents.append(sents)\n",
    "    hd_nlp = nlp(hd.lower())\n",
    "    head_classes = np.zeros(50, dtype='int')\n",
    "    for i in range(len(hd_nlp)):\n",
    "        head_classes[i] = hd_nlp[i].rank\n",
    "    ar_head_vectors.append(hd_nlp.vector)\n",
    "    ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "inputs = {\n",
    "    'article_id': np.array(ar_ids)\n",
    "    ,'headline': np.array(hds)\n",
    "    ,'sentence_vectors' : np.array(ar_sents)\n",
    "#     ,'sentences' : np.array(ar_sentences)\n",
    "    ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "    ,'claims':np.array(claims)\n",
    "}\n",
    "outputs = {\n",
    "    'headline_token_classes': np.array(ar_head_classes)\n",
    "    ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "}\n",
    "threshold = 0.95\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(inputs)\n",
    "_, b2, g2 = model_2.predict(inputs)\n",
    "_, b3, g3 = model_3.predict(inputs)\n",
    "_, b4, g4 = model_4.predict(inputs)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in tqdm_notebook(range(len(inputs['headline']))):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(inputs['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    ids = b[0][:len(articles[inputs['article_id'][test_idx]])].argsort()[-best_N:][::-1]\n",
    "#     print(ids)\n",
    "    pred = np.array(articles[inputs['article_id'][test_idx]])[ids]\n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "        t5 = nlp(str(pred[i]))\n",
    "        flag = False\n",
    "        #pred_claim_sent.append(pred[i])\n",
    "    #     print(t5.vector)\n",
    "        for j in range(len(cl)):\n",
    "            _c = nlp(cl[j])\n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                tp+=1\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fp+=1\n",
    "        \n",
    "            \n",
    "   \n",
    "    #     print(t5.vector)\n",
    "    for j in range(len(cl)):\n",
    "        _c = nlp(cl[j])\n",
    "        flag = False\n",
    "        for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "            t5 = nlp(str(pred[i]))\n",
    "        \n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fn+=1\n",
    "         \n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
