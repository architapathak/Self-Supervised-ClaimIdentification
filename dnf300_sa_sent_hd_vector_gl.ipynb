{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import spacy\n",
    "from keras.utils import to_categorical\n",
    "from spacy.lang.en import English\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.layers import BatchNormalization, Lambda, Concatenate, Dropout, Conv1D, MaxPooling1D, Input, TimeDistributed, Dense, LSTM, RepeatVector, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from AttentionModules import SelfAttention, CrossAttention\n",
    "import sys,os\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['authors', 'claim_ids', 'evidence', 'headline', 'id', 'reason',\n",
       "        'claims', 'type', 'urls'],\n",
       "       dtype='object'),\n",
       " Index(['authors', 'evidence', 'headline', 'id', 'reason', 'type', 'urls'], dtype='object'),\n",
       " 300,\n",
       " 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf300 = pd.read_json('evaluation_set/deepnofakes/dnf_300/combined_300.json').T\n",
    "dnf_eval = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "# display(dnf_eval.head(2))\n",
    "dnf_eval.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls'] \n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_array_id.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "dnf_eval.keys(), dnf300.keys(), len(articles.keys()), len(article_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "train_batchsize = 32\n",
    "val_batchsize = 32\n",
    "test_batchsize = 50\n",
    "train_steps_per_epoch = 4\n",
    "val_steps_per_epoch = 1\n",
    "epochs = 2000\n",
    "max_sentences = 500\n",
    "# for idx in articles.keys():\n",
    "#     num = len(articles[idx])\n",
    "#     if num>=max_sentences:\n",
    "#         max_sentences = num\n",
    "        \n",
    "max_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = sorted(dnf_eval.headline.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "non_test_titles = np.array(list(set(titles)-set(test_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, val_index in kf.split(non_test_titles):\n",
    "    indices.append([train_index,val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n",
      " 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176\n",
      " 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194\n",
      " 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212\n",
      " 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230\n",
      " 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 251 252] [ 51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202, 51, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_index, val_index = indices[np.random.randint(0,num_splits)]\n",
    "print(train_index,val_index)\n",
    "val_titles = non_test_titles[val_index]\n",
    "train_titles = non_test_titles[train_index]\n",
    "len(train_titles),len(val_titles),len(test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy():\n",
    "    sentencizer = English()\n",
    "    sentencizer.add_pipe(sentencizer.create_pipe('sentencizer'))\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    return sentencizer, nlp\n",
    "sentencizer, nlp = load_spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf(batchsize,dataframe,mode):\n",
    "    counter=0\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            idx=np.random.choice(train_titles)\n",
    "        elif mode=='val':\n",
    "            idx=np.random.choice(val_titles)\n",
    "        elif mode=='test':\n",
    "            idx=np.random.choice(test_titles)\n",
    "        idx = idx.strip()\n",
    "        \n",
    "            \n",
    "#         cl = dataframe[dataframe.Article==idx]['Claim'].values\n",
    "#         sentences=articles[ar_id]\n",
    "#         print(len(sentences))\n",
    "        if mode=='test':\n",
    "            hd = dnf_eval[dnf_eval.headline==idx]['headline'].values[0].lower()\n",
    "            ar_id = dnf_eval[dnf_eval.headline==idx]['id'].values[0]\n",
    "            cl = dnf_eval[dnf_eval.headline==idx]['claim_ids'].values[0]\n",
    "            ar_claims.append(cl)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                hd = dataframe[dataframe.headline==idx]['headline'].values[0].lower()\n",
    "                ar_id = dataframe[dataframe.headline==idx]['id'].values[0]\n",
    "                ar_claims.append('None')\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(idx)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "#         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "        \n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "        counter+=1\n",
    "        if counter==batchsize:\n",
    "            inputs = {\n",
    "                'article_id': np.array(ar_ids)\n",
    "                ,'headline': np.array(hds)\n",
    "                ,'sentence_vectors' : np.array(ar_sents)\n",
    "                ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "                ,'claims':np.array(ar_claims)\n",
    "                ,'sentences':np.array(ar_sentences)\n",
    "            }\n",
    "            outputs = {\n",
    "                'headline_token_classes': np.array(ar_head_classes)\n",
    "                ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "            }\n",
    "            yield inputs,outputs\n",
    "            ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "            counter=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = datagen_dnf(train_batchsize,dnf300,mode='train')\n",
    "vdg = datagen_dnf(val_batchsize,dnf300,mode='val')\n",
    "test_dg = datagen_dnf(test_batchsize,dnf300,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(test_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['sentence_vectors'].shape, x['headline_vector'].shape, y['headline_token_classes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 500, 1024)    0           ca1[0][0]                        \n",
      "                                                                 ca2[0][0]                        \n",
      "                                                                 ca3[0][0]                        \n",
      "                                                                 ca4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 1024)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 500, 1024)    4096        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 250, 256)     786688      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 125, 256)     196864      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 63, 256)      196864      conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 32, 256)      196864      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 256)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 256)      1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_headline_vector (Dense)  (None, 300)          153900      batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,465,348\n",
      "Trainable params: 2,460,676\n",
      "Non-trainable params: 4,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"2130pt\" viewBox=\"0.00 0.00 1810.50 2130.00\" width=\"1811pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 2126)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-2126 1806.5,-2126 1806.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140511731782768 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140511731782768</title>\n",
       "<polygon fill=\"none\" points=\"857,-2075.5 857,-2121.5 1198,-2121.5 1198,-2075.5 857,-2075.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2094.8\">sentence_vectors: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2075.5 1033,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2098.5 1088,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2075.5 1088,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2106.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2098.5 1198,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2083.3\">(None, 500, 300)</text>\n",
       "</g>\n",
       "<!-- 140511731783160 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140511731783160</title>\n",
       "<polygon fill=\"none\" points=\"883.5,-1992.5 883.5,-2038.5 1171.5,-2038.5 1171.5,-1992.5 883.5,-1992.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2011.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-1992.5 1006.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2015.5 1061.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-1992.5 1061.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2023.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2015.5 1171.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2000.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 140511731782768&#45;&gt;140511731783160 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140511731782768-&gt;140511731783160</title>\n",
       "<path d=\"M1027.5,-2075.3799C1027.5,-2067.1745 1027.5,-2057.7679 1027.5,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2048.784 1027.5,-2038.784 1024.0001,-2048.784 1031.0001,-2048.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511731783272 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140511731783272</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1909.5 885.5,-1955.5 1169.5,-1955.5 1169.5,-1909.5 885.5,-1909.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1928.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1909.5 1010.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1932.5 1065.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1909.5 1065.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1940.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1932.5 1169.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1917.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 140511731783160&#45;&gt;140511731783272 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140511731783160-&gt;140511731783272</title>\n",
       "<path d=\"M1027.5,-1992.3799C1027.5,-1984.1745 1027.5,-1974.7679 1027.5,-1965.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1965.784 1027.5,-1955.784 1024.0001,-1965.784 1031.0001,-1965.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140517054025176 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140517054025176</title>\n",
       "<polygon fill=\"none\" points=\"886.5,-1826.5 886.5,-1872.5 1168.5,-1872.5 1168.5,-1826.5 886.5,-1826.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1845.8\">conv1d_2: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1826.5 1009.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1849.5 1064.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1826.5 1064.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1857.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1849.5 1168.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1834.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140511731783272&#45;&gt;140517054025176 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140511731783272-&gt;140517054025176</title>\n",
       "<path d=\"M1027.5,-1909.3799C1027.5,-1901.1745 1027.5,-1891.7679 1027.5,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1882.784 1027.5,-1872.784 1024.0001,-1882.784 1031.0001,-1882.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511699593816 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140511699593816</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1743.5 885.5,-1789.5 1169.5,-1789.5 1169.5,-1743.5 885.5,-1743.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1762.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1743.5 1010.5,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1766.5 1065.5,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1743.5 1065.5,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1774.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1766.5 1169.5,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1751.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140517054025176&#45;&gt;140511699593816 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140517054025176-&gt;140511699593816</title>\n",
       "<path d=\"M1027.5,-1826.3799C1027.5,-1818.1745 1027.5,-1808.7679 1027.5,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1799.784 1027.5,-1789.784 1024.0001,-1799.784 1031.0001,-1799.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511699331448 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140511699331448</title>\n",
       "<polygon fill=\"none\" points=\"818,-1660.5 818,-1706.5 1237,-1706.5 1237,-1660.5 818,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1679.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1660.5 1078,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1683.5 1133,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1660.5 1133,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1683.5 1237,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1668.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140511699593816&#45;&gt;140511699331448 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140511699593816-&gt;140511699331448</title>\n",
       "<path d=\"M1027.5,-1743.3799C1027.5,-1735.1745 1027.5,-1725.7679 1027.5,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1716.784 1027.5,-1706.784 1024.0001,-1716.784 1031.0001,-1716.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511699477336 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140511699477336</title>\n",
       "<polygon fill=\"none\" points=\"252.5,-1577.5 252.5,-1623.5 626.5,-1623.5 626.5,-1577.5 252.5,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-1596.8\">sa1: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1577.5 367.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1600.5 422.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1577.5 422.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1608.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1600.5 626.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1585.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511699331448&#45;&gt;140511699477336 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140511699331448-&gt;140511699477336</title>\n",
       "<path d=\"M864.4901,-1660.4901C786.1844,-1649.4367 692.2952,-1636.1837 612.7036,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"612.9631,-1621.4508 602.572,-1623.5187 611.9847,-1628.3821 612.9631,-1621.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511698629128 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140511698629128</title>\n",
       "<polygon fill=\"none\" points=\"644.5,-1577.5 644.5,-1623.5 1018.5,-1623.5 1018.5,-1577.5 644.5,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"702\" y=\"-1596.8\">sa2: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1577.5 759.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1600.5 814.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1577.5 814.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1608.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1600.5 1018.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1585.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511699331448&#45;&gt;140511698629128 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140511699331448-&gt;140511698629128</title>\n",
       "<path d=\"M973.1634,-1660.4901C949.0535,-1650.2803 920.5118,-1638.1938 895.3877,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"896.5156,-1624.2313 885.9423,-1623.5547 893.7859,-1630.6771 896.5156,-1624.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511697666120 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140511697666120</title>\n",
       "<polygon fill=\"none\" points=\"1036.5,-1577.5 1036.5,-1623.5 1410.5,-1623.5 1410.5,-1577.5 1036.5,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094\" y=\"-1596.8\">sa3: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1577.5 1151.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1600.5 1206.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1577.5 1206.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1608.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1600.5 1410.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1585.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511699331448&#45;&gt;140511697666120 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140511699331448-&gt;140511697666120</title>\n",
       "<path d=\"M1081.8366,-1660.4901C1105.9465,-1650.2803 1134.4882,-1638.1938 1159.6123,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1161.2141,-1630.6771 1169.0577,-1623.5547 1158.4844,-1624.2313 1161.2141,-1630.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511696809936 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140511696809936</title>\n",
       "<polygon fill=\"none\" points=\"1428.5,-1577.5 1428.5,-1623.5 1802.5,-1623.5 1802.5,-1577.5 1428.5,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1486\" y=\"-1596.8\">sa4: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1577.5 1543.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1600.5 1598.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1577.5 1598.5,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1608.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1600.5 1802.5,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1585.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511699331448&#45;&gt;140511696809936 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140511699331448-&gt;140511696809936</title>\n",
       "<path d=\"M1190.5099,-1660.4901C1268.8156,-1649.4367 1362.7048,-1636.1837 1442.2964,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1443.0153,-1628.3821 1452.428,-1623.5187 1442.0369,-1621.4508 1443.0153,-1628.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511696086408 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140511696086408</title>\n",
       "<polygon fill=\"none\" points=\"718,-1494.5 718,-1540.5 1337,-1540.5 1337,-1494.5 718,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-1513.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"886,-1494.5 886,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"886,-1517.5 941,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"941,-1494.5 941,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1525.3\">[(None, 500, 32), (None, 500, 32), (None, 500, 32), (None, 500, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"941,-1517.5 1337,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1502.3\">(None, 500, 128)</text>\n",
       "</g>\n",
       "<!-- 140511699477336&#45;&gt;140511696086408 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140511699477336-&gt;140511696086408</title>\n",
       "<path d=\"M602.5099,-1577.4901C680.8156,-1566.4367 774.7048,-1553.1837 854.2964,-1541.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"855.0153,-1545.3821 864.428,-1540.5187 854.0369,-1538.4508 855.0153,-1545.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511698629128&#45;&gt;140511696086408 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140511698629128-&gt;140511696086408</title>\n",
       "<path d=\"M885.8366,-1577.4901C909.9465,-1567.2803 938.4882,-1555.1938 963.6123,-1544.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"965.2141,-1547.6771 973.0577,-1540.5547 962.4844,-1541.2313 965.2141,-1547.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511697666120&#45;&gt;140511696086408 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140511697666120-&gt;140511696086408</title>\n",
       "<path d=\"M1169.1634,-1577.4901C1145.0535,-1567.2803 1116.5118,-1555.1938 1091.3877,-1544.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1092.5156,-1541.2313 1081.9423,-1540.5547 1089.7859,-1547.6771 1092.5156,-1541.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511696809936&#45;&gt;140511696086408 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140511696809936-&gt;140511696086408</title>\n",
       "<path d=\"M1452.4901,-1577.4901C1374.1844,-1566.4367 1280.2952,-1553.1837 1200.7036,-1541.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1200.9631,-1538.4508 1190.572,-1540.5187 1199.9847,-1545.3821 1200.9631,-1538.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511731783608 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140511731783608</title>\n",
       "<polygon fill=\"none\" points=\"357,-1494.5 357,-1540.5 700,-1540.5 700,-1494.5 357,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-1513.8\">input_headline_vector: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"562,-1494.5 562,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"562,-1517.5 617,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"617,-1494.5 617,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1525.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"617,-1517.5 700,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1502.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140511694851824 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140511694851824</title>\n",
       "<polygon fill=\"none\" points=\"439.5,-1411.5 439.5,-1457.5 679.5,-1457.5 679.5,-1411.5 439.5,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-1430.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1411.5 541.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1434.5 596.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1411.5 596.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1442.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1434.5 679.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1419.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140511731783608&#45;&gt;140511694851824 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>140511731783608-&gt;140511694851824</title>\n",
       "<path d=\"M537.1352,-1494.3799C540.2665,-1485.9962 543.8662,-1476.3584 547.2495,-1467.2996\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"550.5834,-1468.3766 550.8036,-1457.784 544.0259,-1465.9273 550.5834,-1468.3766\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511699191680 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140511699191680</title>\n",
       "<polygon fill=\"none\" points=\"881.5,-1411.5 881.5,-1457.5 1169.5,-1457.5 1169.5,-1411.5 881.5,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"943\" y=\"-1430.8\">conv1d_3: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1411.5 1004.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1434.5 1059.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1411.5 1059.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1442.3\">(None, 500, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1434.5 1169.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1419.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140511696086408&#45;&gt;140511699191680 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>140511696086408-&gt;140511699191680</title>\n",
       "<path d=\"M1026.9429,-1494.3799C1026.7452,-1486.1745 1026.5185,-1476.7679 1026.3043,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1029.801,-1467.6968 1026.0611,-1457.784 1022.8031,-1467.8655 1029.801,-1467.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694097936 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>140511694097936</title>\n",
       "<polygon fill=\"none\" points=\"437,-1328.5 437,-1374.5 712,-1374.5 712,-1328.5 437,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-1347.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"560,-1328.5 560,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"560,-1351.5 615,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"615,-1328.5 615,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1359.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"615,-1351.5 712,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1336.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140511694851824&#45;&gt;140511694097936 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>140511694851824-&gt;140511694097936</title>\n",
       "<path d=\"M563.6783,-1411.3799C565.1612,-1403.1745 566.8612,-1393.7679 568.4677,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"571.9578,-1385.2471 570.292,-1374.784 565.0693,-1384.0021 571.9578,-1385.2471\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694850928 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>140511694850928</title>\n",
       "<polygon fill=\"none\" points=\"876.5,-1328.5 876.5,-1374.5 1166.5,-1374.5 1166.5,-1328.5 876.5,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"939\" y=\"-1347.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1328.5 1001.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1351.5 1056.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1328.5 1056.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1359.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1351.5 1166.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1336.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140511699191680&#45;&gt;140511694850928 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>140511699191680-&gt;140511694850928</title>\n",
       "<path d=\"M1024.3858,-1411.3799C1023.9903,-1403.1745 1023.537,-1393.7679 1023.1086,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1026.5995,-1384.6039 1022.6221,-1374.784 1019.6076,-1384.9409 1026.5995,-1384.6039\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693927872 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>140511693927872</title>\n",
       "<polygon fill=\"none\" points=\"376.5,-1245.5 376.5,-1291.5 788.5,-1291.5 788.5,-1245.5 376.5,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-1264.8\">batch_normalization_3: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1245.5 636.5,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1268.5 691.5,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1245.5 691.5,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1276.3\">(None, 1, 256)</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1268.5 788.5,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1253.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140511694097936&#45;&gt;140511693927872 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>140511694097936-&gt;140511693927872</title>\n",
       "<path d=\"M576.7284,-1328.3799C577.5193,-1320.1745 578.426,-1310.7679 579.2828,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"582.7801,-1302.0737 580.2558,-1291.784 575.8124,-1301.4021 582.7801,-1302.0737\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694851040 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>140511694851040</title>\n",
       "<polygon fill=\"none\" points=\"807,-1245.5 807,-1291.5 1232,-1291.5 1232,-1245.5 807,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"937\" y=\"-1264.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1245.5 1067,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1268.5 1122,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1245.5 1122,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1276.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1268.5 1232,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1253.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140511694850928&#45;&gt;140511694851040 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>140511694850928-&gt;140511694851040</title>\n",
       "<path d=\"M1020.9429,-1328.3799C1020.7452,-1320.1745 1020.5185,-1310.7679 1020.3043,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1023.801,-1301.6968 1020.0611,-1291.784 1016.8031,-1301.8655 1023.801,-1301.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693558560 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>140511693558560</title>\n",
       "<polygon fill=\"none\" points=\"810,-1162.5 810,-1208.5 1197,-1208.5 1197,-1162.5 810,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872.5\" y=\"-1181.8\">ca1: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"935,-1162.5 935,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"935,-1185.5 990,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"990,-1162.5 990,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1193.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"990,-1185.5 1197,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1170.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511693927872&#45;&gt;140511693558560 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>140511693927872-&gt;140511693558560</title>\n",
       "<path d=\"M699.2129,-1245.4901C754.3078,-1234.6282 820.1773,-1221.642 876.519,-1210.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"877.4259,-1213.9229 886.5601,-1208.5547 876.0719,-1207.0551 877.4259,-1213.9229\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693511760 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>140511693511760</title>\n",
       "<polygon fill=\"none\" points=\"1215,-1162.5 1215,-1208.5 1602,-1208.5 1602,-1162.5 1215,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277.5\" y=\"-1181.8\">ca2: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1162.5 1340,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1185.5 1395,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1162.5 1395,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1193.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1185.5 1602,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1170.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511693927872&#45;&gt;140511693511760 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>140511693927872-&gt;140511693511760</title>\n",
       "<path d=\"M788.5682,-1245.986C791.9028,-1245.6525 795.2153,-1245.3236 798.5,-1245 976.3881,-1227.477 1023.7095,-1227.5124 1204.8542,-1209.1557\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1205.3964,-1212.6187 1214.9903,-1208.1236 1204.6872,-1205.6547 1205.3964,-1212.6187\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511691988888 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>140511691988888</title>\n",
       "<polygon fill=\"none\" points=\"0,-1162.5 0,-1208.5 387,-1208.5 387,-1162.5 0,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-1181.8\">ca3: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"125,-1162.5 125,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-1185.5 180,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-1162.5 180,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1193.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"180,-1185.5 387,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1170.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511693927872&#45;&gt;140511691988888 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>140511693927872-&gt;140511691988888</title>\n",
       "<path d=\"M474.6584,-1245.4901C423.962,-1234.6731 363.3923,-1221.7495 311.4764,-1210.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"312.0616,-1207.2185 301.5514,-1208.5547 310.6009,-1214.0644 312.0616,-1207.2185\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511691257168 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>140511691257168</title>\n",
       "<polygon fill=\"none\" points=\"405,-1162.5 405,-1208.5 792,-1208.5 792,-1162.5 405,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467.5\" y=\"-1181.8\">ca4: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"530,-1162.5 530,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"530,-1185.5 585,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"585,-1162.5 585,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1193.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"585,-1185.5 792,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1170.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140511693927872&#45;&gt;140511691257168 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>140511693927872-&gt;140511691257168</title>\n",
       "<path d=\"M586.9569,-1245.3799C588.5386,-1237.1745 590.352,-1227.7679 592.0656,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"595.5553,-1219.2658 594.0115,-1208.784 588.6818,-1217.9407 595.5553,-1219.2658\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694851040&#45;&gt;140511693558560 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>140511694851040-&gt;140511693558560</title>\n",
       "<path d=\"M1015.0431,-1245.3799C1013.4614,-1237.1745 1011.648,-1227.7679 1009.9344,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1013.3182,-1217.9407 1007.9885,-1208.784 1006.4447,-1219.2658 1013.3182,-1217.9407\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694851040&#45;&gt;140511693511760 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>140511694851040-&gt;140511693511760</title>\n",
       "<path d=\"M1127.3416,-1245.4901C1178.038,-1234.6731 1238.6077,-1221.7495 1290.5236,-1210.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1291.3991,-1214.0644 1300.4486,-1208.5547 1289.9384,-1207.2185 1291.3991,-1214.0644\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694851040&#45;&gt;140511691988888 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>140511694851040-&gt;140511691988888</title>\n",
       "<path d=\"M806.8249,-1245.9162C803.6957,-1245.6071 800.5859,-1245.3015 797.5,-1245 622.1938,-1227.873 575.6096,-1227.3786 397.0043,-1209.1432\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"397.3151,-1205.6568 387.0102,-1208.1184 396.601,-1212.6203 397.3151,-1205.6568\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511694851040&#45;&gt;140511691257168 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>140511694851040-&gt;140511691257168</title>\n",
       "<path d=\"M902.7871,-1245.4901C847.6922,-1234.6282 781.8227,-1221.642 725.481,-1210.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"725.9281,-1207.0551 715.4399,-1208.5547 724.5741,-1213.9229 725.9281,-1207.0551\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511690568200 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>140511690568200</title>\n",
       "<polygon fill=\"none\" points=\"477.5,-1079.5 477.5,-1125.5 1123.5,-1125.5 1123.5,-1079.5 477.5,-1079.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-1098.8\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1079.5 645.5,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1102.5 700.5,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1079.5 700.5,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1110.3\">[(None, 500, 256), (None, 500, 256), (None, 500, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1102.5 1123.5,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1087.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140511693558560&#45;&gt;140511690568200 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>140511693558560-&gt;140511690568200</title>\n",
       "<path d=\"M947.2228,-1162.4901C922.1419,-1152.2353 892.4302,-1140.0872 866.3257,-1129.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"867.4675,-1126.0996 856.8867,-1125.5547 864.8183,-1132.579 867.4675,-1126.0996\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693511760&#45;&gt;140511690568200 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>140511693511760-&gt;140511690568200</title>\n",
       "<path d=\"M1239.9455,-1162.4901C1158.8115,-1151.4142 1061.4981,-1138.1297 979.0922,-1126.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"979.5002,-1123.4035 969.1187,-1125.5187 978.5534,-1130.3392 979.5002,-1123.4035\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511691988888&#45;&gt;140511690568200 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>140511691988888-&gt;140511690568200</title>\n",
       "<path d=\"M361.7773,-1162.4901C442.7778,-1151.4142 539.9312,-1138.1297 622.2015,-1126.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"622.725,-1130.3413 632.1586,-1125.5187 621.7766,-1123.4058 622.725,-1130.3413\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511691257168&#45;&gt;140511690568200 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>140511691257168-&gt;140511690568200</title>\n",
       "<path d=\"M654.5,-1162.4901C679.4573,-1152.2353 709.0226,-1140.0872 734.9986,-1129.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"736.4717,-1132.5927 744.3911,-1125.5547 733.8112,-1126.1179 736.4717,-1132.5927\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693673752 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>140511693673752</title>\n",
       "<polygon fill=\"none\" points=\"652,-996.5 652,-1042.5 949,-1042.5 949,-996.5 652,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1015.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"777,-996.5 777,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"777,-1019.5 832,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-996.5 832,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1027.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"832,-1019.5 949,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1004.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140511690568200&#45;&gt;140511693673752 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>140511690568200-&gt;140511693673752</title>\n",
       "<path d=\"M800.5,-1079.3799C800.5,-1071.1745 800.5,-1061.7679 800.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1052.784 800.5,-1042.784 797.0001,-1052.784 804.0001,-1052.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693673248 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>140511693673248</title>\n",
       "<polygon fill=\"none\" points=\"584.5,-913.5 584.5,-959.5 1016.5,-959.5 1016.5,-913.5 584.5,-913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-932.8\">batch_normalization_4: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-913.5 844.5,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-936.5 899.5,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-913.5 899.5,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-944.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-936.5 1016.5,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-921.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140511693673752&#45;&gt;140511693673248 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>140511693673752-&gt;140511693673248</title>\n",
       "<path d=\"M800.5,-996.3799C800.5,-988.1745 800.5,-978.7679 800.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-969.784 800.5,-959.784 797.0001,-969.784 804.0001,-969.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511693672912 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>140511693672912</title>\n",
       "<polygon fill=\"none\" points=\"653,-830.5 653,-876.5 948,-876.5 948,-830.5 653,-830.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-849.8\">conv1d_4: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-830.5 776,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-853.5 831,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"831,-830.5 831,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-861.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"831,-853.5 948,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-838.3\">(None, 250, 256)</text>\n",
       "</g>\n",
       "<!-- 140511693673248&#45;&gt;140511693672912 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>140511693673248-&gt;140511693672912</title>\n",
       "<path d=\"M800.5,-913.3799C800.5,-905.1745 800.5,-895.7679 800.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-886.784 800.5,-876.784 797.0001,-886.784 804.0001,-886.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511688921040 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>140511688921040</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-747.5 656.5,-793.5 944.5,-793.5 944.5,-747.5 656.5,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-766.8\">conv1d_5: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-747.5 779.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-770.5 834.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-747.5 834.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-778.3\">(None, 250, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-770.5 944.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-755.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 140511693672912&#45;&gt;140511688921040 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>140511693672912-&gt;140511688921040</title>\n",
       "<path d=\"M800.5,-830.3799C800.5,-822.1745 800.5,-812.7679 800.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-803.784 800.5,-793.784 797.0001,-803.784 804.0001,-803.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511688670736 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>140511688670736</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-664.5 656.5,-710.5 944.5,-710.5 944.5,-664.5 656.5,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-683.8\">conv1d_6: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-664.5 779.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-687.5 834.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-664.5 834.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-695.3\">(None, 125, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-687.5 944.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-672.3\">(None, 63, 256)</text>\n",
       "</g>\n",
       "<!-- 140511688921040&#45;&gt;140511688670736 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>140511688921040-&gt;140511688670736</title>\n",
       "<path d=\"M800.5,-747.3799C800.5,-739.1745 800.5,-729.7679 800.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-720.784 800.5,-710.784 797.0001,-720.784 804.0001,-720.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511687662224 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>140511687662224</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-581.5 659.5,-627.5 941.5,-627.5 941.5,-581.5 659.5,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-600.8\">conv1d_7: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-581.5 782.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-604.5 837.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-581.5 837.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-612.3\">(None, 63, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-604.5 941.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-589.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140511688670736&#45;&gt;140511687662224 -->\n",
       "<g class=\"edge\" id=\"edge37\">\n",
       "<title>140511688670736-&gt;140511687662224</title>\n",
       "<path d=\"M800.5,-664.3799C800.5,-656.1745 800.5,-646.7679 800.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-637.784 800.5,-627.784 797.0001,-637.784 804.0001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511687788976 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>140511687788976</title>\n",
       "<polygon fill=\"none\" points=\"658.5,-498.5 658.5,-544.5 942.5,-544.5 942.5,-498.5 658.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-517.8\">dropout_5: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-498.5 783.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-521.5 838.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-498.5 838.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-529.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-521.5 942.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-506.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140511687662224&#45;&gt;140511687788976 -->\n",
       "<g class=\"edge\" id=\"edge38\">\n",
       "<title>140511687662224-&gt;140511687788976</title>\n",
       "<path d=\"M800.5,-581.3799C800.5,-573.1745 800.5,-563.7679 800.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-554.784 800.5,-544.784 797.0001,-554.784 804.0001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511687338416 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>140511687338416</title>\n",
       "<polygon fill=\"none\" points=\"591,-415.5 591,-461.5 1010,-461.5 1010,-415.5 591,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-434.8\">batch_normalization_5: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"851,-415.5 851,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"851,-438.5 906,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"906,-415.5 906,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-446.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"906,-438.5 1010,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-423.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140511687788976&#45;&gt;140511687338416 -->\n",
       "<g class=\"edge\" id=\"edge39\">\n",
       "<title>140511687788976-&gt;140511687338416</title>\n",
       "<path d=\"M800.5,-498.3799C800.5,-490.1745 800.5,-480.7679 800.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-471.784 800.5,-461.784 797.0001,-471.784 804.0001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511687790208 -->\n",
       "<g class=\"node\" id=\"node32\">\n",
       "<title>140511687790208</title>\n",
       "<polygon fill=\"none\" points=\"559.5,-332.5 559.5,-378.5 1041.5,-378.5 1041.5,-332.5 559.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-351.8\">global_average_pooling1d_1: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-332.5 882.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-355.5 937.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-332.5 937.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-363.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-355.5 1041.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-340.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140511687338416&#45;&gt;140511687790208 -->\n",
       "<g class=\"edge\" id=\"edge40\">\n",
       "<title>140511687338416-&gt;140511687790208</title>\n",
       "<path d=\"M800.5,-415.3799C800.5,-407.1745 800.5,-397.7679 800.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-388.784 800.5,-378.784 797.0001,-388.784 804.0001,-388.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511687471904 -->\n",
       "<g class=\"node\" id=\"node33\">\n",
       "<title>140511687471904</title>\n",
       "<polygon fill=\"none\" points=\"680.5,-249.5 680.5,-295.5 920.5,-295.5 920.5,-249.5 680.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-268.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-249.5 782.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-272.5 837.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-249.5 837.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879\" y=\"-280.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-272.5 920.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140511687790208&#45;&gt;140511687471904 -->\n",
       "<g class=\"edge\" id=\"edge41\">\n",
       "<title>140511687790208-&gt;140511687471904</title>\n",
       "<path d=\"M800.5,-332.3799C800.5,-324.1745 800.5,-314.7679 800.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-305.784 800.5,-295.784 797.0001,-305.784 804.0001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511686546824 -->\n",
       "<g class=\"node\" id=\"node34\">\n",
       "<title>140511686546824</title>\n",
       "<polygon fill=\"none\" points=\"669,-166.5 669,-212.5 932,-212.5 932,-166.5 669,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-185.8\">dropout_6: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"794,-166.5 794,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"821.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"794,-189.5 849,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"821.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"849,-166.5 849,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"849,-189.5 932,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140511687471904&#45;&gt;140511686546824 -->\n",
       "<g class=\"edge\" id=\"edge42\">\n",
       "<title>140511687471904-&gt;140511686546824</title>\n",
       "<path d=\"M800.5,-249.3799C800.5,-241.1745 800.5,-231.7679 800.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-222.784 800.5,-212.784 797.0001,-222.784 804.0001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511686545928 -->\n",
       "<g class=\"node\" id=\"node35\">\n",
       "<title>140511686545928</title>\n",
       "<polygon fill=\"none\" points=\"601.5,-83.5 601.5,-129.5 999.5,-129.5 999.5,-83.5 601.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-102.8\">batch_normalization_6: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"861.5,-83.5 861.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"861.5,-106.5 916.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-83.5 916.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-106.5 999.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140511686546824&#45;&gt;140511686545928 -->\n",
       "<g class=\"edge\" id=\"edge43\">\n",
       "<title>140511686546824-&gt;140511686545928</title>\n",
       "<path d=\"M800.5,-166.3799C800.5,-158.1745 800.5,-148.7679 800.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-139.784 800.5,-129.784 797.0001,-139.784 804.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140511686258816 -->\n",
       "<g class=\"node\" id=\"node36\">\n",
       "<title>140511686258816</title>\n",
       "<polygon fill=\"none\" points=\"639,-.5 639,-46.5 962,-46.5 962,-.5 639,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-19.8\">output_headline_vector: Dense</text>\n",
       "<polyline fill=\"none\" points=\"824,-.5 824,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"851.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"824,-23.5 879,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"851.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"879,-.5 879,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"920.5\" y=\"-31.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"879,-23.5 962,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"920.5\" y=\"-8.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140511686545928&#45;&gt;140511686258816 -->\n",
       "<g class=\"edge\" id=\"edge44\">\n",
       "<title>140511686545928-&gt;140511686258816</title>\n",
       "<path d=\"M800.5,-83.3799C800.5,-75.1745 800.5,-65.7679 800.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-56.784 800.5,-46.784 797.0001,-56.784 804.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    inp_sentence_vectors = Input(shape=(max_sentences, 300), name='sentence_vectors')\n",
    "    inp_headline_vector = Input(shape=(300,), name='input_headline_vector')\n",
    "    conv1 = Conv1D(filters=16,kernel_size=3,strides=1,activation='relu', padding='same')(inp_sentence_vectors)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv2 = Conv1D(filters=32,kernel_size=3,strides=1,activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    sent_sa_feat_1, sent_beta_1, sent_gamma_1 = SelfAttention(int(conv2.shape[-1]), name = 'sa1')(conv2)\n",
    "    sent_sa_feat_2, sent_beta_2, sent_gamma_2 = SelfAttention(int(conv2.shape[-1]), name = 'sa2')(conv2)\n",
    "    sent_sa_feat_3, sent_beta_3, sent_gamma_3 = SelfAttention(int(conv2.shape[-1]), name = 'sa3')(conv2)\n",
    "    sent_sa_feat_4, sent_beta_4, sent_gamma_4 = SelfAttention(int(conv2.shape[-1]), name = 'sa4')(conv2)\n",
    "    concat1 = Concatenate()([sent_sa_feat_1,sent_sa_feat_2,sent_sa_feat_3,sent_sa_feat_4])\n",
    "    conv3 = Conv1D(filters=256,kernel_size=3, strides=1, activation='relu', padding='same')(concat1)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    headline = Dense(256, activation='relu')(inp_headline_vector)\n",
    "    headline = Lambda(lambda x:K.expand_dims(x, axis=1))(headline)\n",
    "    headline = BatchNormalization()(headline)\n",
    "    sent_hd_sa_feat_1, sent_hd_beta_1, sent_hd_gamma_1 = CrossAttention(int(conv3.shape[-1]), name = 'ca1')([headline,conv3])\n",
    "    sent_hd_sa_feat_2, sent_hd_beta_2, sent_hd_gamma_2 = CrossAttention(int(conv3.shape[-1]), name = 'ca2')([headline,conv3])\n",
    "    sent_hd_sa_feat_3, sent_hd_beta_3, sent_hd_gamma_3 = CrossAttention(int(conv3.shape[-1]), name = 'ca3')([headline,conv3])\n",
    "    sent_hd_sa_feat_4, sent_hd_beta_4, sent_hd_gamma_4 = CrossAttention(int(conv3.shape[-1]), name = 'ca4')([headline,conv3])  \n",
    "    concat3 = Concatenate()([sent_hd_sa_feat_1,sent_hd_sa_feat_2,sent_hd_sa_feat_3,sent_hd_sa_feat_4])\n",
    "    concat3 = Dropout(0.5)(concat3)\n",
    "    concat3 = BatchNormalization()(concat3)\n",
    "    conv5 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(concat3)\n",
    "    conv6 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv5)\n",
    "    conv7 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv6)\n",
    "    conv8 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv7)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    gap = GlobalAveragePooling1D()(conv8)\n",
    "#     repeat = RepeatVector(50)(gap)\n",
    "#     lstm = LSTM(256,return_sequences=True)(repeat)\n",
    "    dense1 = Dense(512,activation='relu')(gap)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    gen_hd_vector = Dense(300,activation='linear', name='output_headline_vector')(dense1)\n",
    "    model = Model([inp_sentence_vectors,inp_headline_vector],gen_hd_vector)\n",
    "    return model\n",
    "model = build_model()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001,beta_1=0.0,beta_2=0.99),loss='mse')\n",
    "model.summary()\n",
    "# print('model params:',model.count_params())\n",
    "SVG(model_to_dot(model,show_layer_names=True,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now()\n",
    "mc = ModelCheckpoint('weights/dnf300_sa_sent_hd_vector_gl.hdf5',save_best_only=True,save_weights_only=True)\n",
    "tb = TensorBoard(batch_size=32,log_dir='logs/dnf300_sa_sent_hd_vector_gl/{0}'.format(dt.timestamp()),write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.1858 - val_loss: 0.4229\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 1.1558 - val_loss: 0.3670\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 1.1311 - val_loss: 0.3372\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 1.1232 - val_loss: 0.3229\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.1230 - val_loss: 0.2967\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.1249 - val_loss: 0.2740\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.1159 - val_loss: 0.2751\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0970 - val_loss: 0.2692\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0911 - val_loss: 0.2675\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0976 - val_loss: 0.2602\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.0920 - val_loss: 0.2474\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0692 - val_loss: 0.2422\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0709 - val_loss: 0.2299\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0545 - val_loss: 0.2206\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0576 - val_loss: 0.2005\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0381 - val_loss: 0.1870\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0207 - val_loss: 0.1801\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0182 - val_loss: 0.1705\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0227 - val_loss: 0.1640\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0007 - val_loss: 0.1647\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9886 - val_loss: 0.1602\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0092 - val_loss: 0.1580\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9723 - val_loss: 0.1471\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9789 - val_loss: 0.1469\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9592 - val_loss: 0.1436\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9487 - val_loss: 0.1385\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9523 - val_loss: 0.1380\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9509 - val_loss: 0.1289\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9399 - val_loss: 0.1266\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9253 - val_loss: 0.1314\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 0.9174 - val_loss: 0.1226\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9235 - val_loss: 0.1097\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9042 - val_loss: 0.1191\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8888 - val_loss: 0.1121\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8928 - val_loss: 0.1077\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8788 - val_loss: 0.1129\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8874 - val_loss: 0.1064\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.8732 - val_loss: 0.1002\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8521 - val_loss: 0.0914\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8634 - val_loss: 0.1060\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8639 - val_loss: 0.0916\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8504 - val_loss: 0.0899\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8252 - val_loss: 0.0858\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8175 - val_loss: 0.0952\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.8252 - val_loss: 0.0861\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8070 - val_loss: 0.0848\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7979 - val_loss: 0.0831\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7872 - val_loss: 0.0869\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7810 - val_loss: 0.0812\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7811 - val_loss: 0.0758\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7901 - val_loss: 0.0756\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7678 - val_loss: 0.0746\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7784 - val_loss: 0.0708\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7681 - val_loss: 0.0691\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7517 - val_loss: 0.0644\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 4s 975ms/step - loss: 0.7472 - val_loss: 0.0649\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7428 - val_loss: 0.0696\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7462 - val_loss: 0.0672\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7387 - val_loss: 0.0612\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7187 - val_loss: 0.0647\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7260 - val_loss: 0.0635\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7099 - val_loss: 0.0613\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7011 - val_loss: 0.0617\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7105 - val_loss: 0.0580\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7046 - val_loss: 0.0603\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6764 - val_loss: 0.0625\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6868 - val_loss: 0.0564\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6697 - val_loss: 0.0562\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6649 - val_loss: 0.0616\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6660 - val_loss: 0.0564\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6593 - val_loss: 0.0511\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6453 - val_loss: 0.0512\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6325 - val_loss: 0.0591\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6217 - val_loss: 0.0517\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6392 - val_loss: 0.0529\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6264 - val_loss: 0.0534\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6218 - val_loss: 0.0460\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6283 - val_loss: 0.0479\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6101 - val_loss: 0.0535\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6022 - val_loss: 0.0517\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5985 - val_loss: 0.0474\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5840 - val_loss: 0.0457\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5630 - val_loss: 0.0501\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5690 - val_loss: 0.0528\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5501 - val_loss: 0.0496\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5445 - val_loss: 0.0491\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.5430 - val_loss: 0.0472\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5322 - val_loss: 0.0476\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5266 - val_loss: 0.0484\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.5281 - val_loss: 0.0439\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5046 - val_loss: 0.0417\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5093 - val_loss: 0.0476\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4975 - val_loss: 0.0486\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4743 - val_loss: 0.0417\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4743 - val_loss: 0.0420\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4516 - val_loss: 0.0439\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.4386 - val_loss: 0.0446\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.4586 - val_loss: 0.0449\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.4259 - val_loss: 0.0449\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.4292 - val_loss: 0.0447\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.4247 - val_loss: 0.0384\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.4187 - val_loss: 0.0423\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.4121 - val_loss: 0.0412\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.3839 - val_loss: 0.0420\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.3836 - val_loss: 0.0409\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3796 - val_loss: 0.0374\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3725 - val_loss: 0.0396\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3652 - val_loss: 0.0398\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3733 - val_loss: 0.0384\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3562 - val_loss: 0.0365\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.3432 - val_loss: 0.0389\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3375 - val_loss: 0.0399\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3281 - val_loss: 0.0351\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.3227 - val_loss: 0.0378\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.3204 - val_loss: 0.0367\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2855 - val_loss: 0.0362\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.2837 - val_loss: 0.0347\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2741 - val_loss: 0.0359\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2845 - val_loss: 0.0354\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.2693 - val_loss: 0.0318\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.2599 - val_loss: 0.0318\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2499 - val_loss: 0.0344\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.2450 - val_loss: 0.0332\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2370 - val_loss: 0.0331\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.2293 - val_loss: 0.0322\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2333 - val_loss: 0.0308\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2196 - val_loss: 0.0301\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.2276 - val_loss: 0.0292\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.2038 - val_loss: 0.0304\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.2031 - val_loss: 0.0277\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.2127 - val_loss: 0.0274\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1791 - val_loss: 0.0266\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1966 - val_loss: 0.0282\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1842 - val_loss: 0.0260\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1758 - val_loss: 0.0280\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1937 - val_loss: 0.0277\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1773 - val_loss: 0.0248\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.1708 - val_loss: 0.0246\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.1653 - val_loss: 0.0243\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1676 - val_loss: 0.0234\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1594 - val_loss: 0.0249\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1550 - val_loss: 0.0238\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1482 - val_loss: 0.0237\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1662 - val_loss: 0.0244\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1548 - val_loss: 0.0218\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1421 - val_loss: 0.0209\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1589 - val_loss: 0.0220\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1405 - val_loss: 0.0219\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1474 - val_loss: 0.0203\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1484 - val_loss: 0.0214\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1319 - val_loss: 0.0237\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1407 - val_loss: 0.0193\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1361 - val_loss: 0.0200\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1324 - val_loss: 0.0205\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1384 - val_loss: 0.0208\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1234 - val_loss: 0.0194\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1265 - val_loss: 0.0189\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1177 - val_loss: 0.0176\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1191 - val_loss: 0.0178\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1193 - val_loss: 0.0167\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1109 - val_loss: 0.0184\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1173 - val_loss: 0.0174\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1075 - val_loss: 0.0181\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.1150 - val_loss: 0.0185\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.1044 - val_loss: 0.0170\n",
      "Epoch 166/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 11s 3s/step - loss: 0.1055 - val_loss: 0.0172\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1100 - val_loss: 0.0158\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1024 - val_loss: 0.0172\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0936 - val_loss: 0.0147\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.1029 - val_loss: 0.0160\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0978 - val_loss: 0.0164\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0970 - val_loss: 0.0150\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0951 - val_loss: 0.0144\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0914 - val_loss: 0.0158\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0930 - val_loss: 0.0159\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0935 - val_loss: 0.0167\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.1041 - val_loss: 0.0149\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0919 - val_loss: 0.0131\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0902 - val_loss: 0.0130\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0880 - val_loss: 0.0132\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0851 - val_loss: 0.0155\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0813 - val_loss: 0.0139\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0832 - val_loss: 0.0134\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0794 - val_loss: 0.0131\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0907 - val_loss: 0.0117\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0836 - val_loss: 0.0165\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0789 - val_loss: 0.0129\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0758 - val_loss: 0.0139\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0701 - val_loss: 0.0115\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0740 - val_loss: 0.0117\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0764 - val_loss: 0.0114\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0753 - val_loss: 0.0106\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0793 - val_loss: 0.0141\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0771 - val_loss: 0.0130\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0715 - val_loss: 0.0124\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0757 - val_loss: 0.0114\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0676 - val_loss: 0.0113\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0679 - val_loss: 0.0107\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0698 - val_loss: 0.0122\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0682 - val_loss: 0.0124\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0748 - val_loss: 0.0116\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0726 - val_loss: 0.0125\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0695 - val_loss: 0.0116\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0642 - val_loss: 0.0136\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0668 - val_loss: 0.0111\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0669 - val_loss: 0.0109\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0767 - val_loss: 0.0124\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.0705 - val_loss: 0.0115\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0626 - val_loss: 0.0107\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0661 - val_loss: 0.0115\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0648 - val_loss: 0.0123\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0616 - val_loss: 0.0111\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0605 - val_loss: 0.0110\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0597 - val_loss: 0.0116\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.0586 - val_loss: 0.0117\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0580 - val_loss: 0.0107\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0543 - val_loss: 0.0109\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0630 - val_loss: 0.0109\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0587 - val_loss: 0.0116\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0636 - val_loss: 0.0105\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0604 - val_loss: 0.0108\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0576 - val_loss: 0.0098\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0608 - val_loss: 0.0107\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0613 - val_loss: 0.0119\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0577 - val_loss: 0.0097\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0546 - val_loss: 0.0110\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0616 - val_loss: 0.0108\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0586 - val_loss: 0.0112\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0561 - val_loss: 0.0132\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0537 - val_loss: 0.0121\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0531 - val_loss: 0.0118\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0498 - val_loss: 0.0107\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0516 - val_loss: 0.0107\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0518 - val_loss: 0.0130\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0533 - val_loss: 0.0103\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0493 - val_loss: 0.0103\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0486 - val_loss: 0.0124\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0502 - val_loss: 0.0105\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0495 - val_loss: 0.0109\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0524 - val_loss: 0.0109\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0477 - val_loss: 0.0102\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0513 - val_loss: 0.0103\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0439 - val_loss: 0.0100\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0496 - val_loss: 0.0098\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0498 - val_loss: 0.0135\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0480 - val_loss: 0.0102\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0470 - val_loss: 0.0097\n",
      "Epoch 248/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0441 - val_loss: 0.0106\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0482 - val_loss: 0.0104\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0462 - val_loss: 0.0112\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0478 - val_loss: 0.0112\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0457 - val_loss: 0.0115\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0469 - val_loss: 0.0090\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0454 - val_loss: 0.0108\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0463 - val_loss: 0.0101\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0452 - val_loss: 0.0117\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0436 - val_loss: 0.0097\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0498 - val_loss: 0.0110\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0453 - val_loss: 0.0105\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0415 - val_loss: 0.0108\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0414 - val_loss: 0.0114\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0422 - val_loss: 0.0112\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0407 - val_loss: 0.0095\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0465 - val_loss: 0.0121\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0431 - val_loss: 0.0121\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0396 - val_loss: 0.0098\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0415 - val_loss: 0.0092\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0416 - val_loss: 0.0103\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0414 - val_loss: 0.0109\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0426 - val_loss: 0.0105\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0429 - val_loss: 0.0120\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0399 - val_loss: 0.0112\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0402 - val_loss: 0.0107\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0400 - val_loss: 0.0123\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0413 - val_loss: 0.0096\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0410 - val_loss: 0.0117\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0387 - val_loss: 0.0114\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0346 - val_loss: 0.0102\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0325 - val_loss: 0.0130\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0345 - val_loss: 0.0102\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0365 - val_loss: 0.0117\n",
      "Epoch 282/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0398 - val_loss: 0.0097\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0375 - val_loss: 0.0120\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0359 - val_loss: 0.0106\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0356 - val_loss: 0.0117\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0361 - val_loss: 0.0126\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0376 - val_loss: 0.0117\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0391 - val_loss: 0.0125\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0369 - val_loss: 0.0125\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0339 - val_loss: 0.0095\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0344 - val_loss: 0.0130\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0379 - val_loss: 0.0102\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0327 - val_loss: 0.0116\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0354 - val_loss: 0.0099\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0339 - val_loss: 0.0093\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0337 - val_loss: 0.0110\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0342 - val_loss: 0.0101\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0334 - val_loss: 0.0115\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0346 - val_loss: 0.0122\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0308 - val_loss: 0.0095\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0336 - val_loss: 0.0109\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0319 - val_loss: 0.0099\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0337 - val_loss: 0.0119\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0290 - val_loss: 0.0113\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0321 - val_loss: 0.0106\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0283 - val_loss: 0.0107\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0314 - val_loss: 0.0101\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0290 - val_loss: 0.0120\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0313 - val_loss: 0.0123\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0275 - val_loss: 0.0100\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0317 - val_loss: 0.0101\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0294 - val_loss: 0.0112\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0286 - val_loss: 0.0112\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0309 - val_loss: 0.0097\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0276 - val_loss: 0.0108\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0297 - val_loss: 0.0092\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0283 - val_loss: 0.0107\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0297 - val_loss: 0.0117\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0280 - val_loss: 0.0096\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0290 - val_loss: 0.0112\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0293 - val_loss: 0.0088\n",
      "Epoch 322/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0274 - val_loss: 0.0106\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0236 - val_loss: 0.0107\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0251 - val_loss: 0.0109\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0277 - val_loss: 0.0105\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0293 - val_loss: 0.0103\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0240 - val_loss: 0.0091\n",
      "Epoch 330/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 0.0242 - val_loss: 0.0103\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0267 - val_loss: 0.0113\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0211 - val_loss: 0.0092\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0260 - val_loss: 0.0128\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0241 - val_loss: 0.0105\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0221 - val_loss: 0.0125\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0236 - val_loss: 0.0090\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0229 - val_loss: 0.0123\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0231 - val_loss: 0.0109\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0219 - val_loss: 0.0104\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0233 - val_loss: 0.0097\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0215 - val_loss: 0.0092\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0204 - val_loss: 0.0111\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0207 - val_loss: 0.0114\n",
      "Epoch 344/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0207 - val_loss: 0.0106\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0208 - val_loss: 0.0111\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0187 - val_loss: 0.0114\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0212 - val_loss: 0.0097\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0195 - val_loss: 0.0099\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0196 - val_loss: 0.0102\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0181 - val_loss: 0.0120\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0161 - val_loss: 0.0106\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0182 - val_loss: 0.0106\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0176 - val_loss: 0.0092\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0174 - val_loss: 0.0097\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0173 - val_loss: 0.0114\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0157 - val_loss: 0.0092\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0162 - val_loss: 0.0121\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0162 - val_loss: 0.0097\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0171 - val_loss: 0.0106\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0130 - val_loss: 0.0094\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0122 - val_loss: 0.0112\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 406/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 412/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0183\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0114 - val_loss: 0.0153\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 468/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 482/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 494/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0305\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.1046\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0344\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0094 - val_loss: 0.0167\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0165\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0153\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 530/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0140\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0145\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0152\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 576/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.2603\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0119 - val_loss: 0.0812\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0305\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0145\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 592/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 642/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 654/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 658/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0429\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0174\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0411\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0146\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0088\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 716/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 740/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 778/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 802/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 822/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 3s/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 840/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 902/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0124\n",
      "Epoch 904/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0129\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 962/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 964/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0145\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 986/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 1026/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1042/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0087\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0124\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 1088/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0088\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 1148/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 3s/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 1150/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0135\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1200/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0095 - val_loss: 0.0112\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 1212/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0091\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0345\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.1171\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0241\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.1823\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0591\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0431\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0234\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0166\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0606\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0098 - val_loss: 0.0165\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 1.6425\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0110 - val_loss: 0.2392\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0668\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0279\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0178\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 1274/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0852\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0222\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0278\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 1310/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1336/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0116 - val_loss: 0.2781\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0265\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 1358/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 1398/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0124\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 1460/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 1472/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.4837\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0426\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0178\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1516/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 1522/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 4.3177\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 1.0063\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0977\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0442\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0207\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 1584/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 1634/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 3s/step - loss: 0.0113 - val_loss: 0.0128\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 1646/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 1674/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0123\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 1708/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0159\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0121 - val_loss: 1.1077\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0110 - val_loss: 0.0628\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1770/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1796/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 1832/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0108 - val_loss: 0.1011\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0101 - val_loss: 0.0284\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0150\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0100 - val_loss: 0.0948\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0269\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0158\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0125\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0126 - val_loss: 0.0127\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 1894/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0096 - val_loss: 0.0126\n",
      "Epoch 1911/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0096 - val_loss: 0.0108\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0097 - val_loss: 0.0113\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1956/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1958/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 1989/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 1990/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.0099 - val_loss: 0.0097\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(tdg, callbacks=[mc,tb], initial_epoch=0\n",
    "                           ,steps_per_epoch=train_steps_per_epoch\n",
    "                           ,validation_data=vdg\n",
    "                           ,validation_steps=val_steps_per_epoch\n",
    "                           ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# acc = hist.history['acc']\n",
    "# loss = hist.history['loss']\n",
    "\n",
    "# # Create count of the number of epochs\n",
    "# epoch_count = range(1, len(acc) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# # plt.plot(epoch_count, acc, 'b-')\n",
    "# fig, ax = plt.subplots(ncols=2,sharex=True)\n",
    "# ax[0].plot(epoch_count, loss, 'r--')\n",
    "# ax[0].legend(['Loss'])\n",
    "# ax[0].set_xlabel('Epoch')\n",
    "# ax[0].set_ylabel('Loss')\n",
    "# ax[1].plot(epoch_count, acc, 'b-')\n",
    "# ax[1].legend(['Accuracy'])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_xlabel('Accuracy')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.DataFrame(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['acc','val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `evaluate_generator` call to the Keras 2 API: `evaluate_generator(<generator..., use_multiprocessing=True, steps=5)`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01102324966341257"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('weights/dnf300_sa_sent_hd_vector_gl.hdf5')\n",
    "model.evaluate_generator(test_dg,steps=5,pickle_safe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_dg)\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_idx = np.random.randint(50)\n",
    "# test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 29 : lol! british wife of lib actor who said: there will never be a president donald trumpwarns americans about president-elect trump [video]\n",
      "1 : 15 : hillary clinton's 'sudden move' of $1.8 billion to qatar central bank stuns financial world\n",
      "2 : 12 : jill stein endorsed donald trump\n",
      "3 : 91 : us officials see no link between trump and russia\n",
      "4 : 27 : trump accuses obama, hillary clinton of founding daesh\n",
      "5 : 5 : hillary clinton wore 'secret earpiece' during commander-in-chief forum\n",
      "6 : 39 : doj's loretta lynch tried to squash comey's letter to congress\n",
      "7 : 94 : assange confirms: wikileaks didnt get emails from russian govt\n",
      "8 : 18 : clinton camp demands 'compliant citizenry' for master plan\n",
      "9 : 10 : physician confirms hillary clinton has parkinson's disease\n",
      "10 : 10 : physician confirms hillary clinton has parkinson's disease\n",
      "11 : 28 : hes never sold an original painting until nowand this ones going in the white house\n",
      "12 : 7 : hillary clinton used hand signals to rig debate?\n",
      "13 : 33 : kremlin: putin congratulates trump, hopes to work together major issues\n",
      "14 : 91 : us officials see no link between trump and russia\n",
      "15 : 3 : breaking: fraudulent clinton votes discovered by the tens of thousands\n",
      "16 : 29 : lol! british wife of lib actor who said: there will never be a president donald trumpwarns americans about president-elect trump [video]\n",
      "17 : 100 : hillary friend bribed fbi agent and his wife\n",
      "18 : 15 : hillary clinton's 'sudden move' of $1.8 billion to qatar central bank stuns financial world\n",
      "19 : 28 : hes never sold an original painting until nowand this ones going in the white house\n",
      "20 : 94 : assange confirms: wikileaks didnt get emails from russian govt\n",
      "21 : 16 : george soros: trump will win popular vote by a landslide but clinton victory a 'done deal'\n",
      "22 : 38 : hillarys (islamic) america is already here where muslim no-go zones are popping up all over michiganistan\n",
      "23 : 93 : former nato chief: we need us as worlds policeman\n",
      "24 : 5 : hillary clinton wore 'secret earpiece' during commander-in-chief forum\n",
      "25 : 21 : isis leader calls for american muslim voters to support hillary clinton\n",
      "26 : 3 : breaking: fraudulent clinton votes discovered by the tens of thousands\n",
      "27 : 29 : lol! british wife of lib actor who said: there will never be a president donald trumpwarns americans about president-elect trump [video]\n",
      "28 : 25 : erdoan: us, the founder of isis\n",
      "29 : 33 : kremlin: putin congratulates trump, hopes to work together major issues\n",
      "30 : 16 : george soros: trump will win popular vote by a landslide but clinton victory a 'done deal'\n",
      "31 : 38 : hillarys (islamic) america is already here where muslim no-go zones are popping up all over michiganistan\n",
      "32 : 6 : clinton received debate questions week before debate\n",
      "33 : 19 : leaked 2013 trump tax return shows he paid over 40 million in taxes\n",
      "34 : 19 : leaked 2013 trump tax return shows he paid over 40 million in taxes\n",
      "35 : 39 : doj's loretta lynch tried to squash comey's letter to congress\n",
      "36 : 93 : former nato chief: we need us as worlds policeman\n",
      "37 : 12 : jill stein endorsed donald trump\n",
      "38 : 7 : hillary clinton used hand signals to rig debate?\n",
      "39 : 0 : wikileaks confirms hillary sold weapons to isis... then drops another bombshell! breaking news\n",
      "40 : 38 : hillarys (islamic) america is already here where muslim no-go zones are popping up all over michiganistan\n",
      "41 : 17 : ted cruz said 'if something happens to hillary' he'll 'run as a democrat against trump'\n",
      "42 : 7 : hillary clinton used hand signals to rig debate?\n",
      "43 : 31 : fbi director comeys leaked memo explains why hes reopening the clinton email case\n",
      "44 : 1 : hillary clinton wore secret earpiece during first presidential debate?\n",
      "45 : 93 : former nato chief: we need us as worlds policeman\n",
      "46 : 0 : wikileaks confirms hillary sold weapons to isis... then drops another bombshell! breaking news\n",
      "47 : 98 : top aide: hillary still not perfect in her head, wikileaks\n",
      "48 : 36 : hillary clintons sudden move of $1.8 billion to qatar central bank stuns financial world\n",
      "49 : 94 : assange confirms: wikileaks didnt get emails from russian govt\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x['headline'])):\n",
    "    \n",
    "    print(i,\":\",x['article_id'][i],':',x['headline'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a new interview with Britains Sky News, former NATO Secretary-General Anders Fogh Rasmussen brought out the old narrative of America as the worlds policeman, but with a lot more upbeat of an attitude about it than one would generally see.',\n",
       " 'Rasmussen criticized President Obama for not being hawkish enough, saying his successor needs to be much more interventionist, and declaring  we need America as the worlds policeman,  adding that the US needs to restore international law and order through wars.',\n",
       " 'Rasmussen, who was always a relative hawk in the post but seems to have taken it to an entirely new level, set out a series of things the US needs to fix militarily, including Iraq, Syria, Libya, Russia, China, and North Korea.',\n",
       " 'This of course closely mirrors recent Pentagon talk of wars in the decades to come.',\n",
       " 'The timing of his calls for extreme US bellicosity are centered on trying to influence the upcoming US election in favor of Democratic nominee Hillary Clinton, who has campaigned heavily on picking fights in Syria and against Russia.',\n",
       " 'Rasmussen underscored this fact by declaring Donald Trump, who openly said the US cannot be the worlds police, as very dangerous for the world.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 36\n",
    "x['sentences'][test_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(model.inputs,model.get_layer(name='ca1').output)\n",
    "model_2 = Model(model.inputs,model.get_layer(name='ca2').output)\n",
    "model_3 = Model(model.inputs,model.get_layer(name='ca3').output)\n",
    "model_4 = Model(model.inputs,model.get_layer(name='ca4').output)\n",
    "model_1.summary()\n",
    "model_2.summary()\n",
    "model_3.summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, b1, g1 = model_1.predict(x)\n",
    "_, b2, g2 = model_2.predict(x)\n",
    "_, b3, g3 = model_3.predict(x)\n",
    "_, b4, g4 = model_4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1,g2,g3,g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b1+b2+b3+b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 2, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_N = 5\n",
    "t = b[test_idx][0][:len(x['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.44023"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "b[test_idx][0][:len(x['sentences'][test_idx])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'former nato chief: we need us as worlds policeman'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x['headline'][test_idx])\n",
    "display(x['claims'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : The timing of his calls for extreme US bellicosity are centered on trying to influence the upcoming US election in favor of Democratic nominee Hillary Clinton, who has campaigned heavily on picking fights in Syria and against Russia.\n",
      "5 : Rasmussen underscored this fact by declaring Donald Trump, who openly said the US cannot be the worlds police, as very dangerous for the world.\n",
      "3 : This of course closely mirrors recent Pentagon talk of wars in the decades to come.\n",
      "2 : Rasmussen, who was always a relative hawk in the post but seems to have taken it to an entirely new level, set out a series of things the US needs to fix militarily, including Iraq, Syria, Libya, Russia, China, and North Korea.\n",
      "1 : Rasmussen criticized President Obama for not being hawkish enough, saying his successor needs to be much more interventionist, and declaring  we need America as the worlds policeman,  adding that the US needs to restore international law and order through wars.\n"
     ]
    }
   ],
   "source": [
    "for s in t:\n",
    "    if s>=len(x['sentences'][test_idx]):continue\n",
    "    print(s,':',x['sentences'][test_idx][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.44023"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "h_s_attended_vector = b[test_idx][0][:len(x['sentences'][test_idx])]\n",
    "h_s_attended_vector.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h_s_attended_vector = pd.DataFrame(h_s_attended_vector)\n",
    "\n",
    "\n",
    "xw = df_h_s_attended_vector.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xw_scaled = min_max_scaler.fit_transform(xw)\n",
    "df_h_s_attended_vector = pd.DataFrame(xw_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb6d10aeb8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(2.0,7.0)})\n",
    "sns.heatmap(df_h_s_attended_vector, annot=True, cmap='YlGnBu', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa1 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa2 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa3 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa4 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s1 = Model(model.inputs,model.get_layer(name='sa1').output)\n",
    "model_s2 = Model(model.inputs,model.get_layer(name='sa2').output)\n",
    "model_s3 = Model(model.inputs,model.get_layer(name='sa3').output)\n",
    "model_s4 = Model(model.inputs,model.get_layer(name='sa4').output)\n",
    "model_s1.summary()\n",
    "model_s2.summary()\n",
    "model_s3.summary()\n",
    "model_s4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sb1, sg1 = model_s1.predict([x['sentence_vectors'],x['input_headline_vector']])\n",
    "_, sb2, sg2 = model_s2.predict(x)\n",
    "_, sb3, sg3 = model_s3.predict(x)\n",
    "_, sb4, sg4 = model_s4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128, 0.0050128,\n",
       "        0.0050128, 0.0050128], dtype=float32),\n",
       " array([-0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258,\n",
       "        -0.01164258, -0.01164258, -0.01164258, -0.01164258, -0.01164258],\n",
       "       dtype=float32),\n",
       " array([-0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754,\n",
       "        -0.00668754, -0.00668754, -0.00668754, -0.00668754, -0.00668754],\n",
       "       dtype=float32),\n",
       " array([-0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969,\n",
       "        -0.01190969, -0.01190969, -0.01190969, -0.01190969, -0.01190969],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg1,sg2, sg3, sg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = sb1[test_idx]+sb2[test_idx]+sb3[test_idx]+sb4[test_idx]\n",
    "sb = sb[:len(x['sentences'][test_idx]),:len(x['sentences'][test_idx])]\n",
    "\n",
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb = pd.DataFrame(sb)\n",
    "\n",
    "\n",
    "zx = df_sb.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "zx_scaled = min_max_scaler.fit_transform(zx)\n",
    "df_sb = pd.DataFrame(zx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb2b120fd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAK0CAYAAACDRsJEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xd8VFX+//H3zKRNOgkEUug1ASmCYEFEugoI1l1lF3VF17Xs97fFygqKDeuKuquuK6Koq7g2EGmiIoIsVTokkNCSENLLpExm5vfHYDBMCNIyOeH1fDzm8SB3ztw59x7mzmc+8zlnLB6PxyMAAAAAxrL6uwMAAAAATg1BPQAAAGA4gnoAAADAcAT1AAAAgOEI6gEAAADDEdQDAAAAhiOoBwAAAAxHUA8AAAAYjqAeAAAAaADTp0/XkCFD1LVrV+3cubPONi6XS4888oiGDRum4cOHa86cOb9o3wT1AAAAQAMYOnSo3n33XSUmJh6zzdy5c7V3714tWrRIH3zwgV566SXt37//uPsmqAcAAAAaQL9+/RQfH19vm/nz5+vaa6+V1WpVTEyMhg0bpgULFhx33wGnq5MAAADA2aa4uFjFxcU+2yMjIxUZGXnC+8vKylJCQkLN3/Hx8crOzj7u4xo0qG+Vcl9DPh1OwJylg/zdBRxHm3C3v7uAerQN7+rvLgDGmrkz3d9dwHHc3GWkv7twTPY2v/br8z/91wv18ssv+2y/6667dPfddzdYP8jUAwAAACdp4sSJGj9+vM/2k8nSS97MfGZmpnr27CnJN3N/LAT1AAAAwEk62TKbYxk1apTmzJmjESNGqLCwUEuWLNG777573McxURYAAADGslisfr2diMcee0yDBg1Sdna2br75Zl1xxRWSpEmTJmnTpk2SpCuvvFJJSUkaMWKErrvuOt15551q3br18c+Dx+PxnPjpOznU1Dde1NQ3ftTUN27U1AMnj5r6xq8x19SHtr3Rr8/v2HP8LHpDIFMPAAAAGI6aegAAABjLQo5aEpl6AAAAwHhk6gEAAGCsE52s2lRxFgAAAADDEdQDAAAAhqP8BgAAAMai/MaLswAAAAAYjkw9AAAAjGWxWPzdhUaBTD0AAABgOIJ6AAAAwHCU3wAAAMBg5KglzgIAAABgPDL1AAAAMBZLWnpxFgAAAADDEdQDAAAAhqP8BgAAAMai/MaLswAAAAAYjkw9AAAAjGUhRy2JTD0AAABgPIJ6AAAAwHCU3wAAAMBYTJT14iwAAAAAhiOoBwAAAAxH+Q0AAACMRfmNF2cBAAAAMByZegAAABiLTL0XZwEAAAAwHEE9AAAAYDjKbwAAAGAsiyz+7kKjQKYeAAAAMByZegAAABiLibJenAUAAADAcAT1AAAAgOEovwEAAICxKL/x4iwAAAAAhiNTDwAAAGORqffiLAAAAACGI6gHAAAADEf5DQAAAAxGjlriLAAAAADGI1MPAAAAYzFR1ouzAAAAABiOoB4AAAAwHOU3PxMdZdfz067R4Au7KL+wTI+/sECffLHBp11kRIgee2CshlzcVZL01n9W6tlXlvi0u6Bfe33y9u/1wqtfafqMRWe8/01daXGZZk3/QFvW7FR4VJiunnS5Bgzv69NuwftLtWLhGuVlFygiKkyDx12oUb8eUqvNko+WacmcZSouLFVMXLTueuIWtWod11CH0mQVFzn0/KMfau0POxQVHaZb7rpcQy4716fdhtVpevdfi5W6/YAiIu16Z95DNfflZBXo1mufqdW+orxKt/3faF3zm8Fn+hDOeoWFJXrooRn6/vv1atYsUn/60281Zsxgf3cLhzE+/lNeUqb5M95XxvrtskeG6ZLfjlH3wf182q3+7GutmbtM5cWlCrIHq9vAczXklitltdlUVliiJf/6r/ZtTpOzokrN28Zr6O/GK6Fru4Y/oCaE8hsvgvqfeXLyODmdLvUYNE09uiVo9j9v1tYdWdqRdrBWu0fvHyO7PVDnDX9KzWPCNefNSdqfWaj/fLKmpk1AgFXTHhyrtT/ubejDaLLee+Fj2QID9Pwnj2hf2gHNuP8NJXVKVGL7VrXaeTzS7x68QUkd4nUoM0/P/+U1xcQ1U/+hfSRJy+b9oO++WKV7pt+q+LYtdSgzT6ERdn8cUpPz8vSPFRho04eLp2rXjkxN/uO/1aFLgtp1rD1GIfYgjbyyvwaPcuo/b35V6764+Gb6fPkTNX9nHcjTzeOe0sChPRvkGM52jz76qgIDA/T99+9o27bduv32R9WtW3t17tzW312DGB9/WvTqHNkCbLr7ncd1cPd+ffToa4prn6gWbeNrtevUv4fOGTpAIeGhKi8p0ydPvak1c79V/3FD5KyoVHznNhr6u/EKjYrQxsUrNeeR13THv6cqyB7spyNDU8FHm8NC7YG6YkQPTZ+xSA5Hlf63LkMLv96qa8b08Wk7fHCyXvn3tyqvcGpfZoHe+3i1fnVV7U/rv79pkL79fqfSduc01CE0aZXllVq7bKPG/W6UQkKD1blnB/W6sLtWLlrj0/ayG4aobZck2QJsatUmTr0v6q60TemSJLfbrblvLdKv7rpSCe1ayWKxKC6xucIjwxr6kJqc8vJKLf9qkybeMUr20GD16NNeF1ySoq++WOvTtluPNhp2RV/FJ8Ycd79Lvlirc/p0UKuE47fFqXE4KrRo0Qr98Y8TFBZmV79+3TVkSH999tnX/u4axPj4U1VFpXas+FGDJlyhIHuwWnfvqE79e2jL16t92jaLb6GQ8FDvHx7JYrGoIDNXkhTdqrn6jxui8JgoWW1W9R51kVzV1co/cNBnP/jlLLL69dZY/KKeFBQUaNu2bdq2bZsKCgrOdJ/8okO7FnK5PNq9J7dm29YdWeraqWWd7S2W2v/u9rN2SQnR+vVV/fTcP7+q45E4GQf3HZLVaqlVItO6U4Iy07PrfZzH41HqxnQlHM7mFxwqUsGhQh1Iz9Zfr3lU91//mD57c4HcbvcZ7f/Z4MCeXFltFiW1bVGzrUPnBGXsrn+MjmfJvLUaPtr3K26cfhkZB2S1WtW+fWLNtm7d2istjW8cGwPGx3/yD+TIarUqJvHIe1Bc+0Qd2ptVZ/st36zR89f9VS/e+IBy0g+o92UX1dnu4O79clW7FB3fos77gRNRb/nN3r179be//U1bt25VXJz3P3JOTo5SUlL0yCOPqF27dg3RxwYRFhqkktKKWtuKSyoUHub7ddjXy3forlsv1T0PfKAWzSP06/HnyW4Pqrn/sQfH6unDGX+cHhXlVbKH1y6RsYeFqKK8st7HfT5zoTwety66rL8kqeBQoSRpy+odemTmX+UoLdcLf3lNzVpEadCYC85M588S5eWVCjtqjMLCQ1TuqH+M6rNp/W4V5Jfo4mGU3jQEh6NCERGhtbZFRISprKzcTz3CzzE+/uOsqFJwaEitbcFhdlUd4z2o++B+6j64n/Izc7R56WqFRUf4tKl0lGve8+9o4K9HKSSMElCcunoz9ffee6+uvvpqrVq1Sl988YW++OILrVq1SldddZXuu+++hupjgyhzVPkE8BHhwSot833BTn7ic1VUOrVywb2a9fJEfTJ/g7KyiyR5S3PCQ4P12YKNDdLvs0WIPUgVZbU/dJU7KhVSTw3i0o+/08qFa3TPU5MUGOT9/BoUFChJGvXrSxUaYVfz+BgNGnuBNv2w7cx1/ixhtwfLcdQHY0dZheyhJ18nunjuGg0ccs4p7QO/XGhoiEpLHbW2lZY6FEbA0SgwPv4TGBKkSkft61ulo+K4dfAxCXFq3qaVFv3zw1rbnZVV+ujR15XQtZ0uuHbEae/v2cZisfr11ljU25PCwkKNHTtWVuuRZlarVVdeeaWKiorOeOca0u6MQwoIsKp929iabd27xvtMkpWkwqJy3Xnvf9Rz0GO6ZOzzslotWr9pnyTp4vM7qVePJG1cNlkbl03W2Mt66bbfDtRbL/+2wY6lKWrZuoVcLrcO7j9Us21/WmZNWc3Rln+xSl++t1R/fuEOxcRFH9lPmzgFBNpk+Xn9FE6LxLbN5XK5dWDvkTHanZqldh3qHqPjqaxwatmSjZTeNKB27RLlcrmVkZFZs2379nR16tTGj73CTxgf/4lJjJPb7VZ+5pF5cjnpB9SiTXw9j/Jyu9wqyDpS2lvtdOrjx99QRGy0Rt15/RnpL85O9Qb10dHRmjdvnjweT802j8ejzz//XJGRkWe8cw3JUe7U/MVbdO9dIxRqD9R5fdpq5JDu+mjuep+2bVvHqFlUqKxWi4Zc3FUTrh2gv7+2VJI0fcZCXXj5Mxp61d819Kq/a9HXWzV7zv/0fw/NaehDalKC7cE6d9A5+uzfC1RZXqnUTena8P1mXTDCN+D7YfFaffzGfP2/Z3+vFgmxtfcTEqTzLu2jBe9/rQpHhfJzCvXdvB/U88KUhjqUJstuD9ZFQ87RrFcXqry8Uls2pGvFN1s09ArfZUfdbreqKp2qrnbJ4/GoqtIpp7O6Vpvvv96k8IgQ9T6vU0MdwlkvNDREw4dfoBkz3pXDUaG1a7fqq69W6corL/V31yDGx5+CQoLV9YJe+u7d+aqqqNT+rbuVtmqTul96nk/bHxeuUFlhiSQpd2+WfpizWO16dZEkuapd+uTJNxUQFKjRf5ogi7XxZHlhPovn5xH7UTIyMjRlyhRt27ZNLVt6J4IePHhQ3bp109SpU9WhQ4cTerJWKY27ZCc6yq4XHrtWl1zQWflFDj3+/Jf65IsNGtC3nd577RZ17PewJGnsqJ569P4xiowI0e49uXrsuS/1zfc769zni49fq8yDRY1+nfo5Swf5uwvHVVpcpremf6Cta3YqPDJUV992hQYM76udP+7Wi/e9rlcWPCVJuv/6x1RwqFABQUemjJw/vK9+8+drJUnlZRV6+9kPtXHlNoWG2zVo9ACNnjii0Wfv24Q3/sm8xUUOPffIB1q3aqcio8L0u7u969RvWr9bD939Rs1SlT+uSdNfb3+11mN79u2gZ1//Q83fD9z5urp2b6Ob/jCqQY/hZLUN7+rvLpwWhYUlevDBF7VixQZFR0foz3+eyDrojUhTHZ+ZO9P93YXjKi8p0/wX31PGhh2yR4Tpkoneder3bdmlD6f+U3+e86wk6Yu/v6tda7fKWV4pe1S4ul3UW4MmXKGAoEDt3ZSq9x58SQFBgbJYj7znXDf1DrXu3tFfh/aL3NxlpL+7cEytez7q1+fft/Fhvz7/T+oN6n+Sn5+vrCzvDO/4+HjFxJzc0nKNPag/m5kQ1J/tTAjqz2ZNJagH/MGEoP5sR1B/bI0lqP9FPz4VExNz0oE8AAAAcKY0psmq/sRZAAAAAAxHUA8AAAAY7heV3wAAAACNkYUctSQy9QAAAIDxyNQDAADAWEyU9eIsAAAAAIYjqAcAAAAMR/kNAAAAjEX5jRdnAQAAADAcmXoAAAAYiyUtvTgLAAAAgOEI6gEAAADDUX4DAAAAczFRVhKZegAAAMB4ZOoBAABgLJa09OIsAAAAAIYjqAcAAAAMR/kNAAAAjGWxWPzdhUaBTD0AAABgODL1AAAAMBa/KOvFWQAAAAAMR1APAAAAGI7yGwAAABiLdeq9OAsAAACA4QjqAQAAAMNRfgMAAABzsU69JDL1AAAAgPHI1AMAAMBcpKglcRoAAAAA4xHUAwAAAIaj/AYAAADmYqKsJDL1AAAAgPHI1AMAAMBcZOolkakHAAAAjEdQDwAAABiO8hsAAACYixS1JE4DAAAAYDwy9QAAADCWh4myksjUAwAAAMYjqAcAAAAMR/kNAAAAzEX1jSQy9QAAAIDxyNQDAADAXFZS9RKZegAAAMB4BPUAAACA4Si/AQAAgLlYp14SmXoAAADAeGTqAQAAYC4S9ZIaOKgPvmVkQz4dTsBflgf5uws4juBgrlqNWbdmmf7uAuqx8SA5rMYse021v7uA47j5SX/3AMdD+Q0AAABgOFIXAAAAMBfr1EsiUw8AAAAYj6AeAAAAMBzlNwAAADAX69RLIlMPAAAAGI9MPQAAAMxFol4SmXoAAADAeAT1AAAAgOEovwEAAIC5WKdeEpl6AAAAwHhk6gEAAGAuEvWSyNQDAAAAxiOoBwAAAAxH+Q0AAACM5eEXZSWRqQcAAACMR6YeAAAA5mJJS0lk6gEAAADjkakHAAAAGkh6erruv/9+FRYWKjo6WtOnT1e7du1qtcnLy9MDDzygrKwsOZ1OnX/++Zo8ebICAo4dupOpBwAAgLksfr6doClTpuiGG27QwoULdcMNN+jhhx/2afPqq6+qY8eOmjt3rubOnastW7Zo0aJF9e6XoB4AAAA4ScXFxdq/f7/Prbi42KdtXl6etm7dqtGjR0uSRo8era1btyo/P79WO4vForKyMrndblVVVcnpdKply5b19oPyGwAAAJjLz0tazpo1Sy+//LLP9rvuukt33313rW1ZWVlq2bKlbDabJMlmsykuLk5ZWVmKiYmpafeHP/xBd999twYOHKjy8nLdeOON6tu3b739IKgHAAAATtLEiRM1fvx4n+2RkZEnvc8FCxaoa9eumjVrlsrKyjRp0iQtWLBAo0aNOuZjCOoBAACAkxQZGfmLA/j4+HgdPHhQLpdLNptNLpdLOTk5io+Pr9Vu9uzZeuKJJ2S1WhUREaEhQ4Zo1apV9Qb11NQDAADAXFaLf28nIDY2VsnJyZo3b54kad68eUpOTq5VeiNJSUlJWrZsmSSpqqpKK1euVOfOnes/DSfUEwAAAAAnberUqZo9e7ZGjhyp2bNn65FHHpEkTZo0SZs2bZIkPfjgg1q7dq3GjBmjcePGqV27drruuuvq3S/lNwAAAEAD6dixo+bMmeOz/V//+lfNv9u0aaOZM2ee0H4J6gEAAGAu/y5+02hQfgMAAAAYjkw9AAAAzOXndeobCzL1AAAAgOEI6gEAAADDUX4DAAAAc1F+I4lMPQAAAGA8MvUAAAAwFylqSZwGAAAAwHgE9QAAAIDhKL8BAACAuZgoK4lMPQAAAGA8MvUAAAAwF4l6SWTqAQAAAOMR1AMAAACGo/wGAAAAxvJYqb+RyNQDAAAAxiNTDwAAAHOxpKUkMvUAAACA8QjqAQAAAMNRfgMAAABzUX0jiUw9AAAAYDwy9T8TFRKgp0cma1C7GOWXO/X0sl36bPvBOtv2iAvXw5d2UY+W4XI43XplVYZmrttfq82ApGh9+Ktz9dLKDD37/e4GOIKmLzIwQA/166wBLaNVWOnUPzbv0aJ9h3za3ZrSRjd3S1KV21Oz7cbF65RZVlmr3eVt4zTlvC56fE2qPs+oe6zxy0UEBui+Xp10XotoFVU59fr2PVpyINen3c1dWus3nWuPz83frleWwzs+f+nZUb1jo5QUFqKnNqRpwf6cBjuGpsxZWqYdb72tgi1bFRgervZXj1fL8/sfs727ulprpjwqV2WlLnh2uncfJaXa/PI/5MjKlsftVmh8K3W87hpFde7UUIfRZEUGBujBvkeub//ccozrW3Ib3XTU9W3CEu/1LSooQM9ckKK2EXZZLRZllDj00qZ0bcwrachDaZKi7IF6+uqeurhzc+WXVenphTv0+Y+ZdbbtnhCph0enqEdClBxVLv3jmzTNXJEhSTq3TTM9PDpFneLCtS/fob99tllr9hQ04JE0QSxpKYmgvpZpQ7vK6XKr7z+WKyUuXDOv6qWth0qVmldWq10ze6BmXdNb075O1fydOQq0WhUfEVyrTYDVoilDOmtdZlFDHkKT99c+HeV0u3XZ3FXqEh2u5wemKLWoTOnFDp+2i/flaurqncfcV0SgTRO7JmlXUdkx2+DE/L9zOqja7dG4Rf9Tp6gwTe+forSiMmWUlvu0XZqZq8fWp9a5n13FZVqamavfJ7c7wz0+u6S++76sATZd+MIzKt23X5tefEnhrZMUlphQZ/t9CxYpKCJC5ZVHPgzbQoLV9ebfyh4XJ1ksylv/ozbPeEUX/v1ZWWy2hjqUJukvfTqq2u3W5fO817fnLkpRamGZ0kt8r29L9td9fSuvdumxtanaV1ouj6RBCTF65sIUXT5vlVwen+Y4AdOu7C6ny61+jy9RSnyk3rzpPG3LKlZqTmmtds1CAzXr5v6a9sVWfbkpW4E2i1pF2SV5Pxi88dt+mvzpJi3Ykq2xvRL174nn6eKnl6q4otofh4UmhPKbw+yBVl3WpYWe+363HE6X1hwo0pK0XF2V0sqn7a19W2tZer4+3XZQVS6PypwupeXXvuhO6tdG32Xka1e+78UYJyfEZtWlSbF6bcselbvc+jGvWN9l5uuyNi1Oan9/6NFOH6ZlqrCKC+npEGKz6pL4WL2xwzs+m/JL9P3BfI1MijvhfX2Ska11uUWqcrvPQE/PTq7KSuWuXad2466ULSREUZ07KbZXLx1c+UOd7csP5Srnh1VqfcVltbZbAwMV2qqVLFar5PFIVouqHQ45y/hwfCpCbFZdmhir17YedX1re2LXtyq3R3sPB/QWSW6PFBUUqMigwDPS77OFPdCmUd3j9dzinXJUubRmT4GWbDuoq/ok+rS9dWAHLUs9pM82ZKrK5VZZlUu7DnkD/75tmym3tFLzN2fL7ZE+3XBAeWWVGtUjvqEPCU0QmfrDOjQLldvtUXrBkYzitkMlGtC6mU/bcxOitP1QqT7+dV+1bWbXhqxi/W3JDmWWeLNZiZEhuq5HvK54Z7UeHdqlwY6hqWsTYZfL49G+0oqabalFZerTPKrO9hcnxGjR2AHKK6/SnF1Z+nh3ds19Kc3CldwsXE+v36WhrU/uQwFqax1ml9vj0f6yI+Ozq6hMvWLrHp8LW8Zo3sj+yqt06uP0LH22J7vOdjg9HNkHZbFaFdqqZc228NZJKtxZ97dZae/9R+2vGidbYN3B4Jopj3pLcFwutbp4oIIiI89Iv88WbcLrvr6d26Lu18/A+BgtHDNAeRVV+uio65skzR7WR20j7Aq0WvVZerYKKp1ntP9NXYfmYXJ7PErPPfLhdVtWiQa0j/Fp26dNtHZkl+i/v79QbWNDtWFfoR7+bLMyiypkke+cToss6toy/MweQFPHOvWSTiGoHzNmjObOnXs6++JXoYE2FR+VsS2udCksyPfr5FbhweoeF64JH23QjkNleuCSjnppdHdd/f46SdLUIZ1rMv44fUIDbCo76pyWOqsVGug7Rl/tO6RPd2crv6JK3WMj9NT5ySp1VmvRvlxZJd3bp6Oe3bBbfBt9+tgDbCo9enyqXQoN8B2fpZm5+nzPQRVUVimlWYSm9eumUme1vsr0rb/H6eGqrJTNbq+1LcBul6ui0qdt7rr18rhdan5uHxVu31Hn/vo98rDcTqdy162Xu5pr3amy13F9K3NW1/n6WbL/kD5NP3x9i4nQk+cnq6SqWov3H3n9TFiyXkFWiy5JiFWglS/lT1VosE0lFbU/GJVUOBUe7BtGtYoKUY+EKE14c5V2ZJfo/su6acav+uia11Zq7d4CtYwM0dheCZq/KUtX9k5Q25hQ2et4HwNOVL2v9LS0tGPeCgqa1qQOh9OliKDaL86IYJvKqnzfrCqqXVqYlquN2SWqdLn19xXp6pcYrYggm4Z2iFV4UIDm7WBi3+nmqHYp7Kg3uLCAgDo/PKWXlCu3okpuSZvySvRBWqaGJDaXJF3dMV5pRQ5tzmfi2OlUXu1SWODR42OTo46Ab09pufIqveOzuaBEH6VnanBCbAP19OxkCw6Wq6L23IbqigrZQmrPB3JVVmr3nI/V6YZfHXef1sBAxQ3or31fLlDpvn2ntb9nm/K6rm+BAXW+fjJ+fn3LP3x9S2ru067K7dHi/bn6bdckdYoKO1NdPys4Kl0KD679rVV4cIBKK33LNyudbi3ckq2N+4tUWe3Wi1+lql+7GEUEB6jQ4dSkd9bodwPba81Dw3RJlxZavitXWcUVPvsBTlS9mfrRo0crMTFRHo9vPrOwsPCMdcofdhc4ZLNa1C7aroxC7xtfcotw7cz1rRPdfqjMW0t62E//slgsuqhtjM5pGaHVd1wkSYoMCpDL41HXFmGa9OmmM34cTdneknLZrBa1Dg+p+Yq6c3SYdhcfv5bXI0/Nd57nxUWrT4soXRjvLa2KDApQ1+gwdYkO07MbWKXoZO0rK5fNYlFSWEhNCU7HyDBl1DHJ72gej/craJw5oa1ayuNyy3HwoEJbektwyvbtV1hC7Umy5QdzVJGXqw1PPStJ8lRXq7q8XCv+31917kP3KaS5b/DodrlUcShX4a1bn/kDaaL2lvpe3zpF/bLrm+Sp99Vjs1qUGBaiNBYFOGm7c8u8MUJsqDLyvNe05PhIpR70TQ5tyy6u9S3wT+HCTxUiq9LzdeUr30vyjs23fxmsN77jveeU8PYh6TiZ+sTERL333ntaunSpzy02tmll1cqdbi1IPaQ/XdRB9kCr+iVEaXinFvp4q2+d75zNWRrZuYVSWoQrwGrRPee30//2F6q4slrPLd+tS//9gy6ftVqXz1qtxbty9f7GTP1lwTY/HFXTUuFy65sDebotpa1CbFb1jI3QoIQYfbnXd8m3QfExijicNU5pFq7rOiVoWWa+JOnRNTt1/cK1mrB4vSYsXq9tBaV6Y+te/XPzngY9nqamwuXWsqw83dK1jUJsVvVoFqGBrWK0sI7lKAe2jFH44fFJjg7X1e3jtTw7r+b+AItFQVZvmB9gPfJvnDxbcLCan9tHGZ/OlauyUkWpacrdsEEtLzi/VruwxASd/8xT6jd1svpNnawuN/1GQZGR6jd1soJjYlS8a7eKUtPkrq6Wq6pKe+cvkLOoWBHt2/vpyJqGn65vk46+vu3xvb5dfNT17dqfXd+6x0SoV2ykAiwWBVut+k2XRMUEB2oL30yeknKnSwu3ZOtPw7vIHmhT37bNNDylpT5ef8Cn7Zw1+zWyeyulxEd6Y4QhnfS/9Pya1W26H94eHhyghy5PVnZRhZalUnqIU1dvpn7EiBE6cOCAWrZs6XPf8OHDz1in/GXykh16ZmSy1v3hYhWUOzV58Q6l5pXpvMQozbq6l1JmLJMkrdhXoKe/262ZV/WSPdCq1QeKdM8XWyRJZU5XrbrIimq3yp1uFbFU1Wnx9LpSWKTOAAAgAElEQVRdmtyvsxaMGaCiKqemr9ul9GKHejeP1AsDu+vST1dKkoa3bqHJ/Tor0GZVjqNS7+zYr/l7vMGlt+77yBg53d4VjMqoCz5lz2/arft7d9JnI/qr2Fmt5zftUkZpuXrGROrpASka9aV3pZUhic11X+9OCrRadaiiUu/tOqAF+48EL8+d371mAvQ5MZG6t1cn3bNikzbkFfvluJqKzhNu0I6Zs7Ti//6iwPAwdZ5wo8ISE1S4M1Wb/v6SLv7HDFlsNgVFHZmcGRgWJlktNdvc1dVKe+8DVRw6JIvNprCkRPX4410Kbhbtr8NqMp5Zv0sP9eusL0d7r29Pr9+l9BKHesV6r29DPvvZ9a3v4etbeaVm79iv+Xu917cgq0V/6tVRCWHBqvZ4tKvIoT+v2Krciip/HlqTMPmzzXrm6p5aO3mYChxOTf50s1JzSnVeu2Z666b+6j51oSRp5e48PbNwu96ceJ7sQTatzsjXHz9YX7Of2y/poMFdvauCLdt5SLfPXuuX42lSWKdekmTx1FVbc4a0fXZpQz0VTlCrdkH+7gKOIziYi1Zj1q0Zq4s0ZhsPsthbY5a9ht90aewynrzC3104po43f+jX59818zq/Pv9PmBIPAAAAGI7UBQAAAMxF+Y0kMvUAAACA8cjUAwAAwFgeEvWSyNQDAAAAxiOoBwAAAAxH+Q0AAADMxURZSWTqAQAAAOORqQcAAIC5LGTqJTL1AAAAgPEI6gEAAADDUX4DAAAAczFRVhKZegAAAMB4ZOoBAABgLlLUkjgNAAAAgPEI6gEAAADDUX4DAAAAc7FOvSQy9QAAAIDxyNQDAADAXCxpKYlMPQAAAGA8gnoAAADAcJTfAAAAwFgeJspKIlMPAAAAGI+gHgAAADAc5TcAAAAwFylqSZwGAAAAwHhk6gEAAGAu1qmXRKYeAAAAMB5BPQAAAGA4ym8AAABgLtapl0SmHgAAADAemXoAAACYi4myksjUAwAAAMYjqAcAAAAMR/kNAAAAzEX1jSQy9QAAAIDxyNQDAADAWB4mykoiUw8AAAAYj6AeAAAAMBzlNwAAADAX5TeSyNQDAAAAxiNTDwAAAHNZyNRLZOoBAAAA4xHUAwAAAIaj/AYAAADmIkUtidMAAAAAGI+gHgAAADAc5TcAAAAwF6vfSCJTDwAAABivQTP1OTP+1ZBPhxOQ4+8OAIZb7e8OAMCZ9OQV/u7BsfGLspLI1AMAAADGI6gHAAAADMdEWQAAAJiL8htJZOoBAAAA45GpBwAAgLE8LGkpiUw9AAAAYDyCegAAAMBwlN8AAADAXKSoJXEaAAAAAOORqQcAAIC5mCgriUw9AAAAYDyCegAAAMBwlN8AAADAXPyirCQy9QAAAIDxyNQDAADAXGTqJZGpBwAAAIxHUA8AAAAYjvIbAAAAmIvqG0lk6gEAAADjkakHAACAsTxMlJVEph4AAAAwHkE9AAAAYDjKbwAAAGAuC+U3Epl6AAAAwHgE9QAAAIDhKL8BAACAuVj9RhKZegAAAMB4ZOoBAABgLhL1ksjUAwAAAMYjqAcAAAAMR/kNAAAAjGUlRS2JTD0AAABgPDL1AAAAMBY/KOtFph4AAAAwHEE9AAAAYDjKbwAAAGAsym+8yNQDAAAAhiNTDwAAAGNZSNVLIlMPAAAAGI+gHgAAAGgg6enpuv766zVy5Ehdf/31ysjIqLPd/PnzNWbMGI0ePVpjxoxRbm5uvful/AYAAADGMq36ZsqUKbrhhht05ZVX6rPPPtPDDz+st99+u1abTZs26eWXX9asWbPUokULlZSUKCgoqN79kqkHAAAAGkBeXp62bt2q0aNHS5JGjx6trVu3Kj8/v1a7t956S7fccotatGghSYqIiFBwcHC9+yZTDwAAAGP5O1NfXFys4uJin+2RkZGKjIystS0rK0stW7aUzWaTJNlsNsXFxSkrK0sxMTE17Xbt2qWkpCTdeOONcjgcGj58uO644456JwUT1AMAAAAnadasWXr55Zd9tt911126++67T2qfLpdLO3bs0MyZM1VVVaVbb71VCQkJGjdu3DEfQ1APAAAAnKSJEydq/PjxPtuPztJLUnx8vA4ePCiXyyWbzSaXy6WcnBzFx8fXapeQkKBRo0YpKChIQUFBGjp0qDZu3FhvUE9NPQAAAIxlsfr3FhkZqaSkJJ9bXUF9bGyskpOTNW/ePEnSvHnzlJycXKv0RvLW2i9fvlwej0dOp1M//PCDunXrVu95IKgHAAAAGsjUqVM1e/ZsjRw5UrNnz9YjjzwiSZo0aZI2bdokSbriiisUGxuryy+/XOPGjVOnTp10zTXX1Ltfi8fj8Zzx3h9mb/PrhnoqAAAAnCble9/3dxeOqesby/z6/DtuHeTX5/8JmfoT9PuJI7R83uMqTH1brz/3e393B0dhfBo/xqhxY3waN8ancWN84E9MlD1BWQcLNH3GJxp2SU/ZQ+r/EQA0PMan8WOMGjfGp3FjfBo3xgf+RFB/gj5bsFqSdG7PDkqMjzlOazQ0xqfxY4waN8ancWN8GjfGxz+shv2i7JlC+Q0AAABguHqD+oKCAj300EO65ZZb9O6779a672QX0wcAAABwetUb1E+ZMkVRUVH61a9+pSVLluiuu+5SdXW1JGnfvn0N0kEAAADgWCwW/94ai3qD+j179ujee+/ViBEj9Oabb6pFixa6/fbbVVlZ2VD9AwAAAHAc9Qb1VVVVNf+2WCyaMmWKunTpottuu+2sDextNquCgwNls1lr/RuNA+PT+DFGjRvj07gxPo0b4+MfZOq96v2f1rp1a61evbrWtvvuu0+9e/dWRkbGmexXo3X/PeNVmPq2/nrnlbrhqotVmPq27r9nvL+7hcMYn8aPMWrcGJ/GjfFp3Bgf+FO9vyhbWFgoi8WiqKgon/vS0tLUqVOnE3oyflEWAADAPI35F2W7z/TvL8puublx/KJsvevUR0dHH/O+Ew3oAQAAgNPN0phqYPyIQi8AAADAcPyiLAAAAIxlIUUtiUw9AAAAYDyCegAAAMBwlN8AAADAWMyT9SJTDwAAABiOTD0AAACMRabei0w9AAAAYDiCegAAAMBwlN8AAADAWJTfeJGpBwAAAAxHph4AAADGspKpl0SmHgAAADAeQT0AAABgOMpvAAAAYCwmynqRqQcAAAAMR1APAAAAGI7yGwAAABiL8hsvMvUAAACA4cjUAwAAwFgWFqqXRKYeAAAAMB5BPQAAAGA4ym8AAABgLCbKepGpBwAAAAxHph4AAADGIlPvRaYeAAAAMBxBPQAAAGA4ym8AAABgLMpvvMjUAwAAAIYjUw8AAABj8YOyXmTqAQAAAMMR1AMAAACGo/wGAAAAxmKirBeZegAAAMBwZOoBAABgLAspaklk6gEAAADjEdQDAAAAhqP8BgAAAMZioqwXmXoAAADAcGTqAQAAYCwLqXpJZOoBAAAA4xHUAwAAAIaj/AYAAADGovrGi0w9AAAAYDiCegAAAMBwlN8AAADAWJTfeJGpBwAAAAxHph4AAADGIlPvRaYeAAAAMFyDZuoTBo5tyKfDCQgelujvLuA42ifxGbwxyy32dw9Qn4MbSvzdBdSj+IMv/N0FwHiU3wAAAMBYVspvJFF+AwAAABiPTD0AAACMRabei0w9AAAAYDiCegAAAMBwlN8AAADAWFaLx99daBTI1AMAAACGI1MPAAAAYzFR1otMPQAAAGA4gnoAAADAcJTfAAAAwFhkqL04DwAAAIDhyNQDAADAWCxp6UWmHgAAADAcQT0AAABgOMpvAAAAYCzWqfciUw8AAAAYjkw9AAAAjEWG2ovzAAAAABiOoB4AAAAwHOU3AAAAMBYTZb3I1AMAAACGI6gHAAAADEf5DQAAAIxlsXj83YVGgUw9AAAAYDgy9QAAADAWE2W9yNQDAAAAhiOoBwAAAAxH+Q0AAACMRYbai/MAAAAAGI5MPQAAAIxlZUlLSWTqAQAAAOMR1AMAAACGo/wGAAAAxmKdei8y9QAAAIDhyNQDAADAWGSovTgPAAAAgOEI6gEAAADDUX4DAAAAYzFR1otMPQAAAGA4MvUAAAAwFr8o60WmHgAAADAcQT0AAABgOMpvAAAAYCwmynqRqQcAAAAMR1APAAAAGI7yGwAAABiLDLUX5wEAAAAwHJn6n4kKC9JTt/XXwHPiVVBSqWc++FFzV+zxaffmvZeoX7cWNX8HBliVnlmiy+//smbbTaO66KZRXRUbGaLMvDLd/tx3ysguaZDjaKqiggI07eIuujChmQornXphTbq+2H3Ip92dfdrqtl6t5XQdWbd23Kdrtb+kQpI0ID5afz2vvdpE2lVQ6dQbG/dpzo7sBjuOpiw8IEB/7N5Z5zaPVnGVU2+l7tG32b5j9JMAi0UvX9hHdptNE5etrtneMyZKv+vSXgmhISquqtac9H1acOBgQxxCkxYZGKCH+nXWgJbRKqx06h+b92jRPt/xuTWljW7ulqQq95HX0I2L1ymzrLJWu8vbxmnKeV30+JpUfZ7B+JyqKHugnh7fQxd3aq58h1NPL9qhzzdm1dm2e3ykHr4iWT3iI+VwuvSPb3dp5krv+1VKqwhNHZ2ibq0iVFbp0vtr9mnG12kNeShNUnRUqGY8caMuHdhN+QVlevS5z/XfuWt82kVG2PXk5Gs07JIUSdKb736n6S/Nr9Xm9omD9fuJg9U8NkIHsgp04+9f166MnAY5jqaIdeq9COp/5pGb+8lZ7daAOz5Rcrto/fuvl2j7ngKlHiiu1e6Wp7+t9fe7k4do5ZYjb2jXDe6gawd31K3PfKu0A8VqExeuorKqBjmGpmzyhZ3kdLk16P2V6hYbrn8O76Ed+WVKK3T4tF2w+5DuW7bDZ3uAxaIZQ1P03Op0fbgjSz2ah+uty3pp46ES7cgva4jDaNL+kNxR1R63bvxmlTpEhGtqnxSll5Rpb5nvGEnS1e0SVVTllN1uq9lms1g0uVey3kzN0IL92eocGa4n+52jHUWlSi9ljE7FX/t0lNPt1mVzV6lLdLieH5ii1KIypRf7js/ifbmaunrnMfcVEWjTxK5J2lXEmJwu08akyOnyqN9TS5USH6k3f9NX27JLlJpTWqtds9BAzZrYT9O+3K4vN2cr0GZRq6iQmvtfvK63Fm7N1q/+vUpJzUL10aQB2ppVrCXbCRpPxTNTr5PTWa1uFzygHslJ+uBfd2jLtv3anlY7KfTEQ1cr1B6o3oMfVvPYCH369t3al5mv9/77gyTpN9deoAnXXKBf3faqdqRlq12b5iosqvsaCZwIym8OswfbNLJ/kp6fs0mOymqt3ZGrJWsPaNzF7et9XGLzMJ3XrYU+XZ4hSbJYpHuu7qHH31mntMMfBvbmlBLUnyJ7gFUj2jbXjHV75Kh2a93BYn29N09jOsWd0H6iggMUERSgz9O8H8I255ZqV6FDHaNDz0S3zyrBNqsubBmrd9L2qMLl1tbCYq06lK8hCS3qbN/SHqxL4+P0Yfr+WtsjAgMUFhigrzO9AUhqcan2lTnUJtx+xo+hKQuxWXVpUqxe27JH5S63fswr1neZ+bqsTd3jczx/6NFOH6ZlqrCq+jT39OxkD7RpVEorPbdkpxxVLq3ZU6Al23N0Ve8En7a3XtRey9Jy9dmPmapyuVVW5dKuQ0c+XCVF2/Xpj1lye6S9+Q6t3lOgLnHhDXk4TU6oPUhjRvTWE3//QmWOKq1au1tffrVJ143r79N25KU9NONfS1Re4dS+A/maPWelbrz6fEmSxWLRvXdfroee+K92HP4wkLE3l6Aep8UJB/VFRUVnoh9+175VpNxuT60Sme17C9U5Karex42/uJ1Wbz+k/YcvqK1iQhUfG6YuraO0/KWx+ubvY/THq3vIwhqqp6RdpF0uj0d7istrtu3IL1On6LA62w9uE6uVN16gz8f31fXd4mu251U4NW9XjsZ3aSmrRerVIkIJ4cFad7C4zv3gl0sMtcvt8SjTUVGzLb2kTG3C6x6j33frqFlpe1TlctfaXljl1DdZORqW2FJWSd2iIhRnD9aWAsboVLSJ8L6G9pUeGZ/UojJ1iKx7fC5OiNGisQP0/vA+uqpDq1r3pTQLV3KzcH28m7K106VD8zC5PR6l5x0J7rZllahzXIRP2z6to1XkcOq/t52vNfcP0RsT+irhZ5n6N1dm6Oo+CQqwWtSheZjObd1My3flNcRhNFkd28fJ5XbXKpHZsv2AunWOr7O95Wdv+haLRcldvB/OElpFKzG+mZK7JGjTsmlav3Sq7r/n8lrtceKsFv/eGot6y2+2b9+uBx98UFarVdOnT9f06dO1atUqRUdH69VXX1VycnJD9fOMCw0JUInDWWtbicOpsJD6K5Suuri9Xvl0S83f8THejO/Ac1rpsvu+VGRokGY9MFjZ+eX64Otdp7/jZ4nQQJtKq1y1tpVUVSss0ObTdkH6IX24PUt5FVXq2SJSLw5JVklVteYfrr+fvztHjw7sogcGdJIkPboiVdlH1QrjxNltNjmqa49RWXW17DbfMbogLlY2i0Urc/J0TjPfD87fZufqnpROur1rB0nSK9vSlFvJt12nIjTApjJn7fEpdVYrtI7X0Ff7DunT3dnKr6hS99gIPXV+skqd1Vq0L1dWSff26ahnN+wWVaynT2iQTSUVtb/1KKl0KjzYd3xaRYaoR3ykJry1WjsOluj+kV0147reuuZf3vKOr7bn6PlremrSRe0VYLPqxaWp2nigaSbkGkpYaLCKSypqbSsuKVd4WIhP26++26o/3j5cd977jlrERujGa86X3R4oSUpsFS1JunRgN110xROKirTrvzPvUmZ2od7+cMWZPxA0afVm6h977DHdeeedmjBhgm699VaNHj1aP/74o6ZMmaLp06c3VB8bhKOiWuGHX3Q/CbcHqqzi2F8t9+3aXM2jQ/Tlqn012yoOB56vz92mEodTB3LL9P5XuzS4d92f5vHLOJwuhQXVfnMLD/INUiRpV6FDh8qr5PZIG3KK9c7WTI1o11yS1D7KrucuTdYDy3ao11vfaezHa/S7c1prUFJMgxxHU1bucskeUHuMQgMCVO6qPUbBNqtu7txOr26v+0NuUqhd9/Xsquc379SVS77XHSvW6ep2STqvebMz1vezgaPapbCjxicsIECOOl5D6SXlyq2oklvSprwSfZCWqSGJ3tfQ1R3jlVbk0OZ8Jv6fTo4ql8KDayeRwoMDVFrpOz6VTpcWbjuojQeKVFnt1otL09SvbTNFBAcoyh6oWRPP04yv09T1kUU6/+mvNahzC03o36ahDqVJKnNUKiK8dgAfER6i0rIKn7b3T/tIFRVOrV48Re++erv+O2+tMrMLJUnlld7k4Yx/LVFxSbn2HcjXrP8s17BLup/5g2jCyNR71RvUl5WVaejQoRo3bpwkaezYsZKkIUOGqLCw8Mz3rgGlZxfLZrOoXasjdYfJbaOVuv/Y2Y2rL26vRav3y1F5JPDfnVWsSqeLDNZpllFcrgCLRW0jj1xUu8aEK63w+JP0PB6PLPK+6jo3C1NGUbm+P1Agz+H9frs/TxcnETCeqgOOctksFiWEHhmj9hFh2nvU5NbEULta2oP19Hk9NfuS/nqodzc1Cw7S7Ev6Ky4kWG0jQnWgrFzr8grlObzf1bn56ktQf0r2lpTLZrWo9c8Ck87RYdpd/AteQ/Lo8EtI58VF65LEWM0f3V/zR/dXz9gI/bFXe/2ld4cz1fWzwu7cMtmsFrWLPTK/J7lVpFJzfD88bTtYIs/P3mR++qfFIrVp5i2D+3hDplxuj7KLKzR3Y5Yu7XJycyfgtSs9RwE2qzq0PXIeu3dL1PZU39WJCoscuv3Ps5R84YO68PLHZbVYtG6jd2WitN0HVVnllMdDlIDTr96g/uf/6S666KJa97nd7qObG6280qVFq/fr/67pKXuwTX27NNewvon69Lv0OtsHB9p02YA2+u+3te+vqHJp/g97ddvoZIWFBKhVjF3XD+mopeszG+IwmqzyarcW78nVXee2kz3Aqj5xkRrSJlZz03xXcxjSJlaRQd6M1znNIzQhJVFL93rrSbfllaptpF0D4r1fgbaOCNHg1rGsfHMaVLrcWnEwTxM6tlWwzark6Aid3yJGSzNrL5mYUVqmm5at1t0r1+vules1Y0uaCiurdPfK9cqtqNSu4jIlhNrVM8ZbltPKHqL+LWKUXsIYnYoKl1vfHMjTbSltFWKzqmdshAYlxOjLvb5LWg6Kj1HE4bKclGbhuq5TgpZl5kuSHl2zU9cvXKsJi9drwuL12lZQqje27tU/N/su/4tfrtzp0sKt2frT0M6yB9rUt020hifH6eMNvu8dc9bt18iUlkppFaEAq0X3DO6o/2Xkq7iiWul5Dlkkje0ZL4tFahEepNHntNK2bOaknApHeZXmLfpRD/zfFQq1B2nAuR10+bCe+vDT//m0bdemuZpFh8lqtWjYoBRNvP4iPffKAklSeYVTn3yxTvdMGq7wsGAltIrWb667UIu+3tzQh4QmqN6C8cTERJWWlio8PFyPPfZYzfbs7GzZ7U1vJYqH31yj6bcP0P/+eZUKSyv1tzfXKPVAsfp1baE377tEPW/5qKbtiH5JKnE4tXKr79rMU99ao8dv7a8Vr4xTiaNK/1m6S3O+2d2Qh9IkTVuRpscu7qLvfn2BiiqdenRFqtIKHerbMlKvjThH/d75XpJ0WYcWemxgFwXZrMouq9S/N+3TZ4dXu9lXUqHJy3fowfM7KiE8WCVVLs3blaP/7mTC3+nwj2279H89Ouu9wQNUXOXUK9t2aW+ZQ92jI/XIud11zdKVcnukgqoj81dKnNXy6Mi27PIK/X1Lqm7v1kFxIcFyVLv0TdYhLWKd+lP29LpdmtyvsxaMGaCiKqemr9ul9GKHejeP1AsDu+vST1dKkoa3bqHJ/Tor0GZVjqNS7+zYr/l7vB+gS50uSUdKQpxuj8qcLpVV+5aJ4MRMnrtVz4w/R2sfGKICh1OTP9+i1JxSnde2md76bT91n7ZYkrRyd76eWbxTb/62n+yBNq3eU6A/zvlRklRaWa3b31+n+0d01WNju6vS6daSHTl6+VvmdJ2qv0z9QC89eaN2/PCkCgrL9OcpH2h7WrbO79dRH77xB7Xp/WdJUu/urfX4Q9coKtKuXRk5uv3Ps2ote3nfo3P0wrRfa8vyx1VcUq63P/xesz9a6a/DahJYytHL4jmJ74AcDofKy8sVGxt7Qo/reMP7J/pUaCDBwxL93QUcR/skLluNWS6J0Ebt4AbmADRmxR984e8u4DjyU1/2dxeO6Z6VX/v1+WdccKlfn/8nJ/XjU6GhoQoNZV1vAAAA+Be/KOtF6g8AAAAwHEE9AAAAYDiCegAAABjLtHXq09PTdf3112vkyJG6/vrrlZGRccy2u3fvVq9evX7R70MR1AMAAAANZMqUKbrhhhu0cOFC3XDDDXr44YfrbOdyuTRlyhQNGzbsF+33pCbKAgAAAI2BvzPUxcXFKi72XQItMjJSkZGRtbbl5eVp69atmjlzpiRp9OjRmjZtmvLz8xUTU/vX7V9//XUNHjxYDodDDofjuP3w93kAAAAAjDVr1iwNHTrU5zZr1iyftllZWWrZsqVsNu8P/NlsNsXFxSkrq/avE2/fvl3Lly/XTTfd9Iv7QaYeAAAAOEkTJ07U+PHjfbYfnaX/pZxOp/72t7/pySefrAn+fwmCegAAABjrZCarnk51ldkcS3x8vA4ePCiXyyWbzSaXy6WcnBzFx8fXtDl06JD27t2r2267TZK3vMfj8ai0tFTTpk075r4J6gEAAIAGEBsbq+TkZM2bN0//v717j4uqzv84/h6GO4rkBQWvQF7QNFNKc7USNdxCyVrXx1qbWy1uF63czc1u3rrar12ztK3M2szWyixNNDMlKzWvWVl4RfCKFxQFGa7D/P6YQnEQ05QzX3g9ffB4yOHMmc+Z8/D44T2fcyYpKUkpKSmKjY2tME8fGRmpNWvWlH//8ssvy+Fw6OGHH65y28zUAwAAwFg2m8vSr3M1fvx4zZo1SwkJCZo1a5YmTJggSUpOTtamTZvO+3UgqQcAAACqSUxMjObMmeOxfPr06ZWuP3LkyF+1XZJ6AAAAwHAk9QAAADCW1RfKeguSegAAAMBwNPUAAACA4Ri/AQAAgLFIqN14HQAAAADDkdQDAADAWD7nca/4moikHgAAADAcTT0AAABgOMZvAAAAYCzuU+9GUg8AAAAYjqQeAAAAxiKpdyOpBwAAAAxHUw8AAAAYjvEbAAAAGMtudQFegqQeAAAAMBxJPQAAAIzFJ8q6kdQDAAAAhqOpBwAAAAzH+A0AAACMxX3q3UjqAQAAAMOR1AMAAMBYJPVuJPUAAACA4WjqAQAAAMMxfgMAAABj2Rm/kURSDwAAABiPpB4AAADG4kJZN5J6AAAAwHA09QAAAIDhGL8BAACAsXxsLqtL8Aok9QAAAIDhaOoBAAAAwzF+AwAAAGNx9xs3knoAAADAcCT1AAAAMJbd6gK8BEk9AAAAYDiaegAAAMBw1Tp+89KksOp8OpyDB+7PtLoEnMVWf95g9Ga2ww6rS0AVfOsFWF0CqtD0iSFWlwCDcaGsG0k9AAAAYDgulAUAAICx+ERZN5J6AAAAwHA09QAAAIDhGL8BAACAsexcKCuJpB4AAAAwHkk9AAAAjMUtLd1I6gEAAADD0dQDAAAAhmP8BgAAAMZi/MaNpB4AAAAwHEk9AAAAjEVS70ZSDwAAABiOph4AAAAwHOM3AAAAMJbd5rK6BK9AUg8AAAAYjqQeAAAAxiKhduN1AAAAAAxHUw8AAAAYjvEbAAAAGIv71LuR1AMAAACGo6kHAAAADMf4DQAAAIzF+I0bST0AAABgOJJ6AAAAGItPlHUjqQcAAAAMR1MPAAAAGI7xGwAAAPLW0gcAAB9LSURBVBiLC2XdSOoBAAAAw5HUAwAAwFgk9W4k9QAAAIDhaOoBAAAAwzF+AwAAAGMxfuNGUg8AAAAYjqQeAAAAxrKT1EsiqQcAAACMR1MPAAAAGI7xGwAAABjLx+ayugSvQFIPAAAAGI6kHgAAAMYioXbjdQAAAAAMR1MPAAAAGI7xGwAAABiLT5R1I6kHAAAADEdTDwAAABiO8RsAAAAYy874jSSSegAAAMB4JPUAAAAwFp8o60ZSDwAAABiOpP4U+bn5ev9f72nbhq0KCQ3RDXclqmufrh7rpb6fqvWfr1XOwRyF1AtRjwE9FT8kvvzn+3bs1UdTP1LWzv0KCA5Q9xuvVsKf+1fnrtRI9er469n7eqhn5wjl5BbphVkbteDrDI/1ZjzRR3Gx4eXf+/n6KGN/rm58cIEk6Yq2jfT4XVcqplk97T14QuNeX6MNmw9V237UZPVC/PXs3d3Vs1OEcvKK9MLs77RgZabHejPG9FZcbKPy793HKE83jl6oiAbBWvzvxArrhwT66dl3NmhGypaLvQs1Wr26AXpm9DXq2bWpcnIL9a/p67QgNd1jPX8/Hz1+Xw/169lSvr4++vangxo7eYUOZjsqrNeyaagWzrhFi7/M0EPPLq+mvai5OMd5t1B/X03s0VpXR1yiY0UlmrIxU4syDnusd8/lLZTcsblKnCfT41sWfKu9JwrVJTxU/+lzWYX1g/3sGrU8TUt3H7no+4Cajab+FB+9/KF8fe2aMOdJ7duxT2889rqaxkSqSauI09Z0aejDtyoiOlJH9mfrtYdf1SXhYbqidxdJ0qxn3lHHnp10379G6OjBo3r5wZfUNKaZLutxmeeT4lcbP7ybSkrL1P2OOYqNqq83HovXlsyj2r7neIX17npyWYXv333yen2z6YAk93+arz3aW+NeW6PPVu/WgF6t9PqjvdX77o+Vm19cbftSU42/60r3MRo+V7GtLtEbY67Tll052r73tGP03BcVvn93bF9985P7GGUdcejyYR+U/6xZoxAte2mgFq/Zc/F3oIYb/0APlZQ4dfUtsxR7aQNNf6a/Nu88qh2ZORXWG3bzZercIVyJyR8p70Sxnn6ol8aO7KH7xi09bXu/0w9bsqtzF2o0znHe7bFuMSopc+m6OavVrn4dTYvvoK1H85V+3OGx7meZ2XpkxVaP5d8eylW32avKv49rXE9T49tr5f4cj3Xx63GferdzHr9ZtWrV2VcyUFFBkX74+gf1v+MGBQQFKLpjtDr0uEzrP1/vsW78kD5q1rq57Ha7wps3Vocelynjx5NpytGDR9WlT1f52H3UMLKhoi+L0oHMrOrcnRonKMBXCd1baPLsjXIUlmrD5kNatm6PbroupsrHNW0UorjYcM1bvlOS1KVdIx05VqhPV+1SWZlL87/M0NHcIiV0b1Edu1GjBQXYldCtuSZ/8L0cRaXasPWwlq3fp5t6RVX5OPcxaqR5X3kmkpI06Npordt8SPsO51+MsmuNoEBfXd8rSi++tcH9b+jHg1r2zS7d1O9Sj3WbRdTVinV7dSSnQMUlTi1MTdelrS6psM6NvaOVe6JY32zcV127UKNxjvNuQb4+6teioaZu3KWC0jJtPJSr5XuOaEBM+NkfXIWkmHB9vitbBaVlF6hS1GZVNvU7duzw+HrkkUeUnp6uHTt2VFeN1eLw3sOy+fgovNnJf6CR0ZE6sOtAlY9zuVzK2LRTTVo1KV92zc3Xav2SdXKWOnVoz0FlpmWqTZe2F6322iAqMlRlZS5l7s8rX7Y5M0etm9er8nGDesdo/eZD2nvohCTJJptsp/1Gb5PUpkXYhS651omK+PkYZZ1yjHb9imN0TZTWbz6svWdo2gf1itJHX1be8OPXi2pWz318TnnXZEv6EbU+rVmXpDmLtqrLZY0V3iBYgQF2Dex7qb5ae/KdkjrBfnrgL3F69j+rq6X22oBznHdrGRokp8ulXXkF5cu25uQrpl5wpetf26y+Vgzpro8HdtEf25z+br9boN1H/Vo21Px0RqN+Kx+btV/eosrxm8TEREVGRlZYlp2dreTkZNlsNi1btuwMjzRPcWGRgkICKywLDAlSkaOwysd9NnOxylwuXZXQrXxZ++4d9L9J72r5nC9UVlam6/+coBbtSEl+i+BAX+U5SiosO+EoUUiQX5WPG3RdtKbN2VT+/bdbDyu8frASe7bS4m92acA1UWrRpK4CA5hE+60qP0bFCgk8yzG6JlrTPvqx0p/FtWukBmGBWrx69wWrs7YKDvJT3mnjF3n5xZX+G8rce1xZh05o5ZxbVeos07adRzXhpZPv0j54R5w+/HSrDvDuyQXDOc67BfvadaLEWWHZiRKnQvzsHut+lpmtD7cd0JHCYnVsWFeTr22vvOJSfZpZcf6+b8uGyiks1fqDxz22AZyPKpP6ESNGKCYmRu+8845SU1OVmpqqxo0bKzU1tUY19JLkHxigwtMa+CJHoQKCA8/wCOnreV9r/efrlPz0cPn6u0+Y+bn5ev2RV3X9bddr0qf/p7Gzx2vLui1aOX/FRa2/pnMUlqpOcMX/3OoE+Sm/oOQMj5C6xoarYViQFn+zq3zZsbwi3f3sF7pzYHutfuuPuuaKplr1Q5YOHKE5+a0chaWqc1oDUifYT/mFVRyjto3UsIqm/eZro/XZmj1yFJVe0FprI0dBieoE+1dYVifYv9J/QxMe7Cl/f1/FJc3U5Te8pSVfZ2rGc+6L/WNj6qtH16Z668NNHo/D+eMc590cpZ4NfIifXfmnNfqStPO4Q4cLilXmkr4/nKd3t+xTv5YNPdZLignXgp0HL1rNqH3O2tSPGjVK//jHPzR79mxJku309/VqiEbNGqnMWabDe0/+Jr0/fZ+atGxS6fprPl2t1PeW6p7n71VYo5Nvax7NOiIfHx9def1VstvtCmsUpit6X6HNa9Mu+j7UZBn7c2X3sallRN3yZe1aXeJxAdmpbu4doyWrd8tRWLEhXPvTQd38z0WKu/19PfTiCkVFhuqH7dx14LfKyMqV3W5TyyanHKOWZzlG10ZrydrKm/YAP7t+372FPvpy50Wpt7bJ2HvcfXyahpYvaxfTQNszPS/QaxdTXx8t3qbjeUUqLinTzI9/0uWx4bokNEDdOkeqaeM6+vK9P2nVh7fqrj92UsI1UZr32qDq3J0ah3Ocd9uVWyBfm00t6p4M+tpeElLpRbKnc7ncI1Cnahzsr7jGYfqE0ZsLwsfiL29x1lrat2+vmTNnat++fRo2bJhKSs6cGpgsIChAHXt20uK3F6mooEgZP+7Uj6t+VFy/OI91Nyxbr0VvLtTdk+5Rg8iKv303ahYul8ulDcs2qKysTLlHc/Xd8o2KjGlaXbtSIxUUlWrJ6t168E+dFRTgqy7tGqnvVc01b7nn7fgkKcDfrt/3aKm5X3j+vH1UffnabaoT5Kcxf+mqA0cc+vq7/Rd7F2q8giKnlqzdowf/2ElBAXZ1adtIfeOaaV4lt+STTjbtc5dX3rRff1Vz5eaXaPVPJFkXQkFhqZZ8nakH7+iqoEBfdenQWH17tNS8zz2vj9q09bAGXd9adUL85Gu36dak9jqQna+c3CK9l7JZfW57XwOTP9LA5I80e8FmLV+9W3f+81ML9qrm4Bzn3QpKy7R09xHd17mlgnx91LlRqHo3b6AFlTTlvZvXV+jP795f1qCOhsZG6os9FX+pGhDdWN8fztXeE1WP+ALn4lcN2fn7++uhhx7Sd999p7Vr117smixzy/1/0PsvzNa4wU8ouG6wbnlgsJq0itDOTel6/ZHX9FzK85KkT99apPzcfE2+79/lj+3aN06DH/yjAkMCdcf4O5UyfYHmTpkjvwA/te/eQX2H9rNqt2qMca+v0XMjemjNfwfrWF6xxr62Rtv3HFdcbLhmPNFHlw+dXb5uv6uaKy+/WKs3eV7onDyog67r4v4l66uN+3XPpOXVtQs13rg31um5e7przet/0LETRRr7xjpt33tcce0aacYjvSvcqrLflc2U5zhz037ztVH6+CtS+gtp/JSVenb0NVo99zYdyy3SuBdXaEdmjuI6NtEbz/VX5xv/K0l67tU1emJEDy2dOUR+fj7alpGj+8Z+LkkqLHKqsOjkxYKOghIVFTt19DjNyW/FOc67PbVmh57s0VrLB3fX8eISPbVmh9KPO8rvPf/LrSr7t2qkiT3ayN/HRwcdRXrzx736ZGfF5n9gTLje+mmvFbtRI9XQIZJzZnO5XNX22boL95DkeKsH7vf8AA14GX/PC7LgPWyHz/42PKzjqhdgdQmoQtCgqm99C+ttur2X1SWc0drDCy19/qsa3Wjp8//Cm0aBAAAAAJwH7nEFAAAAYzF940ZSDwAAABiOpB4AAADG4kJZN5J6AAAAwHA09QAAAIDhGL8BAACAsUio3XgdAAAAAMOR1AMAAMBYNlu1fY6qVyOpBwAAAAxHUw8AAAAYjvEbAAAAGIvb1LuR1AMAAACGo6kHAAAADMf4DQAAAIxlY/5GEkk9AAAAYDySegAAABiLoN6NpB4AAAAwHE09AAAAYDjGbwAAAGAsH+ZvJJHUAwAAAMYjqQcAAICxCOrdSOoBAAAAw9HUAwAAAIZj/AYAAADGMu0TZTMyMjRmzBgdO3ZMYWFhmjRpklq1alVhnWnTpmnRokWy2+3y9fXVqFGj1KtXryq3S1MPAAAAVJNx48Zp6NChSkpK0vz58zV27FjNnDmzwjqdOnXSnXfeqaCgIG3ZskW33XabVqxYocDAwDNul/EbAAAAGMtm8de5OHLkiNLS0pSYmChJSkxMVFpamo4ePVphvV69eikoKEiS1LZtW7lcLh07dqzKbZPUAwAAAOcpNzdXubm5HstDQ0MVGhpaYVlWVpYaN24su90uSbLb7QoPD1dWVpbq169f6fbnzZunFi1aqEmTJlXWQVMPAAAAnKe3335bU6dO9Vg+YsQIjRw58jdte+3atZoyZYrefPPNs65LUw8AAABjWX2d7LBhwzRo0CCP5aen9JIUERGhgwcPyul0ym63y+l06tChQ4qIiPBYd+PGjRo9erReeeUVRUdHn7UOmnoAAADgPFU2ZnMmDRo0UGxsrFJSUpSUlKSUlBTFxsZ6jN788MMPGjVqlF566SV16NDhV22bC2UBAABgLB+btV/navz48Zo1a5YSEhI0a9YsTZgwQZKUnJysTZs2SZImTJigwsJCjR07VklJSUpKStLWrVur3C5JPQAAAFBNYmJiNGfOHI/l06dPL//73Llzz3m7JPUAAACA4UjqAQAAYCyrL5T1FiT1AAAAgOFI6gEAAGAsm81ldQlegaQeAAAAMBxNPQAAAGA4xm8AAABgLC6UdSOpBwAAAAxHUw8AAAAYjvEbAAAAGMvG/I0kknoAAADAeCT1AAAAMBYJtRuvAwAAAGA4mnoAAADAcIzfAAAAwFhcKOtGUg8AAAAYrlqT+hubx1Tn0+Ec3Pgxxwb4LQ4VbrG6BFQht5goz5tdGtrY6hJgMP51u5HUAwAAAIajqQcAAAAMx4WyAAAAMBYXyrqR1AMAAACGI6kHAACAsQjq3UjqAQAAAMPR1AMAAACGY/wGAAAAxvJh/kYSST0AAABgPJJ6AAAAGIug3o2kHgAAADAcTT0AAABgOMZvAAAAYCybzWV1CV6BpB4AAAAwHE09AAAAYDjGbwAAAGAs7n7jRlIPAAAAGI6kHgAAAMayEdVLIqkHAAAAjEdTDwAAABiO8RsAAAAYi+kbN5J6AAAAwHAk9QAAADAWCbUbrwMAAABgOJp6AAAAwHCM3wAAAMBY3KfejaQeAAAAMBxJPQAAAAxGVC+R1AMAAADGo6kHAAAADMf4DQAAAIxlY/xGEkk9AAAAYDySegAAABjLZiOjlkjqAQAAAOPR1AMAAACGY/wGAAAABuNCWYmkHgAAADAeST0AAACMxS0t3UjqAQAAAMPR1AMAAACGY/wGAAAABmP8RiKpBwAAAIxHUw8AAAAYjvEbAAAAGMtmI6OWSOoBAAAA45HUAwAAwGBcKCuR1AMAAADGo6kHAAAADMf4DQAAAIxlY/xGEkn9eTl2LE/33fe0Onf+g3r3vlMLFiy3uiScguPj3Tg+1sk97tCjD/5X/bo9qj/0f1qfL9pY6Xrfrt2h++96Vf1/94QG//6ZM25v4/p09bp8tKZPXXyxSq5V8o479NTo/+rmXo/oLwOe0vLF31a63vfrd2jM3f/R4Ose1x0Dn/b4efrWffpn8jQNvu5x3X7jk/rf9CUXu3ScgnMcrEJSfx4mTnxVfn6+WrnyHW3evFN/+9tEtWsXpdatW1pdGsTx8XYcH+v8+5mP5efnq/lfjNOOLfv1z5Fv6tI2EYq6tEmF9QKD/HXDTVeqb1FnvTMjtdJtlZY49dLz89W+Y4vqKL1WeOX5j+Tra9e7n43Xzm37Nf7BGYpqHamWMZ7H5/qBV6no+hJ98N9lHtv5vyfe1dXXddSzr96jQ1lHNfqv0xTdpqm6X9uhunalVuMcV/1I6t1I6s+Rw1GoJUtW6YEHblNISJDi4jooPv4qzZ//hdWlQRwfb8fxsU6Bo1hfLt2ku+5LUHBwgDp1idLvrm2vz1I80+D2HVuo/4CuimxW/4zbe2/ml7ry6jZqEdXoYpZdaxQWFGlV6ib9+e7+CgoOUIfOUep2TXulLtrgsW7bDi0Uf0NXNWla+fE5tD9HvftfIbvdRxHNGqp95yjt3nngYu8CxDkO1qqyqV+5cmX53/Py8jR69Gj17dtXI0eOVHZ29kUvzhtlZu6Tj4+PoqKali9r1y5KO3bstrAq/ILj4904PtbZs+uwfOw2tWh1sgm/tG2EMtLPvdk7sD9HC+et01/+1u9Cllir7dudLR+7TU1bnjw+Ua0jz6sZT/pTLy1buEGlpU7tzTykLZt2qfNVrS9kuTgDznGwUpVN/QsvvFD+98mTJyskJESvvPKKoqOj9dRTT1304ryRw1GounWDKyyrWzdE+fkFFlWEU3F8vBvHxzoFBUWqUyewwrKQOkFyOIrOeVtTJs3TX39O/HFhFDiKFBwSVGFZSJ1AFZzH8bmyZ3utTP1Bg3o+or8Nfl7XD7xKbTowJlUdOMdZxcfiL+9Q5Uy9y+Uq//uGDRv04Ycfys/PT23atNGAAQMuenHeKDg4UCdOOCosO3HCoZDTTsawBsfHu3F8rBMUFKD8/IoNouNE4Tk35iuXp8mRX6Q+/TtfyPJqvaDgABXkF1ZY5sgvVNA5Hp+84w6NfWC67hk9SNclXKGcI3l6ZsxMhdWvo8TBv7uQJaMSnONgpSqb+uLiYqWnp8vlcslms8nPz6/8Zz4+3vObSXVq1aqpnM4yZWbuV6tWkZKkLVsydOmlpCDegOPj3Tg+1mnespGcpWXas+uwmv884rFj235FnXYR5tlsWLtdW9L2Kil+giTpxIlC2X18tHN7lp6dcscFr7u2aNqioZzOMu3bfVhNW7iPT8b2LLWIPrfjc2DfEfn4+KjPjXGSpIaNw3RNv85av2oLTX014BxnDZuNC2Wls7xnUFhYqOHDh2v48OHKzc3VwYMHJUknTpyotU19cHCg+vW7Wi+99K4cjkJt2JCmZcvWKCmpt9WlQRwfb8fxsU5QsL+u6XOZZryyRAWOYv2wMUMrlqcpIbGLx7plZWUqKipRaWmZXC6XiopKVFJSKkn6630J+t8n/9SbH4zSmx+MUs9rOyjxlm56ZOKQ6t6lGiUwKEA9enfUrNc+U2FBkdK+z9DqL39S/A1dPdYtKytTcVGJnKVOuVwuFZ9yfJq2aCS5XFq++FuVlZXpaHauvl76vaJaR1b3LtVKnONgJZvr1BmbX6mgoEDZ2dlq3rz5OT5y27k+lVc6dixPjz46RatWfaewsLr6xz+GacCA66wuCz/j+Hi3mnp8DhVusbqEs8o97tCz4z7Q+m+2KTQsRHc/cIP63XCFvv92p0bfO0NLVrvveb5xXbru/+urFR7bOS5aL8+4x2ObTz/xnsIbhyl5RP9q2YfzlVvs/Ule3nGHXnzyfW1cs02h9UL0lxE36Lr+XfTjxp0a98AbmvuV+zMDftiwQ4/cXfH4dOwSredeu1eS9P267Xrr5YXatztb/gF+6tarvYY/lKTAQP9q36df69LQtlaXcMHU1HOc1MbqAs4ov/RLS58/xPdaS5//F+fV1J+/mtHUA8DpTGjqazMTmvrarCY19TWXNzf1X1n6/CG+11j6/L+onTM0AAAAQA3CJ8oCAADAWHyirBtJPQAAAGA4mnoAAADAcIzfAAAAwGBk1BKvAgAAAGA8knoAAAAYiwtl3UjqAQAAAMPR1AMAAACGY/wGAAAAxrLZGL+RSOoBAAAA49HUAwAAAIZj/AYAAAAGY/xGIqkHAAAAjEdSDwAAAGPZyKglkdQDAAAAxqOpBwAAAAzH+A0AAAAMxoWyEkk9AAAAYDySegAAABiLT5R1I6kHAAAADEdTDwAAABiO8RsAAAAYjPEbiaQeAAAAMB5JPQAAAIzFJ8q68SoAAAAAhqOpBwAAAAzH+A0AAAAMxoWyEkk9AAAAYDySegAAABjLRlIviaQeAAAAMB5NPQAAAGA4xm8AAABgLJuN8RuJpB4AAAAwHk09AAAAYDjGbwAAAGAwMmqJVwEAAAAwHkk9AAAAjMV96t1I6gEAAADD0dQDAAAAhmP8BgAAAAZj/EYiqQcAAACMR1IPAAAAY/GJsm4k9QAAAIDhaOoBAAAAwzF+AwAAAIORUUu8CgAAAEC1ycjI0JAhQ5SQkKAhQ4YoMzPTYx2n06kJEyaob9++6tevn+bMmXPW7dLUAwAAwFg2i/+cq3Hjxmno0KH67LPPNHToUI0dO9ZjnQULFmj37t1asmSJ3n//fb388svau3dvldulqQcAAADOU25urvbu3evxlZub67HukSNHlJaWpsTERElSYmKi0tLSdPTo0QrrLVq0SIMHD5aPj4/q16+vvn37avHixVXWUc0z9W2q9+kAoJqEB3J+82bhgVZXAODisfb8+/bbL2vq1Kkey0eMGKGRI0dWWJaVlaXGjRvLbrdLkux2u8LDw5WVlaX69etXWC8yMrL8+4iICB04cKDKOrhQFgAAADhPw4YN06BBgzyWh4aGVmsdNPUAAADAeQoNDf3VDXxERIQOHjwop9Mpu90up9OpQ4cOKSIiwmO9/fv3q1OnTpI8k/vKMFMPAAAAVIMGDRooNjZWKSkpkqSUlBTFxsZWGL2RpP79+2vOnDkqKyvT0aNHtXTpUiUkJFS5bZvL5XJdtMoBAAAAlEtPT9eYMWOUm5ur0NBQTZo0SdHR0UpOTtb999+vjh07yul0auLEiVq5cqUkKTk5WUOGDKlyuzT1AAAAgOEYvwEAAAAMR1MPAAAAGI6mHgAAADAcTT0AAABgOJr685CRkaEhQ4YoISFBQ4YMUWZmptUl4RSTJk1SfHy82rZtq23btlldDk6Rk5Oj5ORkJSQkaMCAARoxYoTHR2PDevfee68GDhyom266SUOHDtXmzZutLgmnmTp1Kuc4LxUfH6/+/fsrKSlJSUlJ+vrrr60uCbUEd785D7fffrtuueUWJSUlaf78+Zo7d65mzpxpdVn42fr169W0aVPdeuutevXVV9WmjbUfH42Tjh07pq1bt6pbt26S3L+AHT9+XM8884zFleFUeXl5qlu3riRp6dKlmjZtmj7++GOLq8IvfvrpJ02ePFnp6el67bXXOMd5mfj4eP7vgSVI6s/RkSNHlJaWpsTERElSYmKi0tLSSBu9SFxcnMcns8E7hIWFlTf0ktS5c2ft37/fwopQmV8aekk6ceKEbDabhdXgVMXFxZo4caLGjRvHcQFQga/VBZgmKytLjRs3lt1ulyTZ7XaFh4crKyvL49PAAJxZWVmZZs+erfj4eKtLQSUee+wxrVy5Ui6XS2+88YbV5eBnU6ZM0cCBA9W8eXOrS0EVHnroIblcLnXt2lV///vfFRoaanVJqAVI6gFY4sknn1RwcLBuu+02q0tBJZ5++mktX75co0aN0vPPP291OZC0ceNGbdq0SUOHDrW6FFTh3Xff1SeffKK5c+fK5XJp4sSJVpeEWoKm/hxFRETo4MGDcjqdkiSn06lDhw4x7gGcg0mTJmnXrl168cUX5ePDacib3XTTTVqzZo1ycnKsLqXWW7dunXbu3Kk+ffooPj5eBw4c0F133aUVK1ZYXRpO8Us/4O/vr6FDh+rbb7+1uCLUFvxveo4aNGig2NhYpaSkSJJSUlIUGxvL6A3wK02ePFk//vijpk2bJn9/f6vLwWny8/OVlZVV/n1qaqrq1aunsLAwC6uCJA0fPlwrVqxQamqqUlNT1aRJE82YMUM9e/a0ujT8zOFwKC8vT5Lkcrm0aNEixcbGWlwVagvufnMe0tPTNWbMGOXm5io0NFSTJk1SdHS01WXhZ0899ZSWLFmi7OxsXXLJJQoLC9PChQutLguStm/frsTERLVq1UqBgYGSpGbNmmnatGkWV4ZfZGdn695771VBQYF8fHxUr149Pfzww+rQoYPVpeE03GXF++zZs0cjR46U0+lUWVmZYmJi9Pjjjys8PNzq0lAL0NQDAAAAhmP8BgAAADAcTT0AAABgOJp6AAAAwHA09QAAAIDhaOoBAAAAw9HUAwAAAIajqQcAAAAMR1MPAAAAGO7/AQtqIoZ+sCAPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14.0,12.0)})\n",
    "sns.heatmap(pd.DataFrame(df_sb),annot=True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a new interview with Britains Sky News, former NATO Secretary-General Anders Fogh Rasmussen brought out the old narrative of America as the worlds policeman, but with a lot more upbeat of an attitude about it than one would generally see.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rasmussen criticized President Obama for not being hawkish enough, saying his successor needs to be much more interventionist, and declaring  we need America as the worlds policeman,  adding that the US needs to restore international law and order through wars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rasmussen, who was always a relative hawk in the post but seems to have taken it to an entirely new level, set out a series of things the US needs to fix militarily, including Iraq, Syria, Libya, Russia, China, and North Korea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This of course closely mirrors recent Pentagon talk of wars in the decades to come.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The timing of his calls for extreme US bellicosity are centered on trying to influence the upcoming US election in favor of Democratic nominee Hillary Clinton, who has campaigned heavily on picking fights in Syria and against Russia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rasmussen underscored this fact by declaring Donald Trump, who openly said the US cannot be the worlds police, as very dangerous for the world.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                            0\n",
       "0  In a new interview with Britains Sky News, former NATO Secretary-General Anders Fogh Rasmussen brought out the old narrative of America as the worlds policeman, but with a lot more upbeat of an attitude about it than one would generally see.                     \n",
       "1  Rasmussen criticized President Obama for not being hawkish enough, saying his successor needs to be much more interventionist, and declaring  we need America as the worlds policeman,  adding that the US needs to restore international law and order through wars.\n",
       "2  Rasmussen, who was always a relative hawk in the post but seems to have taken it to an entirely new level, set out a series of things the US needs to fix militarily, including Iraq, Syria, Libya, Russia, China, and North Korea.                                       \n",
       "3  This of course closely mirrors recent Pentagon talk of wars in the decades to come.                                                                                                                                                                                       \n",
       "4  The timing of his calls for extreme US bellicosity are centered on trying to influence the upcoming US election in favor of Democratic nominee Hillary Clinton, who has campaigned heavily on picking fights in Syria and against Russia.                                 \n",
       "5  Rasmussen underscored this fact by declaring Donald Trump, who openly said the US cannot be the worlds police, as very dangerous for the world.                                                                                                                        "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x['sentences'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf_eval():\n",
    "\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "\n",
    "    for idx in dnf_eval.id: \n",
    "        hd = dnf_eval[dnf_eval.id==idx]['headline'].values[0].lower()\n",
    "        ar_id = dnf_eval[dnf_eval.id==idx]['id'].values[0]\n",
    "        cl = dnf_eval[dnf_eval.id==idx]['claim_ids'].values[0]\n",
    "        ar_claims.append(cl)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "\n",
    "\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "    #         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "\n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "\n",
    "        inputs = {\n",
    "            'article_id': np.array(ar_ids)\n",
    "            ,'headline': np.array(hds)\n",
    "            ,'sentence_vectors' : np.array(ar_sents)\n",
    "            ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "            ,'claims':np.array(ar_claims)\n",
    "            ,'sentences':np.array(ar_sentences)\n",
    "        }\n",
    "        outputs = {\n",
    "            'headline_token_classes': np.array(ar_head_classes)\n",
    "            ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "        }\n",
    "    return inputs,outputs\n",
    "testX,testY = datagen_dnf_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.389, 0.526, 0.44724371584699457)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(testX)\n",
    "_, b2, g2 = model_2.predict(testX)\n",
    "_, b3, g3 = model_3.predict(testX)\n",
    "_, b4, g4 = model_4.predict(testX)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in range(len(testX['headline'])):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(testX['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    pred = b[0][:len(testX['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "    \n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for p in pred:\n",
    "        if p in claims:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    for c in claims:\n",
    "        if c not in pred:\n",
    "            fn+=1\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "#     counter+=1\n",
    "#     if counter==5:\n",
    "#         break\n",
    "#     print(\"----------------------------\")\n",
    "#     for s in t:\n",
    "#         if s>=len(x['sentences'][test_idx]):continue\n",
    "#         x['sentences'][test_idx][s]\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Topic', 'Title', 'article Id', 'Headline'], dtype='object'),\n",
       " Index(['Unnamed: 0', 'Topic', 'Article', 'Claim'], dtype='object'),\n",
       " 522,\n",
       " 522,\n",
       " Index(['authors', 'claim_ids', 'evidence', 'headline', 'id', 'reason',\n",
       "        'claims', 'type', 'urls'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hd_tp_cdc = pd.read_csv('evaluation_set/cdc_ibm/headline_topic_mapping.csv')\n",
    "df_ar_cl_cdc = pd.read_csv('evaluation_set/cdc_ibm/article_claim_mapping.csv')\n",
    "df_hd_tp_dnf = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "df_hd_tp_dnf.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls']\n",
    "with open('evaluation_set/cdc_ibm/articles.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/cdc_ibm/article_vectors.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "df_hd_tp_cdc.keys(),df_ar_cl_cdc.keys(), len(articles.keys()), len(article_vectors.keys()), df_hd_tp_dnf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = []\n",
    "for ar in df_ar_cl_cdc.Article.unique():\n",
    "    if len(df_ar_cl_cdc[df_ar_cl_cdc.Article==ar]['Claim'].values)>8:\n",
    "        test_titles.append(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e5767d1f5c422b83ab9fedcb4c2b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video game controversies\n",
      "Brown v. Entertainment Merchants Association\n",
      "One-child policy\n",
      "Human population control\n",
      "Use of performance-enhancing drugs in sport\n",
      "Physical exercise\n",
      "Affirmative action\n",
      "Equal opportunity\n",
      "Affirmative action in the United States\n",
      "Boxing\n",
      "Multiculturalism in the Netherlands\n",
      "Criticism of multiculturalism\n",
      "Multicultural education\n",
      "Gambling\n",
      "Problem gambling\n",
      "Economics of gambling\n",
      "Republicanism in the United Kingdom\n",
      "Nuclear weapon\n",
      "Nuclear proliferation\n",
      "Nuclear peace\n",
      "Deterrence theory\n",
      "Abortion debate\n",
      "Philosophical aspects of the abortion debate\n",
      "Year-round school\n",
      "Social safety net\n",
      "Poverty reduction\n",
      "Economic inequality\n",
      "Redistribution of wealth\n",
      "Atheism\n",
      "Existence of God\n",
      "Criticism of religion\n",
      "The God Delusion\n",
      "Conscription\n",
      "Aid effectiveness\n",
      "Development aid\n",
      "Aid\n",
      "Care work\n",
      "Intellectual property\n",
      "Libertarian perspectives on intellectual property\n",
      "Anti-copyright\n",
      "Philosophy of copyright\n",
      "Environmental impact of wind power\n",
      "Biodiversity\n",
      "Deficit spending\n",
      "Gun control\n",
      "Gun politics\n",
      "Political arguments of gun politics in the United States\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ar_ids,ar_sents,ar_sentences,ar_head_vectors,ar_head_classes,hds,claims=[],[],[],[],[],[],[]\n",
    "for idx in tqdm_notebook(test_titles):\n",
    "    print(idx)\n",
    "    hd = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['Headline'].values[0].lower()\n",
    "    hds.append(hd)\n",
    "    ar_id = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['article Id'].values[0]\n",
    "    cl = df_ar_cl_cdc[df_ar_cl_cdc.Article==idx]['Claim'].values\n",
    "    claims.append(cl)\n",
    "#     sentences=articles[ar_id]\n",
    "#     ar_sentences.append(ar_sentences)\n",
    "    #         print(len(sentences))\n",
    "    sents = np.zeros((max_sentences,300))\n",
    "    vectors = article_vectors[ar_id]\n",
    "    sents[:len(vectors)] = vectors[:max_sentences]\n",
    "    ar_ids.append(ar_id)\n",
    "    ar_sents.append(sents)\n",
    "    hd_nlp = nlp(hd.lower())\n",
    "    head_classes = np.zeros(50, dtype='int')\n",
    "    for i in range(len(hd_nlp)):\n",
    "        head_classes[i] = hd_nlp[i].rank\n",
    "    ar_head_vectors.append(hd_nlp.vector)\n",
    "    ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "inputs = {\n",
    "    'article_id': np.array(ar_ids)\n",
    "    ,'headline': np.array(hds)\n",
    "    ,'sentence_vectors' : np.array(ar_sents)\n",
    "#     ,'sentences' : np.array(ar_sentences)\n",
    "    ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "    ,'claims':np.array(claims)\n",
    "}\n",
    "outputs = {\n",
    "    'headline_token_classes': np.array(ar_head_classes)\n",
    "    ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7052873160403f9a9f2f536377c673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1872340425531915, 0.07724237937003894, 0.10936629315166427)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.95\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(inputs)\n",
    "_, b2, g2 = model_2.predict(inputs)\n",
    "_, b3, g3 = model_3.predict(inputs)\n",
    "_, b4, g4 = model_4.predict(inputs)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in tqdm_notebook(range(len(inputs['headline']))):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(inputs['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    ids = b[0][:len(articles[inputs['article_id'][test_idx]])].argsort()[-best_N:][::-1]\n",
    "#     print(ids)\n",
    "    pred = np.array(articles[inputs['article_id'][test_idx]])[ids]\n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "        t5 = nlp(str(pred[i]))\n",
    "        flag = False\n",
    "        #pred_claim_sent.append(pred[i])\n",
    "    #     print(t5.vector)\n",
    "        for j in range(len(cl)):\n",
    "            _c = nlp(cl[j])\n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                tp+=1\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fp+=1\n",
    "        \n",
    "            \n",
    "   \n",
    "    #     print(t5.vector)\n",
    "    for j in range(len(cl)):\n",
    "        _c = nlp(cl[j])\n",
    "        flag = False\n",
    "        for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "            t5 = nlp(str(pred[i]))\n",
    "        \n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fn+=1\n",
    "         \n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
